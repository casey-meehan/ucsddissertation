@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}


@inproceedings{vicreg,
  author    = {Adrien Bardes and
               Jean Ponce and
               Yann LeCun},
  title     = {VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised
               Learning},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
  url       = {https://openreview.net/forum?id=xm6YD62D1Ub},
  timestamp = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/BardesPL22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{simclr,
  author    = {Hui Zeng and
               Xiaohui Cui},
  title     = {SimCLRT: {A} Simple Framework for Contrastive Learning of Rumor Tracking},
  journal   = {Eng. Appl. Artif. Intell.},
  volume    = {110},
  pages     = {104757},
  year      = {2022},
  url       = {https://doi.org/10.1016/j.engappai.2022.104757},
  doi       = {10.1016/j.engappai.2022.104757},
  timestamp = {Fri, 13 May 2022 19:52:30 +0200},
  biburl    = {https://dblp.org/rec/journals/eaai/ZengC22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{
      RCDM,
      title={High Fidelity Visualization of What Your Self-Supervised Representation Knows About},
      author={Florian Bordes and Randall Balestriero and Pascal Vincent},
      journal={Transactions on Machine Learning Research},
      year={2022},
      url={https://openreview.net/forum?id=urfWb7VjmL},
      note={}
}

@InProceedings{MAE,
    author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll\'ar, Piotr and Girshick, Ross},
    title     = {Masked Autoencoders Are Scalable Vision Learners},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16000-16009}
}

@inproceedings{Dino,
author = {Mathilde Caron and Hugo Touvron and Ishan Misra and Herve Jegou and Julien Mairal Piotr Bojanowski Armand Joulin},
title = {Emerging Properties in Self-Supervised Vision Transformers},
booktitle = {ICCV},
year = {2021}}

@inproceedings{chen2020simsiam,
author={Xinlei Chen and Kaiming He},
title={Exploring simple siamese representation learning},
booktitle={CVPR},
year={2020}}

@inproceedings{grill2020byol,
title={Bootstrap your own latent: A new approach to self-supervised Learning},
author={Jean-Bastien Grill and Florian Strub and Florent Altché and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and Rémi Munos and Michal Valko},
booktitle={NeurIPS},
year={2020}}

@inproceedings{chen2020simclr,
author={Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey E. Hinton},
title={A Simple Framework for Contrastive Learning of Visual Representations},
booktitle={ICML},
year={2020}}

@inproceedings{caron2020swav,
title={Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
author={Mathilde Caron and Ishan Misra and Julien Mairal and Priya Goyal and Piotr Bojanowski and Armand Joulin},
booktitle={NeurIPS},
year={2020}}

@article{zbontar2021barlow,
title={Barlow Twins: Self-Supervised Learning via Redundancy Reduction}, 
author={Jure Zbontar and Li Jing and Ishan Misra and Yann LeCun and Stéphane Deny},
journal={arXiv preprint arxiv:2103.03230},
year={2021}}

@misc{Guillotine,
  doi = {10.48550/ARXIV.2206.13378},
  
  url = {https://arxiv.org/abs/2206.13378},
  
  author = {Bordes, Florian and Balestriero, Randall and Garrido, Quentin and Bardes, Adrien and Vincent, Pascal},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Guillotine Regularization: Improving Deep Networks Generalization by Removing their Head},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@article{salem2018ml,
  title={Ml-leaks: Model and data independent membership inference attacks and defenses on machine learning models},
  author={Salem, Ahmed and Zhang, Yang and Humbert, Mathias and Berrang, Pascal and Fritz, Mario and Backes, Michael},
  journal={arXiv preprint arXiv:1806.01246},
  year={2018}
}

@inproceedings{carlini2019secret,
  title={The secret sharer: Evaluating and testing unintended memorization in neural networks},
  author={Carlini, Nicholas and Liu, Chang and Erlingsson, {\'U}lfar and Kos, Jernej and Song, Dawn},
  booktitle={28th USENIX Security Symposium (USENIX Security 19)},
  pages={267--284},
  year={2019}
}

@inproceedings{yeom2018privacy,
  title={Privacy risk in machine learning: Analyzing the connection to overfitting},
  author={Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle={2018 IEEE 31st computer security foundations symposium (CSF)},
  pages={268--282},
  year={2018},
  organization={IEEE}
}

@inproceedings{zhang2020secret,
  title={The secret revealer: Generative model-inversion attacks against deep neural networks},
  author={Zhang, Yuheng and Jia, Ruoxi and Pei, Hengzhi and Wang, Wenxiao and Li, Bo and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={253--261},
  year={2020}
}

@inproceedings{sablayrolles2019white,
  title={White-box vs black-box: Bayes optimal strategies for membership inference},
  author={Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and Ollivier, Yann and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={5558--5567},
  year={2019},
  organization={PMLR}
}

@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={954--959},
  year={2020}
}

@inproceedings{fredrikson2014privacy,
  title={Privacy in pharmacogenetics: An $\{$End-to-End$\}$ case study of personalized warfarin dosing},
  author={Fredrikson, Matthew and Lantz, Eric and Jha, Somesh and Lin, Simon and Page, David and Ristenpart, Thomas},
  booktitle={23rd USENIX Security Symposium (USENIX Security 14)},
  pages={17--32},
  year={2014}
}

@article{mehnaz2022your,
  title={Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models},
  author={Mehnaz, Shagufta and Dibbo, Sayanton V and Kabir, Ehsanul and Li, Ninghui and Bertino, Elisa},
  journal={arXiv preprint arXiv:2201.09370},
  year={2022}
}

@article{jayaraman2022attribute,
  title={Are attribute inference attacks just imputation?},
  author={Jayaraman, Bargav and Evans, David},
  journal={arXiv preprint arXiv:2209.01292},
  year={2022}
}

@article{balle2022reconstructing,
  title={Reconstructing training data with informed adversaries},
  author={Balle, Borja and Cherubin, Giovanni and Hayes, Jamie},
  journal={arXiv preprint arXiv:2201.04845},
  year={2022}
}

@article{guo2022bounding,
  title={Bounding Training Data Reconstruction in Private (Deep) Learning},
  author={Guo, Chuan and Karrer, Brian and Chaudhuri, Kamalika and van der Maaten, Laurens},
  journal={arXiv preprint arXiv:2201.12383},
  year={2022}
}

@article{ericsson2021self,
  title={Why do self-supervised models transfer? investigating the impact of invariance on downstream tasks},
  author={Ericsson, Linus and Gouk, Henry and Hospedales, Timothy M},
  journal={arXiv preprint arXiv:2111.11398},
  year={2021}
}

@article{jing2021understanding,
  title={Understanding dimensional collapse in contrastive self-supervised learning},
  author={Jing, Li and Vincent, Pascal and LeCun, Yann and Tian, Yuandong},
  journal={arXiv preprint arXiv:2110.09348},
  year={2021}
}

@inproceedings{kalibhat2022towards,
  title={Towards better understanding of self-supervised representations},
  author={Kalibhat, Neha Mukund and Narang, Kanika and Firooz, Hamed and Sanjabi, Maziar and Feizi, Soheil},
  booktitle={ICML 2022: Workshop on Spurious Correlations, Invariance and Stability},
  year={2022}
}

@inproceedings{yu2018generative,
  title={Generative image inpainting with contextual attention},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5505--5514},
  year={2018}
}

@inproceedings{ulyanov2018deep,
  title={Deep image prior},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9446--9454},
  year={2018}
}

@article{dwork2013algorithmic,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron},
  journal={Theoretical Computer Science},
  volume={9},
  number={3-4},
  pages={211--407},
  year={2013}
}

@incollection{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of cryptography},
  pages={265--284},
  year={2006},
  publisher={Springer}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

@article{thomee2015new,
  title={The new data and new challenges in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={arXiv preprint arXiv:1503.01817},
  volume={1},
  number={8},
  year={2015}
}

@inproceedings{kandpal2022deduplicating,
  title={Deduplicating training data mitigates privacy risks in language models},
  author={Kandpal, Nikhil and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={10697--10707},
  year={2022},
  organization={PMLR}
}

@article{carlini2022quantifying,
  title={Quantifying memorization across neural language models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2202.07646},
  year={2022}
}

@inproceedings{brown2022does,
  title={What Does it Mean for a Language Model to Preserve Privacy?},
  author={Brown, Hannah and Lee, Katherine and Mireshghallah, Fatemehsadat and Shokri, Reza and Tram{\`e}r, Florian},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={2280--2292},
  year={2022}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr}
}

@article{hendrycks2019using,
  title={Using self-supervised learning can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Mazeika, Mantas and Kadavath, Saurav and Song, Dawn},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{watson2021importance,
  title={On the importance of difficulty calibration in membership inference attacks},
  author={Watson, Lauren and Guo, Chuan and Cormode, Graham and Sablayrolles, Alex},
  journal={arXiv preprint arXiv:2111.08440},
  year={2021}
}

@article{ye2021enhanced,
  title={Enhanced membership inference attacks against machine learning models},
  author={Ye, Jiayuan and Maddi, Aadyaa and Murakonda, Sasi Kumar and Bindschaedler, Vincent and Shokri, Reza},
  journal={arXiv preprint arXiv:2111.09679},
  year={2021}
}

@article{LARS,
  title={Large batch training of convolutional networks},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inbook{pytorch,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K\"{o}pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {721},
numpages = {12}
}

@misc{demo,
  doi = {10.48550/ARXIV.2303.01986},
  url = {https://arxiv.org/abs/2303.01986},
  author = {Bordes, Florian and Balestriero, Randall and Vincent, Pascal},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Towards Democratizing Joint-Embedding Self-Supervised Learning},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{google_diffusion,
  title={Extracting training data from diffusion models},
  author={Carlini, Nicholas and Hayes, Jamie and Nasr, Milad and Jagielski, Matthew and Sehwag, Vikash and Tramer, Florian and Balle, Borja and Ippolito, Daphne and Wallace, Eric},
  journal={arXiv preprint arXiv:2301.13188},
  year={2023}
}

@inproceedings{goodfellow,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{kingma,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{salimans,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={Advances in neural information processing systems},
  pages={2234--2242},
  year={2016}
}

@article{lopez,
  title={Revisiting classifier two-sample tests},
  author={Lopez-Paz, David and Oquab, Maxime},
  journal={arXiv preprint arXiv:1610.06545},
  year={2016}
}

@inproceedings{richardson,
  title={On gans and gmms},
  author={Richardson, Eitan and Weiss, Yair},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5847--5858},
  year={2018}
}

@article{heusel,
	Author = {Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
	Title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
	Year = {2017},
	Eprint = {arXiv:1706.08500},
	Howpublished = {Advances in Neural Information Processing Systems 31 (NIPS 2017)},
}

@misc{mehdi,
	Author = {Mehdi S. M. Sajjadi and Olivier Bachem and Mario Lucic and Olivier Bousquet and Sylvain Gelly},
	Title = {Assessing Generative Models via Precision and Recall},
	Year = {2018},
	Eprint = {arXiv:1806.00035},
	Howpublished = {Advances in Neural Information Processing Systems 31 (NIPS 2017)}
}

@article{lecun,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@inproceedings{zhang,
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={CVPR},
  year={2018}
}

@misc{BigGan,
Author = {Andrew Brock and Jeff Donahue and Karen Simonyan},
Title = {Large Scale GAN Training for High Fidelity Natural Image Synthesis},
Year = {2018},
Eprint = {arXiv:1809.11096},
}

@article{imagenet12,
    Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
    Title = {{ImageNet Large Scale Visual Recognition Challenge}},
    Year = {2015},
    journal   = {International Journal of Computer Vision (IJCV)},
    doi = {10.1007/s11263-015-0816-y},
    volume={115},
    number={3},
    pages={211-252}
}

@article{Kilian,
  title={An empirical study on evaluation metrics of generative adversarial networks},
  author={Xu, Qiantong and Huang, Gao and Yuan, Yang and Guo, Chuan and Sun, Yu and Wu, Felix and Weinberger, Kilian},
  journal={arXiv preprint arXiv:1806.07755},
  year={2018}
}

@article{mannwhitney,
  title={On a test of whether one of two random variables is stochastically larger than the other},
  author={Mann, Henry B and Whitney, Donald R},
  journal={The annals of mathematical statistics},
  pages={50--60},
  year={1947},
  publisher={JSTOR}
}

@article{VAEs_overfit,
  title={Can VAEs Generate Novel Examples?},
  author={Bozkurt, Alican and Esmaeili, Babak and Brooks, Dana H and Dy, Jennifer G and van de Meent, Jan-Willem},
  Howpublished = {Advances in Neural Information Processing Systems 32 (NIPS 2018)},
  year={2018}
}

@inproceedings{Ruslan_et_al,
  author    = {Yuhuai Wu and
               Yuri Burda and
               Ruslan Salakhutdinov and
               Roger B. Grosse},
  title     = {On the Quantitative Analysis of Decoder-Based Generative Models},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  year      = {2017},
  crossref  = {DBLP:conf/iclr/2017},
  url       = {https://openreview.net/forum?id=B1M8JF9xx},
  timestamp = {Thu, 25 Jul 2019 14:25:51 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/iclr/WuBSG17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Kynk_improved,
	author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
	title={Improved precision and recall metric for assessing generative models},
	Year = {2019},
	Eprint =  {arXiv:1904.06991v2},
	Howpublished = {Advances in Neural Information Processing Systems 33 (NIPS 2019)}
}

@article{che_2016,
  author    = {Tong Che and
               Yanran Li and
               Athul Paul Jacob and
               Yoshua Bengio and
               Wenjie Li},
  title     = {Mode Regularized Generative Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1612.02136},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.02136},
  archivePrefix = {arXiv},
  eprint    = {1612.02136},
  timestamp = {Mon, 13 Aug 2018 16:49:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/CheLJBL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{gretton,
  author    = {Dougal J. Sutherland and
               Hsiao{-}Yu Fish Tung and
               Heiko Strathmann and
               Soumyajit De and
               Aaditya Ramdas and
               Alexander J. Smola and
               Arthur Gretton},
  title     = {Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy},
  journal   = {CoRR},
  volume    = {abs/1611.04488},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.04488},
  archivePrefix = {arXiv},
  eprint    = {1611.04488},
  timestamp = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SutherlandTSDRS16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{theis,
  author    = {Lucas Theis and
               A{\"{a}}ron van den Oord and
               Matthias Bethge},
  title     = {A note on the evaluation of generative models},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  crossref  = {DBLP:conf/iclr/2016},
  url       = {http://arxiv.org/abs/1511.01844},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/TheisOB15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gretton_2,
  author    = {Wacha Bounliphone and
               Eugene Belilovsky and
               Matthew B. Blaschko and
               Ioannis Antonoglou and
               Arthur Gretton},
  title     = {A Test of Relative Similarity For Model Selection in Generative Models},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  crossref  = {DBLP:conf/iclr/2016},
  url       = {http://arxiv.org/abs/1511.04581},
  timestamp = {Thu, 25 Jul 2019 14:25:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/BounliphoneBBAG15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GAN_benchmarks,
  author    = {Ishaan Gulrajani and
               Colin Raffel and
               Luke Metz},
  title     = {Towards {GAN} Benchmarks Which Require Generalization},
  journal   = {CoRR},
  volume    = {abs/2001.03653},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.03653},
  archivePrefix = {arXiv},
  eprint    = {2001.03653},
  timestamp = {Fri, 17 Jan 2020 14:07:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2001-03653.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{latent_recovery,
  author    = {Ryan Webster and
               Julien Rabin and
               Lo{\"{\i}}c Simon and
               Fr{\'{e}}d{\'{e}}ric Jurie},
  title     = {Detecting Overfitting of Deep Generative Networks via Latent Recovery},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2019, Long Beach, CA, USA, June 16-20, 2019},
  pages     = {11273--11282},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019},
  url       = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Webster\_Detecting\_Overfitting\_of\_Deep\_Generative\_Networks\_via\_Latent\_Recovery\_CVPR\_2019\_paper.html},
  doi       = {10.1109/CVPR.2019.01153},
  timestamp = {Mon, 20 Jan 2020 15:36:04 +0100},
  biburl    = {https://dblp.org/rec/conf/cvpr/WebsterRSJ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{reviewer_paper,
  title={Real-valued (medical) time series generation with recurrent conditional gans},
  author={Esteban, Crist{\'o}bal and Hyland, Stephanie L and R{\"a}tsch, Gunnar},
  journal={arXiv preprint arXiv:1706.02633},
  year={2017}
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{metricdp,
	title = {Privacy- and {Utility}-{Preserving} {Textual} {Analysis} via {Calibrated} {Multivariate} {Perturbations}},
	url = {https://arxiv.org/abs/1910.08902v1},
	language = {en},
	urldate = {2021-10-13},
	author = {Feyisetan, Oluwaseyi and Balle, Borja and Drake, Thomas and Diethe, Tom},
	month = oct,
	year = {2019}
}

@article{DPbook,
  title={The algorithmic foundations of differential privacy.},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Found. Trends Theor. Comput. Sci.},
  volume={9},
  number={3-4},
  pages={211--407},
  year={2014}
}

@inproceedings{mrini-etal-2021-recursive,
    title = "Recursive Tree-Structured Self-Attention for Answer Sentence Selection",
    author = "Mrini, Khalil  and
      Farcas, Emilia  and
      Nakashole, Ndapa",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.358",
    doi = "10.18653/v1/2021.acl-long.358",
    pages = "4651--4661",
    abstract = "Syntactic structure is an important component of natural language text. Recent top-performing models in Answer Sentence Selection (AS2) use self-attention and transfer learning, but not syntactic structure. Tree structures have shown strong performance in tasks with sentence pair input like semantic relatedness. We investigate whether tree structures can boost performance in AS2. We introduce the Tree Aggregation Transformer: a novel recursive, tree-structured self-attention model for AS2. The recursive nature of our model is able to represent all levels of syntactic parse trees with only one additional self-attention layer. Without transfer learning, we establish a new state of the art on the popular TrecQA and WikiQA benchmark datasets. Additionally, we evaluate our method on four Community Question Answering datasets, and find that tree-structured representations have limitations with noisy user-generated text. We conduct probing experiments to evaluate how our models leverage tree structures across datasets. Our findings show that the ability of tree-structured models to successfully absorb syntactic information is strongly correlated with a higher performance in AS2.",
}



@book{DP,
	title = {Differential {Privacy}},
	volume = {4052},
	isbn = {978-3-540-35907-4},
	url = {https://www.microsoft.com/en-us/research/publication/differential-privacy/},
	abstract = {In 1977 Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a formalization of Dalenius’ goal along the lines of semantic security cannot be achieved. Contrary to intuition, a variant …},
	language = {en-US},
	urldate = {2020-04-12},
	author = {Dwork, Cynthia},
	month = jul,
	year = {2006},
	annote = {Original DP paper.
Way too cryptographic},
	file = {Snapshot:/Users/casey/Zotero/storage/VG5FK8TD/differential-privacy.html:text/html;Full Text PDF:/Users/casey/Zotero/storage/7VQFV7EL/Dwork - 2006 - Differential Privacy.pdf:application/pdf},
}


@incollection{ldp,
	address = {Berlin, Heidelberg},
	title = {Our {Data}, {Ourselves}: {Privacy} {Via} {Distributed} {Noise} {Generation}},
	volume = {4004},
	isbn = {978-3-540-34546-6 978-3-540-34547-3},
	shorttitle = {Our {Data}, {Ourselves}},
	url = {http://link.springer.com/10.1007/11761679_29},
	language = {en},
	urldate = {2020-04-13},
	booktitle = {Advances in {Cryptology} - {EUROCRYPT} 2006},
	publisher = {Springer Berlin Heidelberg},
	author = {Dwork, Cynthia and Kenthapadi, Krishnaram and McSherry, Frank and Mironov, Ilya and Naor, Moni},
	editor = {Vaudenay, Serge},
	year = {2006},
	doi = {10.1007/11761679_29},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {differential privacy},
	pages = {486--503},
	annote = {Proposes local DP. Much like randomized response.},
}

@inproceedings{tukeydepth,
  title={Mathematics and the picturing of data},
  author={Tukey, John W},
  booktitle={Proceedings of the International Congress of Mathematicians, Vancouver, 1975},
  volume={2},
  pages={523--531},
  year={1975}
}

@inproceedings{optimal_tukey,
  title={An optimal randomized algorithm for maximum Tukey depth.},
  author={Chan, Timothy M},
  booktitle={SODA},
  volume={4},
  pages={430--436},
  year={2004}
}


@inproceedings{kamath_high_dim,
	title = {Privately {Learning} {High}-{Dimensional} {Distributions}},
	url = {http://proceedings.mlr.press/v99/kamath19a.html},
	language = {en},
	urldate = {2021-07-27},
	booktitle = {Conference on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Kamath, Gautam and Li, Jerry and Singhal, Vikrant and Ullman, Jonathan},
	month = jun,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {1853--1902},
	file = {Full Text PDF:/Users/casey/Zotero/storage/IRE84K3W/Kamath et al. - 2019 - Privately Learning High-Dimensional Distributions.pdf:application/pdf},
}


@inproceedings{mdp_low_dim,
  title={Private Release of Text Embedding Vectors},
  author={Feyisetan, Oluwaseyi and Kasiviswanathan, Shiva},
  booktitle={Proceedings of the First Workshop on Trustworthy Natural Language Processing},
  pages={15--27},
  year={2021}
}


@inproceedings{DP_compression,
	title = {Differential privacy with compression},
	doi = {10.1109/ISIT.2009.5205863},
	abstract = {This work studies formal utility and privacy guarantees for a simple multiplicative database transformation, where the data are compressed by a random linear or affine transformation, reducing the number of data records substantially, while preserving the number of original input variables.We provide an analysis framework inspired by a recent concept known as differential privacy. Our goal is to show that, despite the general difficulty of achieving the differential privacy guarantee, it is possible to publish synthetic data that are useful for a number of common statistical learning applications. This includes high dimensional sparse regression, principal component analysis (PCA), and other statistical measures based on the covariance of the initial data.},
	booktitle = {2009 {IEEE} {International} {Symposium} on {Information} {Theory}},
	author = {Zhou, Shuheng and Ligett, Katrina and Wasserman, Larry},
	month = jun,
	year = {2009},
	note = {ISSN: 2157-8117},
	keywords = {data privacy, Data privacy, Databases, Statistics, Computer science, Additive noise, affine transformation, affine transforms, Covariance matrix, database management systems, differential privacy guarantee, formal utility, high dimensional sparse regression, multiplicative database transformation, principal component analysis, Principal component analysis, random linear transformation, Random variables, regression analysis, Seminars, statistical learning, Statistical learning},
	pages = {2718--2722},
	file = {Accepted Version:/Users/casey/Zotero/storage/DMLWQXA5/Zhou et al. - 2009 - Differential privacy with compression.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/casey/Zotero/storage/NJJ8IXXA/5205863.html:text/html},
}


@inproceedings{orig_metricdp,
	title = {Invited {Paper}: {Local} {Differential} {Privacy} on {Metric} {Spaces}: {Optimizing} the {Trade}-{Off} with {Utility}},
	shorttitle = {Invited {Paper}},
	doi = {10.1109/CSF.2018.00026},
	abstract = {Local differential privacy (LPD) is a distributed variant of differential privacy (DP) in which the obfuscation of the sensitive information is done at the level of the individual records, and in general it is used to sanitize data that are collected for statistical purposes. LPD has the advantage it does not need to assume a trusted third party. On the other hand LDP in general requires more noise than DP to achieve the same level of protection, with negative consequences on the utility. In practice, utility becomes acceptable only on very large collections of data, and this is the reason why LDP is especially successful among big companies such as Apple and Google, which can count on a huge number of users. In this talk, we propose a variant of LDP suitable for metric spaces, such as location data or energy consumption data, and we show that it provides a much higher utility for the same level of privacy. Furthermore, we discuss algorithms to extract the best possible statistical information from the data obfuscated with this metric variant of LDP.},
	booktitle = {2018 {IEEE} 31st {Computer} {Security} {Foundations} {Symposium} ({CSF})},
	author = {Alvim, Mário and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia and Pazii, Anna},
	month = jul,
	year = {2018},
	note = {ISSN: 2374-8303},
	keywords = {Distributed databases, Local-differential-privacy,-dX–privacy,-Kantorovich-lifting., Measurement, Privacy, Smart meters},
	pages = {262--267},
	file = {IEEE Xplore Full Text PDF:/Users/casey/Zotero/storage/2FQSGZPN/Alvim et al. - 2018 - Invited Paper Local Differential Privacy on Metri.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/casey/Zotero/storage/RZL8XNKF/8429310.html:text/html},
}


@article{clifton,
	title = {Differentially {Private} {Imaging} via {Latent} {Space} {Manipulation}},
	url = {http://arxiv.org/abs/2103.05472},
	abstract = {There is growing concern about image privacy due to the popularity of social media and photo devices, along with increasing use of face recognition systems. However, established image de-identification techniques are either too subject to re-identification, produce photos that are insufficiently realistic, or both. To tackle this, we present a novel approach for image obfuscation by manipulating latent spaces of an unconditionally trained generative model that is able to synthesize photo-realistic facial images of high resolution. This manipulation is done in a way that satisfies the formal privacy standard of local differential privacy. To our knowledge, this is the first approach to image privacy that satisfies \${\textbackslash}varepsilon\$-differential privacy {\textbackslash}emph\{for the person.\}},
	urldate = {2021-05-04},
	journal = {arXiv:2103.05472 [cs]},
	author = {Li, Tao and Clifton, Chris},
	month = apr,
	year = {2021},
	note = {arXiv: 2103.05472},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/ERAZN7FB/Li and Clifton - 2021 - Differentially Private Imaging via Latent Space Ma.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/X3UH5IPM/2103.html:text/html},
}


@article{abadi,
	title = {Deep {Learning} with {Differential} {Privacy}},
	url = {http://arxiv.org/abs/1607.00133},
	doi = {10.1145/2976749.2978318},
	abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
	urldate = {2020-05-12},
	journal = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
	author = {Abadi, Martín and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
	month = oct,
	year = {2016},
	note = {arXiv: 1607.00133},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {308--318},
	file = {arXiv.org Snapshot:/Users/casey/Zotero/storage/NAE4MA8G/1607.html:text/html;arXiv Fulltext PDF:/Users/casey/Zotero/storage/JS3QK5PP/Abadi et al. - 2016 - Deep Learning with Differential Privacy.pdf:application/pdf},
}


@inproceedings{tukey_props,
	address = {Los Angeles, CA, USA},
	title = {When does the {Tukey} {Median} work?},
	isbn = {978-1-72816-432-8},
	url = {https://ieeexplore.ieee.org/document/9173995/},
	doi = {10.1109/ISIT44484.2020.9173995},
	abstract = {We analyze the performance of the Tukey median estimator under total variation (TV) distance corruptions. Previous results show that under Huber’s additive corruption model, the breakdown point is 1/3 for high-dimensional halfspacesymmetric distributions. We show that under TV corruptions, the breakdown point reduces to 1/4 for the same set of distributions. We also show that a certain projection algorithm can attain the optimal breakdown point of 1/2. Both the Tukey median estimator and the projection algorithm achieve sample complexity linear in dimension.},
	language = {en},
	urldate = {2021-11-03},
	booktitle = {2020 {IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	publisher = {IEEE},
	author = {Zhu, Banghua and Jiao, Jiantao and Steinhardt, Jacob},
	month = jun,
	year = {2020},
	pages = {1201--1206},
	annote = {Clarifies when tukey median contains mean},
	file = {Zhu et al. - 2020 - When does the Tukey Median work.pdf:/Users/casey/Zotero/storage/KKW2PGDN/Zhu et al. - 2020 - When does the Tukey Median work.pdf:application/pdf},
}


@article{median_hyp,
	title = {The {Median} {Hypothesis}},
	url = {https://www.microsoft.com/en-us/research/publication/the-median-hypothesis/},
	abstract = {A typical learning process begins with some prior beliefs about the target concept. These beliefs are rened using evidence, typically a sample. The evidence is used to compute a posterior belief, which assigns a probability distribution over the hypothesis class F. Using the posterior, a hypothesis is selected to predict the labels during the generalization […]},
	language = {en-US},
	urldate = {2021-08-12},
	author = {Gilad-Bachrach, Ran and Burges, Chris J. C.},
	month = jun,
	year = {2012},
	file = {Full Text PDF:/Users/casey/Zotero/storage/4G8GKT7N/Gilad-Bachrach and Burges - 2012 - The Median Hypothesis.pdf:application/pdf;Snapshot:/Users/casey/Zotero/storage/74XU4DI8/the-median-hypothesis.html:text/html},
}


@article{sbert,
	title = {Sentence-{BERT}: {Sentence} {Embeddings} using {Siamese} {BERT}-{Networks}},
	shorttitle = {Sentence-{BERT}},
	url = {http://arxiv.org/abs/1908.10084},
	abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
	urldate = {2021-06-16},
	journal = {arXiv:1908.10084 [cs]},
	author = {Reimers, Nils and Gurevych, Iryna},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.10084},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Published at EMNLP 2019},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/ANYCUKXE/Reimers and Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/JU2UW8BA/1908.html:text/html},
}

@inproceedings{goodreads,
  author    = {Mengting Wan and
               Julian J. McAuley},
  editor    = {Sole Pera and
               Michael D. Ekstrand and
               Xavier Amatriain and
               John O'Donovan},
  title     = {Item recommendation on monotonic behavior chains},
  booktitle = {Proceedings of the 12th {ACM} Conference on Recommender Systems, RecSys
               2018, Vancouver, BC, Canada, October 2-7, 2018},
  pages     = {86--94},
  publisher = {{ACM}},
  year      = {2018},
  url       = {https://doi.org/10.1145/3240323.3240369},
  doi       = {10.1145/3240323.3240369},
  timestamp = {Mon, 22 Jul 2019 19:11:02 +0200},
  biburl    = {https://dblp.org/rec/conf/recsys/WanM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{20newsgroup,
	title = {Home {Page} for 20 {Newsgroups} {Data} {Set}},
	url = {http://qwone.com/~jason/20Newsgroups/},
	urldate = {2021-11-15},
	file = {Home Page for 20 Newsgroups Data Set:/Users/casey/Zotero/storage/5NLK944Q/20Newsgroups.html:text/html},
	author = {Lang, Ken}, 
	year = {1995}
}

@InProceedings{imdb,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@inproceedings{alsentzer2019publicly,
  title={Publicly Available Clinical BERT Embeddings},
  author={Alsentzer, Emily and Murphy, John and Boag, William and Weng, Wei-Hung and Jindi, Di and Naumann, Tristan and McDermott, Matthew},
  booktitle={Proceedings of the 2nd Clinical Natural Language Processing Workshop},
  pages={72--78},
  year={2019}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{li2020sentence,
  title={On the sentence embeddings from BERT for semantic textual similarity},
  author={Li, Bohan and Zhou, Hao and He, Junxian and Wang, Mingxuan and Yang, Yiming and Li, Lei},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9119--9130},
  year={2020}
}

@inproceedings{gupta2019better,
  title={Better Word Embeddings by Disentangling Contextual n-Gram Information},
  author={Gupta, Prakhar and Pagliardini, Matteo and Jaggi, Martin},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={933--939},
  year={2019}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@inproceedings{thongtan2019sentiment,
  title={Sentiment classification using document embeddings trained with cosine similarity},
  author={Thongtan, Tan and Phienthrakul, Tanasanee},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop},
  pages={407--414},
  year={2019}
}

@article{bianchi2020pre,
  title={Pre-training is a hot topic: Contextualized document embeddings improve topic coherence},
  author={Bianchi, Federico and Terragni, Silvia and Hovy, Dirk},
  journal={arXiv preprint arXiv:2004.03974},
  year={2020}
}

@inproceedings{yang2016hierarchical,
  title={Hierarchical attention networks for document classification},
  author={Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
  booktitle={Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies},
  pages={1480--1489},
  year={2016}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}

@inproceedings{huang-etal-2020-texthide,
    title = "{T}ext{H}ide: Tackling Data Privacy in Language Understanding Tasks",
    author = "Huang, Yangsibo  and
      Song, Zhao  and
      Chen, Danqi  and
      Li, Kai  and
      Arora, Sanjeev",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.123",
    doi = "10.18653/v1/2020.findings-emnlp.123",
    pages = "1368--1382",
    abstract = "An unsolved challenge in distributed or federated learning is to effectively mitigate privacy risks without slowing down training or reducing accuracy. In this paper, we propose TextHide aiming at addressing this challenge for natural language understanding tasks. It requires all participants to add a simple encryption step to prevent an eavesdropping attacker from recovering private text data. Such an encryption step is efficient and only affects the task performance slightly. In addition, TextHide fits well with the popular framework of fine-tuning pre-trained language models (e.g., BERT) for any sentence or sentence-pair task. We evaluate TextHide on the GLUE benchmark, and our experiments show that TextHide can effectively defend attacks on shared gradients or representations and the averaged accuracy reduction is only 1.9{\%}. We also present an analysis of the security of TextHide using a conjecture about the computational intractability of a mathematical problem.",
}

@inproceedings{xie2021reconstruction,
  title={Reconstruction Attack on Instance Encoding for Language Understanding},
  author={Xie, Shangyu and Hong, Yuan},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={2038--2044},
  year={2021}
}

@inproceedings{pan2020privacy,
  title={Privacy risks of general-purpose language models},
  author={Pan, Xudong and Zhang, Mi and Ji, Shouling and Yang, Min},
  booktitle={2020 IEEE Symposium on Security and Privacy (SP)},
  pages={1314--1331},
  year={2020},
  organization={IEEE}
}

@inproceedings{yenicelik2020does,
  title={How does BERT capture semantics? A closer look at polysemous words},
  author={Yenicelik, David and Schmidt, Florian and Kilcher, Yannic},
  booktitle={Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  pages={156--162},
  year={2020}
}


@inproceedings{strubell2018linguistically,
  title={Linguistically-Informed Self-Attention for Semantic Role Labeling},
  author={Strubell, Emma and Verga, Patrick and Andor, Daniel and Weiss, David and McCallum, Andrew},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={5027--5038},
  year={2018}
}

@inproceedings{liu2019multi,
  title={Multi-Task Deep Neural Networks for Natural Language Understanding},
  author={Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4487--4496},
  year={2019}
}

@inproceedings{jawahar2019does,
  title={What does BERT learn about the structure of language?},
  author={Jawahar, Ganesh and Sagot, Beno{\^\i}t and Seddah, Djam{\'e}},
  booktitle={ACL 2019-57th Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}


@article{exp_mech,
	title = {Mechanism {Design} via {Differential} {Privacy}},
	url = {https://www.microsoft.com/en-us/research/publication/mechanism-design-via-differential-privacy/},
	abstract = {We study the role that privacy-preserving algorithms, which prevent the leakage of speciﬁc information about participants, can play in the design of mechanisms for strategic agents, which must encourage players to honestly report information. Speciﬁcally, we show that the recent notion of differential privacy [15, 14], in addition to its own intrinsic virtue, can ensure …},
	language = {en-US},
	urldate = {2020-04-12},
	author = {McSherry, Frank and Talwar, Kunal},
	month = oct,
	year = {2007},
	annote = {Discusses composition and post-processing properties of DP
 },
	file = {Snapshot:/Users/casey/Zotero/storage/UM45NJXT/mechanism-design-via-differential-privacy.html:text/html;Full Text PDF:/Users/casey/Zotero/storage/CAUNX7CZ/McSherry and Talwar - 2007 - Mechanism Design via Differential Privacy.pdf:application/pdf},
}

@article{TEM,
  title={TEM: High Utility Metric Differential Privacy on Text},
  author={Carvalho, Ricardo Silva and Vasiloudis, Theodore and Feyisetan, Oluwaseyi},
  journal={arXiv preprint arXiv:2107.07928},
  year={2021}
}


@article{attack_word_embs,
	title = {Exploring the {Privacy}-{Preserving} {Properties} of {Word} {Embeddings}: {Algorithmic} {Validation} {Study}},
	volume = {22},
	issn = {1438-8871},
	shorttitle = {Exploring the {Privacy}-{Preserving} {Properties} of {Word} {Embeddings}},
	url = {https://www.jmir.org/2020/7/e18055},
	doi = {10.2196/18055},
	abstract = {Background: Word embeddings are dense numeric vectors used to represent language in neural networks. Until recently, there had been no publicly released embeddings trained on clinical data. Our work is the first to study the privacy implications of releasing these models.
Objective: This paper aims to demonstrate that traditional word embeddings created on clinical corpora that have been deidentified by removing personal health information (PHI) can nonetheless be exploited to reveal sensitive patient information.
Methods: We used embeddings created from 400,000 doctor-written consultation notes and experimented with 3 common word embedding methods to explore the privacy-preserving properties of each.
Results: We found that if publicly released embeddings are trained from a corpus anonymized by PHI removal, it is possible to reconstruct up to 68.5\% (n=411/600) of the full names that remain in the deidentified corpus and associated sensitive information to specific patients in the corpus from which the embeddings were created. We also found that the distance between the word vector representation of a patient’s name and a diagnostic billing code is informative and differs significantly from the distance between the name and a code not billed for that patient.
Conclusions: Special care must be taken when sharing word embeddings created from clinical texts, as current approaches may compromise patient privacy. If PHI removal is used for anonymization before traditional word embeddings are trained, it is possible to attribute sensitive information to patients who have not been fully deidentified by the (necessarily imperfect) removal algorithms. A promising alternative (ie, anonymization by PHI replacement) may avoid these flaws. Our results are timely and critical, as an increasing number of researchers are pushing for publicly available health data.},
	language = {en},
	number = {7},
	urldate = {2021-06-16},
	journal = {Journal of Medical Internet Research},
	author = {Abdalla, Mohamed and Abdalla, Moustafa and Hirst, Graeme and Rudzicz, Frank},
	month = jul,
	year = {2020},
	pages = {e18055},
	file = {Abdalla et al. - 2020 - Exploring the Privacy-Preserving Properties of Wor.pdf:/Users/casey/Zotero/storage/7AX9YN83/Abdalla et al. - 2020 - Exploring the Privacy-Preserving Properties of Wor.pdf:application/pdf},
}


@article{another_metric_DP,
	title = {Privacy-{Adaptive} {BERT} for {Natural} {Language} {Understanding}},
	url = {http://arxiv.org/abs/2104.07504},
	abstract = {When trying to apply the recent advance of Natural Language Understanding (NLU) technologies to real-world applications, privacy preservation imposes a crucial challenge, which, unfortunately, has not been well resolved. To address this issue, we study how to improve the effectiveness of NLU models under a Local Privacy setting, using BERT [9], a widely-used pretrained Language Model (LM), as an example. We systematically study the strengths and weaknesses of imposing ������ ������-privacy [12], a relaxed variant of Local Differential Privacy, at different stages of language modeling: input text, token embeddings, and sequence representations. We then focus on the former two with privacy-constrained fine-tuning experiments to reveal the utility of BERT under local privacy constraints. More importantly, to the best of our knowledge, we are the first to propose privacy-adaptive LM pretraining methods and demonstrate that they can significantly improve model performance on privatized text input. We also interpret the level of privacy preservation and provide our guidance on privacy parameter selections.},
	language = {en},
	urldate = {2021-06-09},
	journal = {arXiv:2104.07504 [cs]},
	author = {Qu, Chen and Kong, Weize and Yang, Liu and Zhang, Mingyang and Bendersky, Michael and Najork, Marc},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.07504},
	keywords = {Computer Science - Computation and Language},
	file = {Qu et al. - 2021 - Privacy-Adaptive BERT for Natural Language Underst.pdf:/Users/casey/Zotero/storage/3J4CDYJN/Qu et al. - 2021 - Privacy-Adaptive BERT for Natural Language Underst.pdf:application/pdf},
}


@article{carlini_attack,
	title = {Extracting {Training} {Data} from {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2012.07805},
	abstract = {It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model. We demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data. We comprehensively evaluate our extraction attack to understand the factors that contribute to its success. For example, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.},
	urldate = {2021-06-09},
	journal = {arXiv:2012.07805 [cs]},
	author = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and Oprea, Alina and Raffel, Colin},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.07805},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/IBTBC44K/Carlini et al. - 2020 - Extracting Training Data from Large Language Model.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/4IXVKUHQ/2012.html:text/html},
}


@article{attack_on_embeddings,
	title = {Information {Leakage} in {Embedding} {Models}},
	url = {http://arxiv.org/abs/2004.00053},
	abstract = {Embeddings are functions that map raw input data to low-dimensional vector representations, while preserving important semantic information about the inputs. Pre-training embeddings on a large amount of unlabeled data and fine-tuning them for downstream tasks is now a de facto standard in achieving state of the art learning in many domains. We demonstrate that embeddings, in addition to encoding generic semantics, often also present a vector that leaks sensitive information about the input data. We develop three classes of attacks to systematically study information that might be leaked by embeddings. First, embedding vectors can be inverted to partially recover some of the input data. As an example, we show that our attacks on popular sentence embeddings recover between 50{\textbackslash}\%--70{\textbackslash}\% of the input words (F1 scores of 0.5--0.7). Second, embeddings may reveal sensitive attributes inherent in inputs and independent of the underlying semantic task at hand. Attributes such as authorship of text can be easily extracted by training an inference model on just a handful of labeled embedding vectors. Third, embedding models leak moderate amount of membership information for infrequent training data inputs. We extensively evaluate our attacks on various state-of-the-art embedding models in the text domain. We also propose and evaluate defenses that can prevent the leakage to some extent at a minor cost in utility.},
	urldate = {2021-06-09},
	journal = {arXiv:2004.00053 [cs, stat]},
	author = {Song, Congzheng and Raghunathan, Ananth},
	month = aug,
	year = {2020},
	note = {arXiv: 2004.00053},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/27XDU35A/Song and Raghunathan - 2020 - Information Leakage in Embedding Models.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/IC82WUA2/2004.html:text/html},
}


@article{fancy_metricdp,
	title = {Differential {Privacy} for {Text} {Analytics} via {Natural} {Text} {Sanitization}},
	url = {http://arxiv.org/abs/2106.01221},
	abstract = {Texts convey sophisticated knowledge. However, texts also convey sensitive information. Despite the success of general-purpose language models and domain-specific mechanisms with differential privacy (DP), existing text sanitization mechanisms still provide low utility, as cursed by the high-dimensional text representation. The companion issue of utilizing sanitized texts for downstream analytics is also under-explored. This paper takes a direct approach to text sanitization. Our insight is to consider both sensitivity and similarity via our new local DP notion. The sanitized texts also contribute to our sanitization-aware pretraining and fine-tuning, enabling privacy-preserving natural language processing over the BERT language model with promising utility. Surprisingly, the high utility does not boost up the success rate of inference attacks.},
	urldate = {2021-06-09},
	journal = {arXiv:2106.01221 [cs]},
	author = {Yue, Xiang and Du, Minxin and Wang, Tianhao and Li, Yaliang and Sun, Huan and Chow, Sherman S. M.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.01221},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Computation and Language},
	annote = {Comment: ACL-ICJNLP'21 Findings; The first two authors contributed equally},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/D3JRBRR7/Yue et al. - 2021 - Differential Privacy for Text Analytics via Natura.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/J8S8VM4G/2106.html:text/html},
}


@article{DP_training,
	title = {Differentially {Private} {Language} {Models} {Benefit} from {Public} {Pre}-training},
	url = {http://arxiv.org/abs/2009.05886},
	abstract = {Language modeling is a keystone task in natural language processing. When training a language model on sensitive information, differential privacy (DP) allows us to quantify the degree to which our private data is protected. However, training algorithms which enforce differential privacy often lead to degradation in model quality. We study the feasibility of learning a language model which is simultaneously high-quality and privacy preserving by tuning a public base model on a private corpus. We find that DP fine-tuning boosts the performance of language models in the private domain, making the training of such models possible.},
	urldate = {2021-06-15},
	journal = {arXiv:2009.05886 [cs]},
	author = {Kerrigan, Gavin and Slack, Dylan and Tuyls, Jens},
	month = oct,
	year = {2020},
	note = {arXiv: 2009.05886},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/LZD3RNSS/Kerrigan et al. - 2020 - Differentially Private Language Models Benefit fro.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/JU5SRJH6/2009.html:text/html},
}

@article{DP_training_II,
  title={Differential privacy has disparate impact on model accuracy},
  author={Bagdasaryan, Eugene and Poursaeed, Omid and Shmatikov, Vitaly},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={15479--15488},
  year={2019}
}


@article{metricDP_gumbel,
	title = {Density-{Aware} {Differentially} {Private} {Textual} {Perturbations} {Using} {Truncated} {Gumbel} {Noise}},
	volume = {34},
	issn = {2334-0762},
	url = {https://journals.flvc.org/FLAIRS/article/view/128463},
	doi = {10.32473/flairs.v34i1.128463},
	abstract = {Deep Neural Networks, despite their success in diverse domains, are provably sensitive to small perturbations which cause the models to return erroneous predictions to minor transformations. Recently, it was proposed that this effect can be addressed in the text domain by optimizing for the worst case loss function over all possible word substitutions within the training examples. However, this approach is prone to weighing semantically unlikely word replacements higher, resulting in accuracy loss. In this paper, we study robustness to adversarial perturbations by using differentially private randomized substitutions while training the model. This approach has two immediate advantages: (1) by ensuring that the word replacement likelihood is weighted by its proximity to the original word in a metric space, we circumvent optimizing for worst case guarantees thereby achieve performance gains; and (2) the calibrated randomness results in training a privacy preserving model, while also guaranteeing robustness against adversarial attacks on the model outputs. Our approach uses a novel density-based differentially private mechanism based on truncated Gumbel noise. This ensures training on substitutions of words in dense and sparse regions of a metric space while maintaining semantic similarity for model robustness. Our experiments on two datasets suggest an improvement of up to 10\% on the accuracy metrics.},
	language = {en},
	number = {1},
	urldate = {2021-11-15},
	journal = {The International FLAIRS Conference Proceedings},
	author = {Xu, Nan and Feyisetan, Oluwaseyi and Aggarwal, Abhinav and Xu, Zekun and Teissier, Nathanael},
	month = apr,
	year = {2021},
	file = {Xu et al. - 2021 - Density-Aware Differentially Private Textual Pertu.pdf:/Users/casey/Zotero/storage/UNYJYRHI/Xu et al. - 2021 - Density-Aware Differentially Private Textual Pertu.pdf:application/pdf},
}


@article{private_halfspaces,
	title = {Private {Center} {Points} and {Learning} of {Halfspaces}},
	url = {http://arxiv.org/abs/1902.10731},
	abstract = {We present a private learner for halfspaces over an arbitrary finite domain \$X{\textbackslash}subset {\textbackslash}mathbb\{R\}{\textasciicircum}d\$ with sample complexity \$mathrm\{poly\}(d,2{\textasciicircum}\{{\textbackslash}log{\textasciicircum}*{\textbar}X{\textbar}\})\$. The building block for this learner is a differentially private algorithm for locating an approximate center point of \$m{\textgreater}{\textbackslash}mathrm\{poly\}(d,2{\textasciicircum}\{{\textbackslash}log{\textasciicircum}*{\textbar}X{\textbar}\})\$ points -- a high dimensional generalization of the median function. Our construction establishes a relationship between these two problems that is reminiscent of the relation between the median and learning one-dimensional thresholds [Bun et al.{\textbackslash} FOCS '15]. This relationship suggests that the problem of privately locating a center point may have further applications in the design of differentially private algorithms. We also provide a lower bound on the sample complexity for privately finding a point in the convex hull. For approximate differential privacy, we show a lower bound of \$m={\textbackslash}Omega(d+{\textbackslash}log{\textasciicircum}*{\textbar}X{\textbar})\$, whereas for pure differential privacy \$m={\textbackslash}Omega(d{\textbackslash}log{\textbar}X{\textbar})\$.},
	urldate = {2021-07-30},
	journal = {arXiv:1902.10731 [cs, stat]},
	author = {Beimel, Amos and Moran, Shay and Nissim, Kobbi and Stemmer, Uri},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.10731},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computational Geometry},
	annote = {Comment: 14 pages},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/99NUB8R2/Beimel et al. - 2019 - Private Center Points and Learning of Halfspaces.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/99X9WZY4/1902.html:text/html},
}











@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}


@inproceedings{vicreg,
  author    = {Adrien Bardes and
               Jean Ponce and
               Yann LeCun},
  title     = {VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised
               Learning},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
  url       = {https://openreview.net/forum?id=xm6YD62D1Ub},
  timestamp = {Sat, 20 Aug 2022 01:15:42 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/BardesPL22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{simclr,
  author    = {Hui Zeng and
               Xiaohui Cui},
  title     = {SimCLRT: {A} Simple Framework for Contrastive Learning of Rumor Tracking},
  journal   = {Eng. Appl. Artif. Intell.},
  volume    = {110},
  pages     = {104757},
  year      = {2022},
  url       = {https://doi.org/10.1016/j.engappai.2022.104757},
  doi       = {10.1016/j.engappai.2022.104757},
  timestamp = {Fri, 13 May 2022 19:52:30 +0200},
  biburl    = {https://dblp.org/rec/journals/eaai/ZengC22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{
      RCDM,
      title={High Fidelity Visualization of What Your Self-Supervised Representation Knows About},
      author={Florian Bordes and Randall Balestriero and Pascal Vincent},
      journal={Transactions on Machine Learning Research},
      year={2022},
      url={https://openreview.net/forum?id=urfWb7VjmL},
      note={}
}

@InProceedings{MAE,
    author    = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll\'ar, Piotr and Girshick, Ross},
    title     = {Masked Autoencoders Are Scalable Vision Learners},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {16000-16009}
}

@inproceedings{Dino,
author = {Mathilde Caron and Hugo Touvron and Ishan Misra and Herve Jegou and Julien Mairal Piotr Bojanowski Armand Joulin},
title = {Emerging Properties in Self-Supervised Vision Transformers},
booktitle = {ICCV},
year = {2021}}

@inproceedings{chen2020simsiam,
author={Xinlei Chen and Kaiming He},
title={Exploring simple siamese representation learning},
booktitle={CVPR},
year={2020}}

@inproceedings{grill2020byol,
title={Bootstrap your own latent: A new approach to self-supervised Learning},
author={Jean-Bastien Grill and Florian Strub and Florent Altché and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and Rémi Munos and Michal Valko},
booktitle={NeurIPS},
year={2020}}

@inproceedings{chen2020simclr,
author={Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey E. Hinton},
title={A Simple Framework for Contrastive Learning of Visual Representations},
booktitle={ICML},
year={2020}}

@inproceedings{caron2020swav,
title={Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
author={Mathilde Caron and Ishan Misra and Julien Mairal and Priya Goyal and Piotr Bojanowski and Armand Joulin},
booktitle={NeurIPS},
year={2020}}

@article{zbontar2021barlow,
title={Barlow Twins: Self-Supervised Learning via Redundancy Reduction}, 
author={Jure Zbontar and Li Jing and Ishan Misra and Yann LeCun and Stéphane Deny},
journal={arXiv preprint arxiv:2103.03230},
year={2021}}

@misc{Guillotine,
  doi = {10.48550/ARXIV.2206.13378},
  
  url = {https://arxiv.org/abs/2206.13378},
  
  author = {Bordes, Florian and Balestriero, Randall and Garrido, Quentin and Bardes, Adrien and Vincent, Pascal},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Guillotine Regularization: Improving Deep Networks Generalization by Removing their Head},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@article{salem2018ml,
  title={Ml-leaks: Model and data independent membership inference attacks and defenses on machine learning models},
  author={Salem, Ahmed and Zhang, Yang and Humbert, Mathias and Berrang, Pascal and Fritz, Mario and Backes, Michael},
  journal={arXiv preprint arXiv:1806.01246},
  year={2018}
}

@inproceedings{carlini2019secret,
  title={The secret sharer: Evaluating and testing unintended memorization in neural networks},
  author={Carlini, Nicholas and Liu, Chang and Erlingsson, {\'U}lfar and Kos, Jernej and Song, Dawn},
  booktitle={28th USENIX Security Symposium (USENIX Security 19)},
  pages={267--284},
  year={2019}
}

@inproceedings{yeom2018privacy,
  title={Privacy risk in machine learning: Analyzing the connection to overfitting},
  author={Yeom, Samuel and Giacomelli, Irene and Fredrikson, Matt and Jha, Somesh},
  booktitle={2018 IEEE 31st computer security foundations symposium (CSF)},
  pages={268--282},
  year={2018},
  organization={IEEE}
}

@inproceedings{zhang2020secret,
  title={The secret revealer: Generative model-inversion attacks against deep neural networks},
  author={Zhang, Yuheng and Jia, Ruoxi and Pei, Hengzhi and Wang, Wenxiao and Li, Bo and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={253--261},
  year={2020}
}

@inproceedings{sablayrolles2019white,
  title={White-box vs black-box: Bayes optimal strategies for membership inference},
  author={Sablayrolles, Alexandre and Douze, Matthijs and Schmid, Cordelia and Ollivier, Yann and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={5558--5567},
  year={2019},
  organization={PMLR}
}

@inproceedings{feldman2020does,
  title={Does learning require memorization? a short tale about a long tail},
  author={Feldman, Vitaly},
  booktitle={Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={954--959},
  year={2020}
}

@inproceedings{fredrikson2014privacy,
  title={Privacy in pharmacogenetics: An $\{$End-to-End$\}$ case study of personalized warfarin dosing},
  author={Fredrikson, Matthew and Lantz, Eric and Jha, Somesh and Lin, Simon and Page, David and Ristenpart, Thomas},
  booktitle={23rd USENIX Security Symposium (USENIX Security 14)},
  pages={17--32},
  year={2014}
}

@article{mehnaz2022your,
  title={Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models},
  author={Mehnaz, Shagufta and Dibbo, Sayanton V and Kabir, Ehsanul and Li, Ninghui and Bertino, Elisa},
  journal={arXiv preprint arXiv:2201.09370},
  year={2022}
}

@article{jayaraman2022attribute,
  title={Are attribute inference attacks just imputation?},
  author={Jayaraman, Bargav and Evans, David},
  journal={arXiv preprint arXiv:2209.01292},
  year={2022}
}

@article{balle2022reconstructing,
  title={Reconstructing training data with informed adversaries},
  author={Balle, Borja and Cherubin, Giovanni and Hayes, Jamie},
  journal={arXiv preprint arXiv:2201.04845},
  year={2022}
}

@article{guo2022bounding,
  title={Bounding Training Data Reconstruction in Private (Deep) Learning},
  author={Guo, Chuan and Karrer, Brian and Chaudhuri, Kamalika and van der Maaten, Laurens},
  journal={arXiv preprint arXiv:2201.12383},
  year={2022}
}

@article{ericsson2021self,
  title={Why do self-supervised models transfer? investigating the impact of invariance on downstream tasks},
  author={Ericsson, Linus and Gouk, Henry and Hospedales, Timothy M},
  journal={arXiv preprint arXiv:2111.11398},
  year={2021}
}

@article{jing2021understanding,
  title={Understanding dimensional collapse in contrastive self-supervised learning},
  author={Jing, Li and Vincent, Pascal and LeCun, Yann and Tian, Yuandong},
  journal={arXiv preprint arXiv:2110.09348},
  year={2021}
}

@inproceedings{kalibhat2022towards,
  title={Towards better understanding of self-supervised representations},
  author={Kalibhat, Neha Mukund and Narang, Kanika and Firooz, Hamed and Sanjabi, Maziar and Feizi, Soheil},
  booktitle={ICML 2022: Workshop on Spurious Correlations, Invariance and Stability},
  year={2022}
}

@inproceedings{yu2018generative,
  title={Generative image inpainting with contextual attention},
  author={Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5505--5514},
  year={2018}
}

@inproceedings{ulyanov2018deep,
  title={Deep image prior},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9446--9454},
  year={2018}
}

@article{dwork2013algorithmic,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron},
  journal={Theoretical Computer Science},
  volume={9},
  number={3-4},
  pages={211--407},
  year={2013}
}

@incollection{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of cryptography},
  pages={265--284},
  year={2006},
  publisher={Springer}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

@article{thomee2015new,
  title={The new data and new challenges in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={arXiv preprint arXiv:1503.01817},
  volume={1},
  number={8},
  year={2015}
}

@inproceedings{kandpal2022deduplicating,
  title={Deduplicating training data mitigates privacy risks in language models},
  author={Kandpal, Nikhil and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={10697--10707},
  year={2022},
  organization={PMLR}
}

@article{carlini2022quantifying,
  title={Quantifying memorization across neural language models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2202.07646},
  year={2022}
}

@inproceedings{brown2022does,
  title={What Does it Mean for a Language Model to Preserve Privacy?},
  author={Brown, Hannah and Lee, Katherine and Mireshghallah, Fatemehsadat and Shokri, Reza and Tram{\`e}r, Florian},
  booktitle={2022 ACM Conference on Fairness, Accountability, and Transparency},
  pages={2280--2292},
  year={2022}
}

@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr}
}

@article{hendrycks2019using,
  title={Using self-supervised learning can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Mazeika, Mantas and Kadavath, Saurav and Song, Dawn},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{watson2021importance,
  title={On the importance of difficulty calibration in membership inference attacks},
  author={Watson, Lauren and Guo, Chuan and Cormode, Graham and Sablayrolles, Alex},
  journal={arXiv preprint arXiv:2111.08440},
  year={2021}
}

@article{ye2021enhanced,
  title={Enhanced membership inference attacks against machine learning models},
  author={Ye, Jiayuan and Maddi, Aadyaa and Murakonda, Sasi Kumar and Bindschaedler, Vincent and Shokri, Reza},
  journal={arXiv preprint arXiv:2111.09679},
  year={2021}
}

@article{LARS,
  title={Large batch training of convolutional networks},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inbook{pytorch,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K\"{o}pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {721},
numpages = {12}
}

@misc{demo,
  doi = {10.48550/ARXIV.2303.01986},
  url = {https://arxiv.org/abs/2303.01986},
  author = {Bordes, Florian and Balestriero, Randall and Vincent, Pascal},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Towards Democratizing Joint-Embedding Self-Supervised Learning},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{google_diffusion,
  title={Extracting training data from diffusion models},
  author={Carlini, Nicholas and Hayes, Jamie and Nasr, Milad and Jagielski, Matthew and Sehwag, Vikash and Tramer, Florian and Balle, Borja and Ippolito, Daphne and Wallace, Eric},
  journal={arXiv preprint arXiv:2301.13188},
  year={2023}
}

@inproceedings{goodfellow,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{kingma,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{salimans,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  booktitle={Advances in neural information processing systems},
  pages={2234--2242},
  year={2016}
}

@article{lopez,
  title={Revisiting classifier two-sample tests},
  author={Lopez-Paz, David and Oquab, Maxime},
  journal={arXiv preprint arXiv:1610.06545},
  year={2016}
}

@inproceedings{richardson,
  title={On gans and gmms},
  author={Richardson, Eitan and Weiss, Yair},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5847--5858},
  year={2018}
}

@article{heusel,
	Author = {Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
	Title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
	Year = {2017},
	Eprint = {arXiv:1706.08500},
	Howpublished = {Advances in Neural Information Processing Systems 31 (NIPS 2017)},
}

@misc{mehdi,
	Author = {Mehdi S. M. Sajjadi and Olivier Bachem and Mario Lucic and Olivier Bousquet and Sylvain Gelly},
	Title = {Assessing Generative Models via Precision and Recall},
	Year = {2018},
	Eprint = {arXiv:1806.00035},
	Howpublished = {Advances in Neural Information Processing Systems 31 (NIPS 2017)}
}

@article{lecun,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}

@inproceedings{zhang,
  title={The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
  booktitle={CVPR},
  year={2018}
}

@misc{BigGan,
Author = {Andrew Brock and Jeff Donahue and Karen Simonyan},
Title = {Large Scale GAN Training for High Fidelity Natural Image Synthesis},
Year = {2018},
Eprint = {arXiv:1809.11096},
}

@article{imagenet12,
    Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
    Title = {{ImageNet Large Scale Visual Recognition Challenge}},
    Year = {2015},
    journal   = {International Journal of Computer Vision (IJCV)},
    doi = {10.1007/s11263-015-0816-y},
    volume={115},
    number={3},
    pages={211-252}
}

@article{Kilian,
  title={An empirical study on evaluation metrics of generative adversarial networks},
  author={Xu, Qiantong and Huang, Gao and Yuan, Yang and Guo, Chuan and Sun, Yu and Wu, Felix and Weinberger, Kilian},
  journal={arXiv preprint arXiv:1806.07755},
  year={2018}
}

@article{mannwhitney,
  title={On a test of whether one of two random variables is stochastically larger than the other},
  author={Mann, Henry B and Whitney, Donald R},
  journal={The annals of mathematical statistics},
  pages={50--60},
  year={1947},
  publisher={JSTOR}
}

@article{VAEs_overfit,
  title={Can VAEs Generate Novel Examples?},
  author={Bozkurt, Alican and Esmaeili, Babak and Brooks, Dana H and Dy, Jennifer G and van de Meent, Jan-Willem},
  Howpublished = {Advances in Neural Information Processing Systems 32 (NIPS 2018)},
  year={2018}
}

@inproceedings{Ruslan_et_al,
  author    = {Yuhuai Wu and
               Yuri Burda and
               Ruslan Salakhutdinov and
               Roger B. Grosse},
  title     = {On the Quantitative Analysis of Decoder-Based Generative Models},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  year      = {2017},
  crossref  = {DBLP:conf/iclr/2017},
  url       = {https://openreview.net/forum?id=B1M8JF9xx},
  timestamp = {Thu, 25 Jul 2019 14:25:51 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/iclr/WuBSG17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Kynk_improved,
	author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
	title={Improved precision and recall metric for assessing generative models},
	Year = {2019},
	Eprint =  {arXiv:1904.06991v2},
	Howpublished = {Advances in Neural Information Processing Systems 33 (NIPS 2019)}
}

@article{che_2016,
  author    = {Tong Che and
               Yanran Li and
               Athul Paul Jacob and
               Yoshua Bengio and
               Wenjie Li},
  title     = {Mode Regularized Generative Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1612.02136},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.02136},
  archivePrefix = {arXiv},
  eprint    = {1612.02136},
  timestamp = {Mon, 13 Aug 2018 16:49:01 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/CheLJBL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{gretton,
  author    = {Dougal J. Sutherland and
               Hsiao{-}Yu Fish Tung and
               Heiko Strathmann and
               Soumyajit De and
               Aaditya Ramdas and
               Alexander J. Smola and
               Arthur Gretton},
  title     = {Generative Models and Model Criticism via Optimized Maximum Mean Discrepancy},
  journal   = {CoRR},
  volume    = {abs/1611.04488},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.04488},
  archivePrefix = {arXiv},
  eprint    = {1611.04488},
  timestamp = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SutherlandTSDRS16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{theis,
  author    = {Lucas Theis and
               A{\"{a}}ron van den Oord and
               Matthias Bethge},
  title     = {A note on the evaluation of generative models},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  crossref  = {DBLP:conf/iclr/2016},
  url       = {http://arxiv.org/abs/1511.01844},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/TheisOB15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gretton_2,
  author    = {Wacha Bounliphone and
               Eugene Belilovsky and
               Matthew B. Blaschko and
               Ioannis Antonoglou and
               Arthur Gretton},
  title     = {A Test of Relative Similarity For Model Selection in Generative Models},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  crossref  = {DBLP:conf/iclr/2016},
  url       = {http://arxiv.org/abs/1511.04581},
  timestamp = {Thu, 25 Jul 2019 14:25:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/BounliphoneBBAG15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GAN_benchmarks,
  author    = {Ishaan Gulrajani and
               Colin Raffel and
               Luke Metz},
  title     = {Towards {GAN} Benchmarks Which Require Generalization},
  journal   = {CoRR},
  volume    = {abs/2001.03653},
  year      = {2020},
  url       = {https://arxiv.org/abs/2001.03653},
  archivePrefix = {arXiv},
  eprint    = {2001.03653},
  timestamp = {Fri, 17 Jan 2020 14:07:30 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2001-03653.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{latent_recovery,
  author    = {Ryan Webster and
               Julien Rabin and
               Lo{\"{\i}}c Simon and
               Fr{\'{e}}d{\'{e}}ric Jurie},
  title     = {Detecting Overfitting of Deep Generative Networks via Latent Recovery},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2019, Long Beach, CA, USA, June 16-20, 2019},
  pages     = {11273--11282},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019},
  url       = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Webster\_Detecting\_Overfitting\_of\_Deep\_Generative\_Networks\_via\_Latent\_Recovery\_CVPR\_2019\_paper.html},
  doi       = {10.1109/CVPR.2019.01153},
  timestamp = {Mon, 20 Jan 2020 15:36:04 +0100},
  biburl    = {https://dblp.org/rec/conf/cvpr/WebsterRSJ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{reviewer_paper,
  title={Real-valued (medical) time series generation with recurrent conditional gans},
  author={Esteban, Crist{\'o}bal and Hyland, Stephanie L and R{\"a}tsch, Gunnar},
  journal={arXiv preprint arXiv:1706.02633},
  year={2017}
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{metricdp,
	title = {Privacy- and {Utility}-{Preserving} {Textual} {Analysis} via {Calibrated} {Multivariate} {Perturbations}},
	url = {https://arxiv.org/abs/1910.08902v1},
	language = {en},
	urldate = {2021-10-13},
	author = {Feyisetan, Oluwaseyi and Balle, Borja and Drake, Thomas and Diethe, Tom},
	month = oct,
	year = {2019}
}

@article{DPbook,
  title={The algorithmic foundations of differential privacy.},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Found. Trends Theor. Comput. Sci.},
  volume={9},
  number={3-4},
  pages={211--407},
  year={2014}
}

@inproceedings{mrini-etal-2021-recursive,
    title = "Recursive Tree-Structured Self-Attention for Answer Sentence Selection",
    author = "Mrini, Khalil  and
      Farcas, Emilia  and
      Nakashole, Ndapa",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.358",
    doi = "10.18653/v1/2021.acl-long.358",
    pages = "4651--4661",
    abstract = "Syntactic structure is an important component of natural language text. Recent top-performing models in Answer Sentence Selection (AS2) use self-attention and transfer learning, but not syntactic structure. Tree structures have shown strong performance in tasks with sentence pair input like semantic relatedness. We investigate whether tree structures can boost performance in AS2. We introduce the Tree Aggregation Transformer: a novel recursive, tree-structured self-attention model for AS2. The recursive nature of our model is able to represent all levels of syntactic parse trees with only one additional self-attention layer. Without transfer learning, we establish a new state of the art on the popular TrecQA and WikiQA benchmark datasets. Additionally, we evaluate our method on four Community Question Answering datasets, and find that tree-structured representations have limitations with noisy user-generated text. We conduct probing experiments to evaluate how our models leverage tree structures across datasets. Our findings show that the ability of tree-structured models to successfully absorb syntactic information is strongly correlated with a higher performance in AS2.",
}



@book{DP,
	title = {Differential {Privacy}},
	volume = {4052},
	isbn = {978-3-540-35907-4},
	url = {https://www.microsoft.com/en-us/research/publication/differential-privacy/},
	abstract = {In 1977 Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a formalization of Dalenius’ goal along the lines of semantic security cannot be achieved. Contrary to intuition, a variant …},
	language = {en-US},
	urldate = {2020-04-12},
	author = {Dwork, Cynthia},
	month = jul,
	year = {2006},
	annote = {Original DP paper.
Way too cryptographic},
	file = {Snapshot:/Users/casey/Zotero/storage/VG5FK8TD/differential-privacy.html:text/html;Full Text PDF:/Users/casey/Zotero/storage/7VQFV7EL/Dwork - 2006 - Differential Privacy.pdf:application/pdf},
}


@incollection{ldp,
	address = {Berlin, Heidelberg},
	title = {Our {Data}, {Ourselves}: {Privacy} {Via} {Distributed} {Noise} {Generation}},
	volume = {4004},
	isbn = {978-3-540-34546-6 978-3-540-34547-3},
	shorttitle = {Our {Data}, {Ourselves}},
	url = {http://link.springer.com/10.1007/11761679_29},
	language = {en},
	urldate = {2020-04-13},
	booktitle = {Advances in {Cryptology} - {EUROCRYPT} 2006},
	publisher = {Springer Berlin Heidelberg},
	author = {Dwork, Cynthia and Kenthapadi, Krishnaram and McSherry, Frank and Mironov, Ilya and Naor, Moni},
	editor = {Vaudenay, Serge},
	year = {2006},
	doi = {10.1007/11761679_29},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {differential privacy},
	pages = {486--503},
	annote = {Proposes local DP. Much like randomized response.},
}

@inproceedings{tukeydepth,
  title={Mathematics and the picturing of data},
  author={Tukey, John W},
  booktitle={Proceedings of the International Congress of Mathematicians, Vancouver, 1975},
  volume={2},
  pages={523--531},
  year={1975}
}

@inproceedings{optimal_tukey,
  title={An optimal randomized algorithm for maximum Tukey depth.},
  author={Chan, Timothy M},
  booktitle={SODA},
  volume={4},
  pages={430--436},
  year={2004}
}


@inproceedings{kamath_high_dim,
	title = {Privately {Learning} {High}-{Dimensional} {Distributions}},
	url = {http://proceedings.mlr.press/v99/kamath19a.html},
	language = {en},
	urldate = {2021-07-27},
	booktitle = {Conference on {Learning} {Theory}},
	publisher = {PMLR},
	author = {Kamath, Gautam and Li, Jerry and Singhal, Vikrant and Ullman, Jonathan},
	month = jun,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {1853--1902},
	file = {Full Text PDF:/Users/casey/Zotero/storage/IRE84K3W/Kamath et al. - 2019 - Privately Learning High-Dimensional Distributions.pdf:application/pdf},
}


@inproceedings{mdp_low_dim,
  title={Private Release of Text Embedding Vectors},
  author={Feyisetan, Oluwaseyi and Kasiviswanathan, Shiva},
  booktitle={Proceedings of the First Workshop on Trustworthy Natural Language Processing},
  pages={15--27},
  year={2021}
}


@inproceedings{DP_compression,
	title = {Differential privacy with compression},
	doi = {10.1109/ISIT.2009.5205863},
	abstract = {This work studies formal utility and privacy guarantees for a simple multiplicative database transformation, where the data are compressed by a random linear or affine transformation, reducing the number of data records substantially, while preserving the number of original input variables.We provide an analysis framework inspired by a recent concept known as differential privacy. Our goal is to show that, despite the general difficulty of achieving the differential privacy guarantee, it is possible to publish synthetic data that are useful for a number of common statistical learning applications. This includes high dimensional sparse regression, principal component analysis (PCA), and other statistical measures based on the covariance of the initial data.},
	booktitle = {2009 {IEEE} {International} {Symposium} on {Information} {Theory}},
	author = {Zhou, Shuheng and Ligett, Katrina and Wasserman, Larry},
	month = jun,
	year = {2009},
	note = {ISSN: 2157-8117},
	keywords = {data privacy, Data privacy, Databases, Statistics, Computer science, Additive noise, affine transformation, affine transforms, Covariance matrix, database management systems, differential privacy guarantee, formal utility, high dimensional sparse regression, multiplicative database transformation, principal component analysis, Principal component analysis, random linear transformation, Random variables, regression analysis, Seminars, statistical learning, Statistical learning},
	pages = {2718--2722},
	file = {Accepted Version:/Users/casey/Zotero/storage/DMLWQXA5/Zhou et al. - 2009 - Differential privacy with compression.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/casey/Zotero/storage/NJJ8IXXA/5205863.html:text/html},
}


@inproceedings{orig_metricdp,
	title = {Invited {Paper}: {Local} {Differential} {Privacy} on {Metric} {Spaces}: {Optimizing} the {Trade}-{Off} with {Utility}},
	shorttitle = {Invited {Paper}},
	doi = {10.1109/CSF.2018.00026},
	abstract = {Local differential privacy (LPD) is a distributed variant of differential privacy (DP) in which the obfuscation of the sensitive information is done at the level of the individual records, and in general it is used to sanitize data that are collected for statistical purposes. LPD has the advantage it does not need to assume a trusted third party. On the other hand LDP in general requires more noise than DP to achieve the same level of protection, with negative consequences on the utility. In practice, utility becomes acceptable only on very large collections of data, and this is the reason why LDP is especially successful among big companies such as Apple and Google, which can count on a huge number of users. In this talk, we propose a variant of LDP suitable for metric spaces, such as location data or energy consumption data, and we show that it provides a much higher utility for the same level of privacy. Furthermore, we discuss algorithms to extract the best possible statistical information from the data obfuscated with this metric variant of LDP.},
	booktitle = {2018 {IEEE} 31st {Computer} {Security} {Foundations} {Symposium} ({CSF})},
	author = {Alvim, Mário and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia and Pazii, Anna},
	month = jul,
	year = {2018},
	note = {ISSN: 2374-8303},
	keywords = {Distributed databases, Local-differential-privacy,-dX–privacy,-Kantorovich-lifting., Measurement, Privacy, Smart meters},
	pages = {262--267},
	file = {IEEE Xplore Full Text PDF:/Users/casey/Zotero/storage/2FQSGZPN/Alvim et al. - 2018 - Invited Paper Local Differential Privacy on Metri.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/casey/Zotero/storage/RZL8XNKF/8429310.html:text/html},
}


@article{clifton,
	title = {Differentially {Private} {Imaging} via {Latent} {Space} {Manipulation}},
	url = {http://arxiv.org/abs/2103.05472},
	abstract = {There is growing concern about image privacy due to the popularity of social media and photo devices, along with increasing use of face recognition systems. However, established image de-identification techniques are either too subject to re-identification, produce photos that are insufficiently realistic, or both. To tackle this, we present a novel approach for image obfuscation by manipulating latent spaces of an unconditionally trained generative model that is able to synthesize photo-realistic facial images of high resolution. This manipulation is done in a way that satisfies the formal privacy standard of local differential privacy. To our knowledge, this is the first approach to image privacy that satisfies \${\textbackslash}varepsilon\$-differential privacy {\textbackslash}emph\{for the person.\}},
	urldate = {2021-05-04},
	journal = {arXiv:2103.05472 [cs]},
	author = {Li, Tao and Clifton, Chris},
	month = apr,
	year = {2021},
	note = {arXiv: 2103.05472},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/ERAZN7FB/Li and Clifton - 2021 - Differentially Private Imaging via Latent Space Ma.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/X3UH5IPM/2103.html:text/html},
}


@article{abadi,
	title = {Deep {Learning} with {Differential} {Privacy}},
	url = {http://arxiv.org/abs/1607.00133},
	doi = {10.1145/2976749.2978318},
	abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
	urldate = {2020-05-12},
	journal = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
	author = {Abadi, Martín and Chu, Andy and Goodfellow, Ian and McMahan, H. Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
	month = oct,
	year = {2016},
	note = {arXiv: 1607.00133},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {308--318},
	file = {arXiv.org Snapshot:/Users/casey/Zotero/storage/NAE4MA8G/1607.html:text/html;arXiv Fulltext PDF:/Users/casey/Zotero/storage/JS3QK5PP/Abadi et al. - 2016 - Deep Learning with Differential Privacy.pdf:application/pdf},
}


@inproceedings{tukey_props,
	address = {Los Angeles, CA, USA},
	title = {When does the {Tukey} {Median} work?},
	isbn = {978-1-72816-432-8},
	url = {https://ieeexplore.ieee.org/document/9173995/},
	doi = {10.1109/ISIT44484.2020.9173995},
	abstract = {We analyze the performance of the Tukey median estimator under total variation (TV) distance corruptions. Previous results show that under Huber’s additive corruption model, the breakdown point is 1/3 for high-dimensional halfspacesymmetric distributions. We show that under TV corruptions, the breakdown point reduces to 1/4 for the same set of distributions. We also show that a certain projection algorithm can attain the optimal breakdown point of 1/2. Both the Tukey median estimator and the projection algorithm achieve sample complexity linear in dimension.},
	language = {en},
	urldate = {2021-11-03},
	booktitle = {2020 {IEEE} {International} {Symposium} on {Information} {Theory} ({ISIT})},
	publisher = {IEEE},
	author = {Zhu, Banghua and Jiao, Jiantao and Steinhardt, Jacob},
	month = jun,
	year = {2020},
	pages = {1201--1206},
	annote = {Clarifies when tukey median contains mean},
	file = {Zhu et al. - 2020 - When does the Tukey Median work.pdf:/Users/casey/Zotero/storage/KKW2PGDN/Zhu et al. - 2020 - When does the Tukey Median work.pdf:application/pdf},
}


@article{median_hyp,
	title = {The {Median} {Hypothesis}},
	url = {https://www.microsoft.com/en-us/research/publication/the-median-hypothesis/},
	abstract = {A typical learning process begins with some prior beliefs about the target concept. These beliefs are rened using evidence, typically a sample. The evidence is used to compute a posterior belief, which assigns a probability distribution over the hypothesis class F. Using the posterior, a hypothesis is selected to predict the labels during the generalization […]},
	language = {en-US},
	urldate = {2021-08-12},
	author = {Gilad-Bachrach, Ran and Burges, Chris J. C.},
	month = jun,
	year = {2012},
	file = {Full Text PDF:/Users/casey/Zotero/storage/4G8GKT7N/Gilad-Bachrach and Burges - 2012 - The Median Hypothesis.pdf:application/pdf;Snapshot:/Users/casey/Zotero/storage/74XU4DI8/the-median-hypothesis.html:text/html},
}


@article{sbert,
	title = {Sentence-{BERT}: {Sentence} {Embeddings} using {Siamese} {BERT}-{Networks}},
	shorttitle = {Sentence-{BERT}},
	url = {http://arxiv.org/abs/1908.10084},
	abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
	urldate = {2021-06-16},
	journal = {arXiv:1908.10084 [cs]},
	author = {Reimers, Nils and Gurevych, Iryna},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.10084},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Published at EMNLP 2019},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/ANYCUKXE/Reimers and Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/JU2UW8BA/1908.html:text/html},
}

@inproceedings{goodreads,
  author    = {Mengting Wan and
               Julian J. McAuley},
  editor    = {Sole Pera and
               Michael D. Ekstrand and
               Xavier Amatriain and
               John O'Donovan},
  title     = {Item recommendation on monotonic behavior chains},
  booktitle = {Proceedings of the 12th {ACM} Conference on Recommender Systems, RecSys
               2018, Vancouver, BC, Canada, October 2-7, 2018},
  pages     = {86--94},
  publisher = {{ACM}},
  year      = {2018},
  url       = {https://doi.org/10.1145/3240323.3240369},
  doi       = {10.1145/3240323.3240369},
  timestamp = {Mon, 22 Jul 2019 19:11:02 +0200},
  biburl    = {https://dblp.org/rec/conf/recsys/WanM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{20newsgroup,
	title = {Home {Page} for 20 {Newsgroups} {Data} {Set}},
	url = {http://qwone.com/~jason/20Newsgroups/},
	urldate = {2021-11-15},
	file = {Home Page for 20 Newsgroups Data Set:/Users/casey/Zotero/storage/5NLK944Q/20Newsgroups.html:text/html},
	author = {Lang, Ken}, 
	year = {1995}
}

@InProceedings{imdb,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@inproceedings{alsentzer2019publicly,
  title={Publicly Available Clinical BERT Embeddings},
  author={Alsentzer, Emily and Murphy, John and Boag, William and Weng, Wei-Hung and Jindi, Di and Naumann, Tristan and McDermott, Matthew},
  booktitle={Proceedings of the 2nd Clinical Natural Language Processing Workshop},
  pages={72--78},
  year={2019}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{li2020sentence,
  title={On the sentence embeddings from BERT for semantic textual similarity},
  author={Li, Bohan and Zhou, Hao and He, Junxian and Wang, Mingxuan and Yang, Yiming and Li, Lei},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9119--9130},
  year={2020}
}

@inproceedings{gupta2019better,
  title={Better Word Embeddings by Disentangling Contextual n-Gram Information},
  author={Gupta, Prakhar and Pagliardini, Matteo and Jaggi, Martin},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={933--939},
  year={2019}
}

@article{bojanowski2017enriching,
  title={Enriching word vectors with subword information},
  author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={135--146},
  year={2017},
  publisher={MIT Press}
}

@inproceedings{thongtan2019sentiment,
  title={Sentiment classification using document embeddings trained with cosine similarity},
  author={Thongtan, Tan and Phienthrakul, Tanasanee},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop},
  pages={407--414},
  year={2019}
}

@article{bianchi2020pre,
  title={Pre-training is a hot topic: Contextualized document embeddings improve topic coherence},
  author={Bianchi, Federico and Terragni, Silvia and Hovy, Dirk},
  journal={arXiv preprint arXiv:2004.03974},
  year={2020}
}

@inproceedings{yang2016hierarchical,
  title={Hierarchical attention networks for document classification},
  author={Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
  booktitle={Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies},
  pages={1480--1489},
  year={2016}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}

@inproceedings{huang-etal-2020-texthide,
    title = "{T}ext{H}ide: Tackling Data Privacy in Language Understanding Tasks",
    author = "Huang, Yangsibo  and
      Song, Zhao  and
      Chen, Danqi  and
      Li, Kai  and
      Arora, Sanjeev",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.123",
    doi = "10.18653/v1/2020.findings-emnlp.123",
    pages = "1368--1382",
    abstract = "An unsolved challenge in distributed or federated learning is to effectively mitigate privacy risks without slowing down training or reducing accuracy. In this paper, we propose TextHide aiming at addressing this challenge for natural language understanding tasks. It requires all participants to add a simple encryption step to prevent an eavesdropping attacker from recovering private text data. Such an encryption step is efficient and only affects the task performance slightly. In addition, TextHide fits well with the popular framework of fine-tuning pre-trained language models (e.g., BERT) for any sentence or sentence-pair task. We evaluate TextHide on the GLUE benchmark, and our experiments show that TextHide can effectively defend attacks on shared gradients or representations and the averaged accuracy reduction is only 1.9{\%}. We also present an analysis of the security of TextHide using a conjecture about the computational intractability of a mathematical problem.",
}

@inproceedings{xie2021reconstruction,
  title={Reconstruction Attack on Instance Encoding for Language Understanding},
  author={Xie, Shangyu and Hong, Yuan},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={2038--2044},
  year={2021}
}

@inproceedings{pan2020privacy,
  title={Privacy risks of general-purpose language models},
  author={Pan, Xudong and Zhang, Mi and Ji, Shouling and Yang, Min},
  booktitle={2020 IEEE Symposium on Security and Privacy (SP)},
  pages={1314--1331},
  year={2020},
  organization={IEEE}
}

@inproceedings{yenicelik2020does,
  title={How does BERT capture semantics? A closer look at polysemous words},
  author={Yenicelik, David and Schmidt, Florian and Kilcher, Yannic},
  booktitle={Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP},
  pages={156--162},
  year={2020}
}


@inproceedings{strubell2018linguistically,
  title={Linguistically-Informed Self-Attention for Semantic Role Labeling},
  author={Strubell, Emma and Verga, Patrick and Andor, Daniel and Weiss, David and McCallum, Andrew},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={5027--5038},
  year={2018}
}

@inproceedings{liu2019multi,
  title={Multi-Task Deep Neural Networks for Natural Language Understanding},
  author={Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4487--4496},
  year={2019}
}

@inproceedings{jawahar2019does,
  title={What does BERT learn about the structure of language?},
  author={Jawahar, Ganesh and Sagot, Beno{\^\i}t and Seddah, Djam{\'e}},
  booktitle={ACL 2019-57th Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}


@article{exp_mech,
	title = {Mechanism {Design} via {Differential} {Privacy}},
	url = {https://www.microsoft.com/en-us/research/publication/mechanism-design-via-differential-privacy/},
	abstract = {We study the role that privacy-preserving algorithms, which prevent the leakage of speciﬁc information about participants, can play in the design of mechanisms for strategic agents, which must encourage players to honestly report information. Speciﬁcally, we show that the recent notion of differential privacy [15, 14], in addition to its own intrinsic virtue, can ensure …},
	language = {en-US},
	urldate = {2020-04-12},
	author = {McSherry, Frank and Talwar, Kunal},
	month = oct,
	year = {2007},
	annote = {Discusses composition and post-processing properties of DP
 },
	file = {Snapshot:/Users/casey/Zotero/storage/UM45NJXT/mechanism-design-via-differential-privacy.html:text/html;Full Text PDF:/Users/casey/Zotero/storage/CAUNX7CZ/McSherry and Talwar - 2007 - Mechanism Design via Differential Privacy.pdf:application/pdf},
}

@article{TEM,
  title={TEM: High Utility Metric Differential Privacy on Text},
  author={Carvalho, Ricardo Silva and Vasiloudis, Theodore and Feyisetan, Oluwaseyi},
  journal={arXiv preprint arXiv:2107.07928},
  year={2021}
}


@article{attack_word_embs,
	title = {Exploring the {Privacy}-{Preserving} {Properties} of {Word} {Embeddings}: {Algorithmic} {Validation} {Study}},
	volume = {22},
	issn = {1438-8871},
	shorttitle = {Exploring the {Privacy}-{Preserving} {Properties} of {Word} {Embeddings}},
	url = {https://www.jmir.org/2020/7/e18055},
	doi = {10.2196/18055},
	abstract = {Background: Word embeddings are dense numeric vectors used to represent language in neural networks. Until recently, there had been no publicly released embeddings trained on clinical data. Our work is the first to study the privacy implications of releasing these models.
Objective: This paper aims to demonstrate that traditional word embeddings created on clinical corpora that have been deidentified by removing personal health information (PHI) can nonetheless be exploited to reveal sensitive patient information.
Methods: We used embeddings created from 400,000 doctor-written consultation notes and experimented with 3 common word embedding methods to explore the privacy-preserving properties of each.
Results: We found that if publicly released embeddings are trained from a corpus anonymized by PHI removal, it is possible to reconstruct up to 68.5\% (n=411/600) of the full names that remain in the deidentified corpus and associated sensitive information to specific patients in the corpus from which the embeddings were created. We also found that the distance between the word vector representation of a patient’s name and a diagnostic billing code is informative and differs significantly from the distance between the name and a code not billed for that patient.
Conclusions: Special care must be taken when sharing word embeddings created from clinical texts, as current approaches may compromise patient privacy. If PHI removal is used for anonymization before traditional word embeddings are trained, it is possible to attribute sensitive information to patients who have not been fully deidentified by the (necessarily imperfect) removal algorithms. A promising alternative (ie, anonymization by PHI replacement) may avoid these flaws. Our results are timely and critical, as an increasing number of researchers are pushing for publicly available health data.},
	language = {en},
	number = {7},
	urldate = {2021-06-16},
	journal = {Journal of Medical Internet Research},
	author = {Abdalla, Mohamed and Abdalla, Moustafa and Hirst, Graeme and Rudzicz, Frank},
	month = jul,
	year = {2020},
	pages = {e18055},
	file = {Abdalla et al. - 2020 - Exploring the Privacy-Preserving Properties of Wor.pdf:/Users/casey/Zotero/storage/7AX9YN83/Abdalla et al. - 2020 - Exploring the Privacy-Preserving Properties of Wor.pdf:application/pdf},
}


@article{another_metric_DP,
	title = {Privacy-{Adaptive} {BERT} for {Natural} {Language} {Understanding}},
	url = {http://arxiv.org/abs/2104.07504},
	abstract = {When trying to apply the recent advance of Natural Language Understanding (NLU) technologies to real-world applications, privacy preservation imposes a crucial challenge, which, unfortunately, has not been well resolved. To address this issue, we study how to improve the effectiveness of NLU models under a Local Privacy setting, using BERT [9], a widely-used pretrained Language Model (LM), as an example. We systematically study the strengths and weaknesses of imposing ������ ������-privacy [12], a relaxed variant of Local Differential Privacy, at different stages of language modeling: input text, token embeddings, and sequence representations. We then focus on the former two with privacy-constrained fine-tuning experiments to reveal the utility of BERT under local privacy constraints. More importantly, to the best of our knowledge, we are the first to propose privacy-adaptive LM pretraining methods and demonstrate that they can significantly improve model performance on privatized text input. We also interpret the level of privacy preservation and provide our guidance on privacy parameter selections.},
	language = {en},
	urldate = {2021-06-09},
	journal = {arXiv:2104.07504 [cs]},
	author = {Qu, Chen and Kong, Weize and Yang, Liu and Zhang, Mingyang and Bendersky, Michael and Najork, Marc},
	month = apr,
	year = {2021},
	note = {arXiv: 2104.07504},
	keywords = {Computer Science - Computation and Language},
	file = {Qu et al. - 2021 - Privacy-Adaptive BERT for Natural Language Underst.pdf:/Users/casey/Zotero/storage/3J4CDYJN/Qu et al. - 2021 - Privacy-Adaptive BERT for Natural Language Underst.pdf:application/pdf},
}


@article{carlini_attack,
	title = {Extracting {Training} {Data} from {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2012.07805},
	abstract = {It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model. We demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data. We comprehensively evaluate our extraction attack to understand the factors that contribute to its success. For example, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.},
	urldate = {2021-06-09},
	journal = {arXiv:2012.07805 [cs]},
	author = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and Oprea, Alina and Raffel, Colin},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.07805},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/IBTBC44K/Carlini et al. - 2020 - Extracting Training Data from Large Language Model.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/4IXVKUHQ/2012.html:text/html},
}


@article{attack_on_embeddings,
	title = {Information {Leakage} in {Embedding} {Models}},
	url = {http://arxiv.org/abs/2004.00053},
	abstract = {Embeddings are functions that map raw input data to low-dimensional vector representations, while preserving important semantic information about the inputs. Pre-training embeddings on a large amount of unlabeled data and fine-tuning them for downstream tasks is now a de facto standard in achieving state of the art learning in many domains. We demonstrate that embeddings, in addition to encoding generic semantics, often also present a vector that leaks sensitive information about the input data. We develop three classes of attacks to systematically study information that might be leaked by embeddings. First, embedding vectors can be inverted to partially recover some of the input data. As an example, we show that our attacks on popular sentence embeddings recover between 50{\textbackslash}\%--70{\textbackslash}\% of the input words (F1 scores of 0.5--0.7). Second, embeddings may reveal sensitive attributes inherent in inputs and independent of the underlying semantic task at hand. Attributes such as authorship of text can be easily extracted by training an inference model on just a handful of labeled embedding vectors. Third, embedding models leak moderate amount of membership information for infrequent training data inputs. We extensively evaluate our attacks on various state-of-the-art embedding models in the text domain. We also propose and evaluate defenses that can prevent the leakage to some extent at a minor cost in utility.},
	urldate = {2021-06-09},
	journal = {arXiv:2004.00053 [cs, stat]},
	author = {Song, Congzheng and Raghunathan, Ananth},
	month = aug,
	year = {2020},
	note = {arXiv: 2004.00053},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/27XDU35A/Song and Raghunathan - 2020 - Information Leakage in Embedding Models.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/IC82WUA2/2004.html:text/html},
}


@article{fancy_metricdp,
	title = {Differential {Privacy} for {Text} {Analytics} via {Natural} {Text} {Sanitization}},
	url = {http://arxiv.org/abs/2106.01221},
	abstract = {Texts convey sophisticated knowledge. However, texts also convey sensitive information. Despite the success of general-purpose language models and domain-specific mechanisms with differential privacy (DP), existing text sanitization mechanisms still provide low utility, as cursed by the high-dimensional text representation. The companion issue of utilizing sanitized texts for downstream analytics is also under-explored. This paper takes a direct approach to text sanitization. Our insight is to consider both sensitivity and similarity via our new local DP notion. The sanitized texts also contribute to our sanitization-aware pretraining and fine-tuning, enabling privacy-preserving natural language processing over the BERT language model with promising utility. Surprisingly, the high utility does not boost up the success rate of inference attacks.},
	urldate = {2021-06-09},
	journal = {arXiv:2106.01221 [cs]},
	author = {Yue, Xiang and Du, Minxin and Wang, Tianhao and Li, Yaliang and Sun, Huan and Chow, Sherman S. M.},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.01221},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Computation and Language},
	annote = {Comment: ACL-ICJNLP'21 Findings; The first two authors contributed equally},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/D3JRBRR7/Yue et al. - 2021 - Differential Privacy for Text Analytics via Natura.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/J8S8VM4G/2106.html:text/html},
}


@article{DP_training,
	title = {Differentially {Private} {Language} {Models} {Benefit} from {Public} {Pre}-training},
	url = {http://arxiv.org/abs/2009.05886},
	abstract = {Language modeling is a keystone task in natural language processing. When training a language model on sensitive information, differential privacy (DP) allows us to quantify the degree to which our private data is protected. However, training algorithms which enforce differential privacy often lead to degradation in model quality. We study the feasibility of learning a language model which is simultaneously high-quality and privacy preserving by tuning a public base model on a private corpus. We find that DP fine-tuning boosts the performance of language models in the private domain, making the training of such models possible.},
	urldate = {2021-06-15},
	journal = {arXiv:2009.05886 [cs]},
	author = {Kerrigan, Gavin and Slack, Dylan and Tuyls, Jens},
	month = oct,
	year = {2020},
	note = {arXiv: 2009.05886},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/LZD3RNSS/Kerrigan et al. - 2020 - Differentially Private Language Models Benefit fro.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/JU5SRJH6/2009.html:text/html},
}

@article{DP_training_II,
  title={Differential privacy has disparate impact on model accuracy},
  author={Bagdasaryan, Eugene and Poursaeed, Omid and Shmatikov, Vitaly},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={15479--15488},
  year={2019}
}


@article{metricDP_gumbel,
	title = {Density-{Aware} {Differentially} {Private} {Textual} {Perturbations} {Using} {Truncated} {Gumbel} {Noise}},
	volume = {34},
	issn = {2334-0762},
	url = {https://journals.flvc.org/FLAIRS/article/view/128463},
	doi = {10.32473/flairs.v34i1.128463},
	abstract = {Deep Neural Networks, despite their success in diverse domains, are provably sensitive to small perturbations which cause the models to return erroneous predictions to minor transformations. Recently, it was proposed that this effect can be addressed in the text domain by optimizing for the worst case loss function over all possible word substitutions within the training examples. However, this approach is prone to weighing semantically unlikely word replacements higher, resulting in accuracy loss. In this paper, we study robustness to adversarial perturbations by using differentially private randomized substitutions while training the model. This approach has two immediate advantages: (1) by ensuring that the word replacement likelihood is weighted by its proximity to the original word in a metric space, we circumvent optimizing for worst case guarantees thereby achieve performance gains; and (2) the calibrated randomness results in training a privacy preserving model, while also guaranteeing robustness against adversarial attacks on the model outputs. Our approach uses a novel density-based differentially private mechanism based on truncated Gumbel noise. This ensures training on substitutions of words in dense and sparse regions of a metric space while maintaining semantic similarity for model robustness. Our experiments on two datasets suggest an improvement of up to 10\% on the accuracy metrics.},
	language = {en},
	number = {1},
	urldate = {2021-11-15},
	journal = {The International FLAIRS Conference Proceedings},
	author = {Xu, Nan and Feyisetan, Oluwaseyi and Aggarwal, Abhinav and Xu, Zekun and Teissier, Nathanael},
	month = apr,
	year = {2021},
	file = {Xu et al. - 2021 - Density-Aware Differentially Private Textual Pertu.pdf:/Users/casey/Zotero/storage/UNYJYRHI/Xu et al. - 2021 - Density-Aware Differentially Private Textual Pertu.pdf:application/pdf},
}


@article{private_halfspaces,
	title = {Private {Center} {Points} and {Learning} of {Halfspaces}},
	url = {http://arxiv.org/abs/1902.10731},
	abstract = {We present a private learner for halfspaces over an arbitrary finite domain \$X{\textbackslash}subset {\textbackslash}mathbb\{R\}{\textasciicircum}d\$ with sample complexity \$mathrm\{poly\}(d,2{\textasciicircum}\{{\textbackslash}log{\textasciicircum}*{\textbar}X{\textbar}\})\$. The building block for this learner is a differentially private algorithm for locating an approximate center point of \$m{\textgreater}{\textbackslash}mathrm\{poly\}(d,2{\textasciicircum}\{{\textbackslash}log{\textasciicircum}*{\textbar}X{\textbar}\})\$ points -- a high dimensional generalization of the median function. Our construction establishes a relationship between these two problems that is reminiscent of the relation between the median and learning one-dimensional thresholds [Bun et al.{\textbackslash} FOCS '15]. This relationship suggests that the problem of privately locating a center point may have further applications in the design of differentially private algorithms. We also provide a lower bound on the sample complexity for privately finding a point in the convex hull. For approximate differential privacy, we show a lower bound of \$m={\textbackslash}Omega(d+{\textbackslash}log{\textasciicircum}*{\textbar}X{\textbar})\$, whereas for pure differential privacy \$m={\textbackslash}Omega(d{\textbackslash}log{\textbar}X{\textbar})\$.},
	urldate = {2021-07-30},
	journal = {arXiv:1902.10731 [cs, stat]},
	author = {Beimel, Amos and Moran, Shay and Nissim, Kobbi and Stemmer, Uri},
	month = feb,
	year = {2019},
	note = {arXiv: 1902.10731},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computational Geometry},
	annote = {Comment: 14 pages},
	file = {arXiv Fulltext PDF:/Users/casey/Zotero/storage/99NUB8R2/Beimel et al. - 2019 - Private Center Points and Learning of Halfspaces.pdf:application/pdf;arXiv.org Snapshot:/Users/casey/Zotero/storage/99X9WZY4/1902.html:text/html},
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{Prochlo,
 author = {Bittau, Andrea and Erlingsson, \'{U}lfar and Maniatis, Petros and Mironov, Ilya and Raghunathan, Ananth and Lie, David and Rudominer, Mitch and Kode, Ushasree and Tinnes, Julien and Seefeld, Bernhard},
 title = {Prochlo: Strong Privacy for Analytics in the Crowd},
 booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
 series = {SOSP '17},
 year = {2017},
 isbn = {978-1-4503-5085-3},
 location = {Shanghai, China},
 pages = {441--459},
 numpages = {19},
 url = {http://doi.acm.org/10.1145/3132747.3132769},
 doi = {10.1145/3132747.3132769},
 acmid = {3132769},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@INPROCEEDINGS{sok,
  author={M. C. {Tschantz} and S. {Sen} and A. {Datta}},
  booktitle={2020 IEEE Symposium on Security and Privacy (SP)}, 
  title={SoK: Differential Privacy as a Causal Property}, 
  year={2020},
  volume={},
  number={},
  pages={354-371},
  doi={10.1109/SP40000.2020.00012}}
@misc{MLPriv,
      title={An Overview of Privacy in Machine Learning}, 
      author={Emiliano De Cristofaro},
      year={2020},
      eprint={2005.08679},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
	@incollection{Microsoft,
title = {Collecting Telemetry Data Privately},
author = {Ding, Bolin and Kulkarni, Janardhan and Yekhanin, Sergey},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {3571--3580},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6948-collecting-telemetry-data-privately.pdf}
}
@inproceedings{Rappor1,
	Author = {Erlingsson, {\'U}lfar and Pihur, Vasyl and Korolova, Aleksandra},
	Booktitle = {CCS},
	Date-Added = {2018-08-21 20:00:11 -0400},
	Date-Modified = {2018-08-21 20:00:11 -0400},
	Title = {Rappor: Randomized aggregatable privacy-preserving ordinal response},
	Year = {2014}}
	@article{EncryptedDP,
  title={Encrypted Databases for Differential Privacy},
  author={A. Agarwal and M. Herlihy and S. Kamara and Tarik Moataz},
  journal={Proceedings on Privacy Enhancing Technologies},
  year={2018},
  volume={2019},
  pages={170 - 190}
}@misc{Rappor2,
    title={Building a RAPPOR with the Unknown: Privacy-Preserving Learning of Associations and Data Dictionaries},
    author={Giulia Fanti and Vasyl Pihur and {\'U}lfar Erlingsson},
    year={2015},
    eprint={1503.01214},
    archivePrefix={arXiv},
    primaryClass={cs.CR}
}
@misc{Census1, 
title="Disclosure Avoidance and the 2020 Census",
howpublished ="\url{https://www.census.gov/about/policies/privacy/statistical_safeguards/disclosure-avoidance-2020-census.html/}",
year=2020}
@INPROCEEDINGS{Census2,
  author={A. {Machanavajjhala} and D. {Kifer} and J. {Abowd} and J. {Gehrke} and L. {Vilhuber}},
  booktitle={2008 IEEE 24th International Conference on Data Engineering}, 
  title={Privacy: Theory meets Practice on the Map}, 
  year={2008},
  volume={},
  number={},
  pages={277-286},}
  @article{Dwork,
 author = {Dwork, Cynthia and Roth, Aaron},
 title = {The Algorithmic Foundations of Differential Privacy},
 journal = {Found. Trends Theor. Comput. Sci.},
 issue_date = {August 2014},
 month = aug,
 year = {2014},
 issn = {1551-305X},
 pages = {211--407},
} 
@article{Apple,
	Author = {Andy Greenberg},
	Date-Added = {2018-08-21 19:59:41 -0400},
	Date-Modified = {2018-08-21 19:59:41 -0400},
	Journal = {Wired},
	Month = {Jun 13},
	Title = {Apple's `Differential Privacy' Is About Collecting Your Data---But Not {\em Your} Data},
	Year = {2016}}
	
	@misc{Vilhuber17Proceedings,
	Author = {Lars Vilhuber and Ian M. Schmutte and John M. Abowd},
	Date-Added = {2017-04-21 13:47:25 +0000},
	Date-Modified = {2017-04-21 13:51:01 +0000},
	Month = {Jan},
	Title = {Proceedings from the 2016 {NSF}--{Sloan} Workshop on Practical Privacy},
	Year = {2017}}
@misc{Census1, 
title="Disclosure Avoidance and the 2020 Census",
howpublished ="\url{https://www.census.gov/about/policies/privacy/statistical_safeguards/disclosure-avoidance-2020-census.html/}",
year=2020}
@INPROCEEDINGS{Census2,
  author={A. {Machanavajjhala} and D. {Kifer} and J. {Abowd} and J. {Gehrke} and L. {Vilhuber}},
  booktitle={2008 IEEE 24th International Conference on Data Engineering}, 
  title={Privacy: Theory meets Practice on the Map}, 
  year={2008},
  volume={},
  number={},
  pages={277-286},}
  @INPROCEEDINGS{Chaabane12youare,
    author = {Abdelberi Chaabane and Gergely Acs and Mohamed Ali Kaafar},
    title = {You Are What You Like! Information Leakage Through Users’ Interests},
    booktitle = {In NDSS},
    year = {2012}
}
@misc{feldman2020hiding,
      title={Hiding Among the Clones: A Simple and Nearly Optimal Analysis of Privacy Amplification by Shuffling}, 
      author={Vitaly Feldman and Audra McMillan and Kunal Talwar},
      year={2020},
      eprint={2012.12803},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{TSP,
author={Balas, E., Simonetti, N. Vazacopoulos, A.},
title={Job shop scheduling with setup times, deadlines and precedence constraints},
url={https://doi.org/10.1007/s10951-008-0067-7},
year={2008},
pages={253–262},
Journal={J Sched},
Volume={11}}

@inproceedings{Bittau2017,
author = {Bittau, Andrea and Erlingsson, \'{U}lfar and Maniatis, Petros and Mironov, Ilya and Raghunathan, Ananth and Lie, David and Rudominer, Mitch and Kode, Ushasree and Tinnes, Julien and Seefeld, Bernhard},
title = {Prochlo: Strong Privacy for Analytics in the Crowd},
year = {2017},
isbn = {9781450350853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132747.3132769},
doi = {10.1145/3132747.3132769},
abstract = {The large-scale monitoring of computer users' software activities has become commonplace, e.g., for application telemetry, error reporting, or demographic profiling. This paper describes a principled systems architecture---Encode, Shuffle, Analyze (ESA)---for performing such monitoring with high utility while also protecting user privacy. The ESA design, and its Prochlo implementation, are informed by our practical experiences with an existing, large deployment of privacy-preserving software monitoring.With ESA, the privacy of monitored users' data is guaranteed by its processing in a three-step pipeline. First, the data is encoded to control scope, granularity, and randomness. Second, the encoded data is collected in batches subject to a randomized threshold, and blindly shuffled, to break linkability and to ensure that individual data items get "lost in the crowd" of the batch. Third, the anonymous, shuffled data is analyzed by a specific analysis engine that further prevents statistical inference attacks on analysis results.ESA extends existing best-practice methods for sensitive-data analytics, by using cryptography and statistical techniques to make explicit how data is elided and reduced in precision, how only common-enough, anonymous data is analyzed, and how this is done for only specific, permitted purposes. As a result, ESA remains compatible with the established workflows of traditional database analysis.Strong privacy guarantees, including differential privacy, can be established at each processing step to defend against malice or compromise at one or more of those steps. Prochlo develops new techniques to harden those steps, including the Stash Shuffle, a novel scalable and efficient oblivious-shuffling algorithm based on Intel's SGX, and new applications of cryptographic secret sharing and blinding. We describe ESA and Prochlo, as well as experiments that validate their ability to balance utility and privacy.},
booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
pages = {441–459},
numpages = {19},
location = {Shanghai, China},
series = {SOSP '17}
}
@misc{birth,
author = {La Corte, Rachel}, 
title={Supreme Court: State employee birthdates are public record},
howpublished="\url{https://apnews.com/article/c1ff652f271947b2884dfe1216a11bc2/}",
year={2019}}
@misc{home,
author = {CheckCriminalRecord.com}
title={Which Parts of Your Personal Data Are Considered “Public Record”?},
howpublished="\url{https://www.checkcriminalrecord.com/which-parts-of-your-personal-data-are-considered-public-record/}", 

}

@inproceedings{shuffling1,
author = {Erlingsson, {\'U}lfar and Feldman, Vitaly and Mironov, Ilya and Raghunathan, Ananth and Talwar, Kunal and Thakurta, Abhradeep},
title = {Amplification by Shuffling: From Local to Central Differential Privacy via Anonymity},
year = {2019},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
booktitle = {Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {2468–2479},
numpages = {12},
location = {San Diego, California},
series = {SODA ’19}
}

@InProceedings{blanket,
author="Balle, Borja
and Bell, James
and Gasc{\'o}n, Adri{\`a}
and Nissim, Kobbi",
editor="Boldyreva, Alexandra
and Micciancio, Daniele",
title="The Privacy Blanket of the Shuffle Model",
booktitle="Advances in Cryptology -- CRYPTO 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="638--667",
abstract="This work studies differential privacy in the context of the recently proposed shuffle model. Unlike in the local model, where the server collecting privatized data from users can track back an input to a specific user, in the shuffle model users submit their privatized inputs to a server anonymously. This setup yields a trust model which sits in between the classical curator and local models for differential privacy. The shuffle model is the core idea in the Encode, Shuffle, Analyze (ESA) model introduced by Bittau et al. (SOPS 2017). Recent work by Cheu et al. (EUROCRYPT 2019) analyzes the differential privacy properties of the shuffle model and shows that in some cases shuffled protocols provide strictly better accuracy than local protocols. Additionally, Erlingsson et al. (SODA 2019) provide a privacy amplification bound quantifying the level of curator differential privacy achieved by the shuffle model in terms of the local differential privacy of the randomizer used by each user.",
isbn="978-3-030-26951-7"
}
@article{semantics,
  title={On the 'Semantics' of Differential Privacy: A Bayesian Formulation},
  author={S. Kasiviswanathan and A. Smith},
  journal={J. Priv. Confidentiality},
  year={2014},
  volume={6}
}
@inproceedings{deep2021ranked,
title={Ranked Enumeration of Conjunctive Query Results},
author={Deep, Shaleen and Koutris, Paraschos},
booktitle={24th International Conference on Database Theory (ICDT 2021)},
year={2021},
organization={Schloss Dagstuhl-Leibniz-Zentrum f{\"u}r Informatik}
}
@inproceedings{deep2021enumeration,
title={Enumeration Algorithms for Conjunctive Queries with Projection},
author={Deep, Shaleen and Hu, Xiao and Koutris, Paraschos},
booktitle={24th International Conference on Database Theory (ICDT 2021)},
year={2021},
organization={Schloss Dagstuhl-Leibniz-Zentrum f{\"u}r Informatik}
}
@InProceedings{shuffle2,
author="Cheu, Albert
and Smith, Adam
and Ullman, Jonathan
and Zeber, David
and Zhilyaev, Maxim",
editor="Ishai, Yuval
and Rijmen, Vincent",
title="Distributed Differential Privacy via Shuffling",
booktitle="Advances in Cryptology -- EUROCRYPT 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="375--403",
abstract="We consider the problem of designing scalable, robust protocols for computing statistics about sensitive data. Specifically, we look at how best to design differentially private protocols in a distributed setting, where each user holds a private datum. The literature has mostly considered two models: the ``central'' model, in which a trusted server collects users' data in the clear, which allows greater accuracy; and the ``local'' model, in which users individually randomize their data, and need not trust the server, but accuracy is limited. Attempts to achieve the accuracy of the central model without a trusted server have so far focused on variants of cryptographic multiparty computation (MPC), which limits scalability.",
isbn="978-3-030-17653-2"
}
@article{IP,
  author    = {Arpita Ghosh and
               Robert Kleinberg},
  title     = {Inferential Privacy Guarantees for Differentially Private Mechanisms},
  journal   = {CoRR},
  volume    = {abs/1603.01508},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.01508},
  archivePrefix = {arXiv},
  eprint    = {1603.01508},
  timestamp = {Mon, 13 Aug 2018 16:48:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/GhoshK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@MISC{TSP,
    author = {Christian Nilsson},
    title = {Heuristics for the Traveling Salesman Problem},
    year = {2003}
}
@article{MM,
    author = {MALLOWS, C. L.},
    title = "{NON-NULL RANKING MODELS. I}",
    journal = {Biometrika},
    volume = {44},
    number = {1-2},
    pages = {114-130},
    year = {1957},
    month = {06},
    issn = {0006-3444},
    doi = {10.1093/biomet/44.1-2.114},
    url = {https://doi.org/10.1093/biomet/44.1-2.114},
    eprint = {https://academic.oup.com/biomet/article-pdf/44/1-2/114/752590/44-1-2-114.pdf},
}
@misc{Syn,
title={Synthetic Dataset},
year=2021,
url={https://anonymous.4open.science/r/2ab201ef-0928-4775-afd0-7608e1e50cba/}
}

@InProceedings{bounded,
  author =	{Katrina Ligett and Charlotte Peale and Omer Reingold},
  title =	{{Bounded-Leakage Differential Privacy}},
  booktitle =	{1st Symposium on Foundations of Responsible Computing (FORC 2020)},
  pages =	{10:1--10:20},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-142-9},
  ISSN =	{1868-8969},
  year =	{2020},
  volume =	{156},
  editor =	{Aaron Roth},
  publisher =	{Schloss Dagstuhl--Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/opus/volltexte/2020/12026},
  URN =		{urn:nbn:de:0030-drops-120265},
  doi =		{10.4230/LIPIcs.FORC.2020.10},
  annote =	{Keywords: differential privacy, applications, privacy, leakage, auxiliary information}
}
@misc{PUDF,title={Hospital Discharge Data Public Use Data File}, howpublished = "\url{https://www.dshs.state.tx.us/THCIC/Hospitals/Download.shtm}"}
@misc{UCI,title={UCI Machine Learning Repository}, author=
{A.Asuncion and D.Newman},year=2010}
@misc{derangement,
title={Derangement},
howpublished="\url{https://en.wikipedia.org/wiki/Derangement}"}
@inproceedings{profile,
  author    = {Joseph Geumlek and
               Kamalika Chaudhuri},
  title     = {Profile-based Privacy for Locally Private Computations},
  booktitle = {{IEEE} International Symposium on Information Theory, {ISIT} 2019,
               Paris, France, July 7-12, 2019},
  pages     = {537--541},
  publisher = {{IEEE}},
  year      = {2019},
  url       = {https://doi.org/10.1109/ISIT.2019.8849549},
  doi       = {10.1109/ISIT.2019.8849549},
  timestamp = {Wed, 16 Oct 2019 14:14:48 +0200},
  biburl    = {https://dblp.org/rec/conf/isit/GeumlekC19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Takao,
  author    = {Yusuke Kawamoto and
               Takao Murakami},
  title     = {Differentially Private Obfuscation Mechanisms for Hiding Probability
               Distributions},
  journal   = {CoRR},
  volume    = {abs/1812.00939},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.00939},
  archivePrefix = {arXiv},
  eprint    = {1812.00939},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-00939.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{Evfimievski:2003:LPB:773153.773174,
 author = {Evfimievski, Alexandre and Gehrke, Johannes and Srikant, Ramakrishnan},
 title = {Limiting Privacy Breaches in Privacy Preserving Data Mining},
 booktitle = {Proceedings of the Twenty-second ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems},
 series = {PODS '03},
 year = {2003},
 isbn = {1-58113-670-6},
 location = {San Diego, California},
 pages = {211--222},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/773153.773174},
 doi = {10.1145/773153.773174},
 acmid = {773174},
 publisher = {ACM},
 address = {New York, NY, USA},
}
@article{Warner,
author={Warner, Stanley L},
title={Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias},
journal={Journal of the American Statistical Association}, volume={60 60, no. 309},year={ 1965}, pages={ 63-69} }
@INPROCEEDINGS{Kasivi,
  author={S. P. {Kasiviswanathan} and H. K. {Lee} and K. {Nissim} and S. {Raskhodnikova} and A. {Smith}},
  booktitle={2008 49th Annual IEEE Symposium on Foundations of Computer Science}, 
  title={What Can We Learn Privately?}, 
  year={2008},
  volume={},
  number={},
  pages={531-540},
  doi={10.1109/FOCS.2008.27}}
@misc{AP,
      title={Attribute Privacy: Framework and Mechanisms}, 
      author={Wanrong Zhang and Olga Ohrimenko and Rachel Cummings},
      year={2020},
      eprint={2009.04013},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@InProceedings{crowd,
author="Gehrke, Johannes
and Hay, Michael
and Lui, Edward
and Pass, Rafael",
editor="Safavi-Naini, Reihaneh
and Canetti, Ran",
title="Crowd-Blending Privacy",
booktitle="Advances in Cryptology -- CRYPTO 2012",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="479--496",
abstract="We introduce a new definition of privacy called crowd-blending privacy that strictly relaxes the notion of differential privacy. Roughly speaking, k-crowd blending private sanitization of a database requires that each individual i in the database ``blends'' with k other individuals j in the database, in the sense that the output of the sanitizer is ``indistinguishable'' if i's data is replaced by j's.",
isbn="978-3-642-32009-5"
}

@article{Dalenius:1977,
  added-at = {2013-03-25T19:03:53.000+0100},
  author = {Dalenius, Tore},
  biburl = {https://www.bibsonomy.org/bibtex/2a6ff1ff0735e4efb017a100a275f4b9f/privtec},
  interhash = {c3374a66a20f1a21a641bac0993d24d2},
  intrahash = {a6ff1ff0735e4efb017a100a275f4b9f},
  journal = {Statistik Tidskrift},
  keywords = {},
  owner = {jonny},
  pages = {429--444},
  timestamp = {2013-03-25T22:11:36.000+0100},
  title = {{T}owards a methodology for statistical disclosure control},
  volume = 15,
  year = 1977
}
@inproceedings{DDP,
  added-at = {2017-03-09T00:00:00.000+0100},
  author = {Liu, Changchang and Chakraborty, Supriyo and Mittal, Prateek},
  biburl = {https://www.bibsonomy.org/bibtex/22332c86bdd854b11bff88526f70cf8f7/dblp},
  booktitle = {NDSS},
  ee = {http://www.internetsociety.org/sites/default/files/blogs-media/dependence-makes-you-vulnerable-differential-privacy-under-dependent-tuples.pdf},
  interhash = {3479f2a3d030085d4e76b50a6a9f7bb7},
  intrahash = {2332c86bdd854b11bff88526f70cf8f7},
  keywords = {dblp},
  publisher = {The Internet Society},
  timestamp = {2017-03-10T11:36:09.000+0100},
  title = {Dependence Makes You Vulnberable: Differential Privacy Under Dependent Tuples.},
  url = {http://dblp.uni-trier.de/db/conf/ndss/ndss2016.html#LiuMC16},
  year = 2016
}

@INPROCEEDINGS{CWP,
  author={R. {Bassily} and A. {Groce} and J. {Katz} and A. {Smith}},
  booktitle={2013 IEEE 54th Annual Symposium on Foundations of Computer Science}, 
  title={Coupled-Worlds Privacy: Exploiting Adversarial Uncertainty in Statistical Data Privacy}, 
  year={2013},
  volume={},
  number={},
  pages={439-448},
  doi={10.1109/FOCS.2013.54}}

@inproceedings{Blowfish,
author = {He, Xi and Machanavajjhala, Ashwin and Ding, Bolin},
title = {Blowfish Privacy: Tuning Privacy-Utility Trade-Offs Using Policies},
year = {2014},
isbn = {9781450323765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2588555.2588581},
doi = {10.1145/2588555.2588581},
abstract = {Privacy definitions provide ways for trading-off the privacy of individuals in a statistical database for the utility of downstream analysis of the data. In this paper, we present Blowfish, a class of privacy definitions inspired by the Pufferfish framework, that provides a rich interface for this trade-off. In particular, we allow data publishers to extend differential privacy using a policy, which specifies (a) secrets, or information that must be kept secret, and (b) constraints that may be known about the data. While the secret specification allows increased utility by lessening protection for certain individual properties, the constraint specification provides added protection against an adversary who knows correlations in the data (arising from constraints). We formalize policies and present novel algorithms that can handle general specifications of sensitive information and certain count constraints. We show that there are reasonable policies under which our privacy mechanisms for k-means clustering, histograms and range queries introduce significantly lesser noise than their differentially private counterparts. We quantify the privacy-utility trade-offs for various policies analytically and empirically on real datasets.},
booktitle = {Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data},
pages = {1447–1458},
numpages = {12},
keywords = {privacy, blowfish privacy, differential privacy},
location = {Snowbird, Utah, USA},
series = {SIGMOD '14}
}
@ARTICLE{correlated2,
  author={T. {Zhu} and P. {Xiong} and G. {Li} and W. {Zhou}},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Correlated Differential Privacy: Hiding Information in Non-IID Data Set}, 
  year={2015},
  volume={10},
  number={2},
  pages={229-242},
  doi={10.1109/TIFS.2014.2368363}}
@article{correlated,
author = {Chen, Rui and Fung, Benjamin C. and Yu, Philip S. and Desai, Bipin C.},
title = {Correlated Network Data Publication via Differential Privacy},
year = {2014},
issue_date = {August 2014},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {23},
number = {4},
issn = {1066-8888},
url = {https://doi.org/10.1007/s00778-013-0344-8},
doi = {10.1007/s00778-013-0344-8},
abstract = {With the increasing prevalence of information networks, research on privacy-preserving network data publishing has received substantial attention recently. There are two streams of relevant research, targeting different privacy requirements. A large body of existing works focus on preventing node re-identification against adversaries with structural background knowledge, while some other studies aim to thwart edge disclosure. In general, the line of research on preventing edge disclosure is less fruitful, largely due to lack of a formal privacy model. The recent emergence of differential privacy has shown great promise for rigorous prevention of edge disclosure. Yet recent research indicates that differential privacy is vulnerable to data correlation, which hinders its application to network data that may be inherently correlated. In this paper, we show that differential privacy could be tuned to provide provable privacy guarantees even in the correlated setting by introducing an extra parameter, which measures the extent of correlation. We subsequently provide a holistic solution for non-interactive network data publication. First, we generate a private vertex labeling for a given network dataset to make the corresponding adjacency matrix form dense clusters. Next, we adaptively identify dense regions of the adjacency matrix by a data-dependent partitioning process. Finally, we reconstruct a noisy adjacency matrix by a novel use of the exponential mechanism. To our best knowledge, this is the first work providing a practical solution for publishing real-life network data via differential privacy. Extensive experiments demonstrate that our approach performs well on different types of real-life network datasets.},
journal = {The VLDB Journal},
month = aug,
pages = {653–676},
numpages = {24},
keywords = {Data correlation, Differential privacy, Non-interactive publication, Network data}
}

@article{Pufferfish,
author = {Kifer, Daniel and Machanavajjhala, Ashwin},
title = {Pufferfish: A Framework for Mathematical Privacy Definitions},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {1},
issn = {0362-5915},
url = {https://doi.org/10.1145/2514689},
doi = {10.1145/2514689},
abstract = {In this article, we introduce a new and general privacy framework called Pufferfish. The Pufferfish framework can be used to create new privacy definitions that are customized to the needs of a given application. The goal of Pufferfish is to allow experts in an application domain, who frequently do not have expertise in privacy, to develop rigorous privacy definitions for their data sharing needs. In addition to this, the Pufferfish framework can also be used to study existing privacy definitions.We illustrate the benefits with several applications of this privacy framework: we use it to analyze differential privacy and formalize a connection to attackers who believe that the data records are independent; we use it to create a privacy definition called hedging privacy, which can be used to rule out attackers whose prior beliefs are inconsistent with the data; we use the framework to define and study the notion of composition in a broader context than before; we show how to apply the framework to protect unbounded continuous attributes and aggregate information; and we show how to use the framework to rigorously account for prior data releases.},
journal = {ACM Trans. Database Syst.},
month = jan,
articleno = {3},
numpages = {36},
keywords = {Privacy, differential privacy}
}



@Article{dwork2010on,
author = {Dwork, Cynthia and Naor, Moni},
title = {On the Difficulties of Disclosure Prevention in Statistical Databases or The Case for Differential Privacy},
year = {2010},
month = {January},
abstract = {In 1977 Tore Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a natural formalization of Dalenius’ goal cannot be achieved if the database is useful. The key obstacle is the side information that may be available to an adversary. Our results hold under very general conditions regarding the database, the notion of privacy violation, and the notion of utility.

Contrary to intuition, a variant of the result threatens the privacy even of someone not in the database. This state of affairs motivated the notion of differential privacy [15, 16], a strong ad omnia privacy which, intuitively, captures the increased risk to one’s privacy incurred by participating in a database.},
% url = {https://www.microsoft.com/en-us/research/publication/on-the-difficulties-of-disclosure-prevention-in-statistical-databases-or-the-case-for-differential-privacy/},
pages = {93-107},
journal = {Journal of Privacy and Confidentiality},
volume = {2},
edition = {Journal of Privacy and Confidentiality},
}
@InProceedings{noiseless,
author="Bhaskar, Raghav
and Bhowmick, Abhishek
and Goyal, Vipul
and Laxman, Srivatsan
and Thakurta, Abhradeep",
editor="Lee, Dong Hoon
and Wang, Xiaoyun",
title="Noiseless Database Privacy",
booktitle="Advances in Cryptology -- ASIACRYPT 2011",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="215--232",
abstract="Differential Privacy (DP) has emerged as a formal, flexible framework for privacy protection, with a guarantee that is agnostic to auxiliary information and that admits simple rules for composition. Benefits notwithstanding, a major drawback of DP is that it provides noisy responses to queries, making it unsuitable for many applications. We propose a new notion called Noiseless Privacy that provides exact answers to queries, without adding any noise whatsoever. While the form of our guarantee is similar to DP, where the privacy comes from is very different, based on statistical assumptions on the data and on restrictions to the auxiliary information available to the adversary. We present a first set of results for Noiseless Privacy of arbitrary Boolean-function queries and of linear Real-function queries, when data are drawn independently, from nearly-uniform and Gaussian distributions respectively. We also derive simple rules for composition under models of dynamically changing data.",
isbn="978-3-642-25385-0"
}

@inproceedings{TNP,
author = {Grining, Krzysztof and Klonowski, Marek},
title = {Towards Extending Noiseless Privacy: Dependent Data and More Practical Approach},
year = {2017},
isbn = {9781450349444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3052973.3052992},
doi = {10.1145/3052973.3052992},
abstract = {In 2011 Bhaskar et al. pointed out that in many cases one can ensure sufficient level of privacy without adding noise by utilizing adversarial uncertainty. Informally speaking, this observation comes from the fact that if at least a part of the data is randomized from the adversary's point of view, it can be effectively used for hiding other values.So far the approach to that idea in the literature was mostly purely asymptotic, which greatly limited its adaptation in real-life scenarios. In this paper we aim to make the concept of utilizing adversarial uncertainty not only an interesting theoretical idea, but rather a practically useful technique, complementary to differential privacy, which is the state-of-the-art definition of privacy. This requires non-asymptotic privacy guarantees, more realistic approach to the randomness inherently present in the data and to the adversary's knowledge.In our paper we extend the concept proposed by Bhaskar et al. and present some results for wider class of data. In particular we cover the data sets that are dependent. We also introduce rigorous adversarial model. Moreover, in contrast to most of previous papers in this field, we give detailed (non-asymptotic) results which is motivated by practical reasons. Note that it required a modified approach and more subtle mathematical tools, including Stein method which, to the best of our knowledge, was not used in privacy research before.Apart from that, we show how to combine adversarial uncertainty with differential privacy approach and explore synergy between them to enhance the privacy parameters already present in the data itself by adding small amount of noise.},
booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
pages = {546–560},
numpages = {15},
keywords = {distributed system, differential privacy, data aggregation},
location = {Abu Dhabi, United Arab Emirates},
series = {ASIA CCS '17}
}
@inproceedings{ZKPrivacy,
author = {Gehrke, Johannes and Lui, Edward and Pass, Rafael},
title = {Towards Privacy for Social Networks: A Zero-Knowledge Based Definition of Privacy},
year = {2011},
isbn = {9783642195709},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {We put forward a zero-knowledge based definition of privacy. Our notion is strictly stronger than the notion of differential privacy and is particularly attractive when modeling privacy in social networks. We furthermore demonstrate that it can be meaningfully achieved for tasks such as computing averages, fractions, histograms, and a variety of graph parameters and properties, such as average degree and distance to connectivity. Our results are obtained by establishing a connection between zero-knowledge privacy and sample complexity, and by leveraging recent sublinear time algorithms.},
booktitle = {Proceedings of the 8th Conference on Theory of Cryptography},
pages = {432–449},
numpages = {18},
location = {Providence, RI},
series = {TCC'11}
}

@inproceedings{BDP,
author = {Yang, Bin and Sato, Issei and Nakagawa, Hiroshi},
title = {Bayesian Differential Privacy on Correlated Data},
year = {2015},
isbn = {9781450327589},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2723372.2747643},
doi = {10.1145/2723372.2747643},
abstract = {Differential privacy provides a rigorous standard for evaluating the privacy of perturbation algorithms. It has widely been regarded that differential privacy is a universal definition that deals with both independent and correlated data and a differentially private algorithm can protect privacy against arbitrary adversaries. However, recent research indicates that differential privacy may not guarantee privacy against arbitrary adversaries if the data are correlated.In this paper, we focus on the private perturbation algorithms on correlated data. We investigate the following three problems: (1) the influence of data correlations on privacy; (2) the influence of adversary prior knowledge on privacy; and (3) a general perturbation algorithm that is private for prior knowledge of any subset of tuples in the data when the data are correlated. We propose a Pufferfish definition of privacy, called Bayesian differential privacy, by which the privacy level of a probabilistic perturbation algorithm can be evaluated even when the data are correlated and when the prior knowledge is incomplete. We present a Gaussian correlation model to accurately describe the structure of data correlations and analyze the Bayesian differential privacy of the perturbation algorithm on the basis of this model. Our results show that privacy is poorest for an adversary who has the least prior knowledge. We further extend this model to a more general one that considers uncertain prior knowledge.},
booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
pages = {747–762},
numpages = {16},
keywords = {gaussian markov random field, differential privacy, output perturbation, private data analysis, optimization},
location = {Melbourne, Victoria, Australia},
series = {SIGMOD '15}
}

@inproceedings{Song,
author = {Song, Shuang and Wang, Yizhen and Chaudhuri, Kamalika},
title = {Pufferfish Privacy Mechanisms for Correlated Data},
year = {2017},
isbn = {9781450341974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3035918.3064025},
doi = {10.1145/3035918.3064025},
abstract = {Many modern databases include personal and sensitive correlated data, such as private information on users connected together in a social network, and measurements of physical activity of single subjects across time. However, differential privacy, the current gold standard in data privacy, does not adequately address privacy issues in this kind of data.This work looks at a recent generalization of differential privacy, called Pufferfish, that can be used to address privacy in correlated data. The main challenge in applying Pufferfish is a lack of suitable mechanisms. We provide the first mechanism -- the Wasserstein Mechanism -- which applies to any general Pufferfish framework. Since this mechanism may be computationally inefficient, we provide an additional mechanism that applies to some practical cases such as physical activity measurements across time, and is computationally efficient. Our experimental evaluations indicate that this mechanism provides privacy and utility for synthetic as well as real data in two separate domains.},
booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},
pages = {1291–1306},
numpages = {16},
keywords = {pufferfish privacy, privacy, differential privacy},
location = {Chicago, Illinois, USA},
series = {SIGMOD '17}
}
@inproceedings{Kifer,
author = {Kifer, Daniel and Machanavajjhala, Ashwin},
title = {No Free Lunch in Data Privacy},
year = {2011},
isbn = {9781450306614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1989323.1989345},
doi = {10.1145/1989323.1989345},
abstract = {Differential privacy is a powerful tool for providing privacy-preserving noisy query answers over statistical databases. It guarantees that the distribution of noisy query answers changes very little with the addition or deletion of any tuple. It is frequently accompanied by popularized claims that it provides privacy without any assumptions about the data and that it protects against attackers who know all but one record. In this paper we critically analyze the privacy protections offered by differential privacy.First, we use a no-free-lunch theorem, which defines non-privacy as a game, to argue that it is not possible to provide privacy and utility without making assumptions about how the data are generated. Then we explain where assumptions are needed. We argue that privacy of an individual is preserved when it is possible to limit the inference of an attacker about the participation of the individual in the data generating process. This is different from limiting the inference about the presence of a tuple (for example, Bob's participation in a social network may cause edges to form between pairs of his friends, so that it affects more than just the tuple labeled as "Bob"). The definition of evidence of participation, in turn, depends on how the data are generated -- this is how assumptions enter the picture. We explain these ideas using examples from social network research as well as tabular data for which deterministic statistics have been previously released. In both cases the notion of participation varies, the use of differential privacy can lead to privacy breaches, and differential privacy does not always adequately limit inference about participation.},
booktitle = {Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data},
pages = {193–204},
numpages = {12},
keywords = {differential privacy, privacy},
location = {Athens, Greece},
series = {SIGMOD '11}
}


@inproceedings{calibration,
  title={Predicting good probabilities with supervised learning},
  author={Niculescu-Mizil, Alexandru and Caruana, Rich},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={625--632},
  year={2005}
}

@article{gradientboosting,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@article{insurance, 
title={Comparing Private Payer and Medicare Payment Rates for Select Inpatient Hospital Services},
journal={Kaiser Family Foundation}, 
publisher={Kaiser Family Foundation}, 
author={Eric Lopez, Gary Claxton}, 
year={2020}, 
month={Jul}
}

@article{twitch,
  title={Multi-scale attributed node embedding},
  author={Rozemberczki, Benedek and Allen, Carl and Sarkar, Rik},
  journal={arXiv preprint arXiv:1909.13021},
  year={2019}, 
  url={http://snap.stanford.edu/data/twitch-social-networks.html}
}

@inproceedings{Balcer2020SeparatingL,
  title={Separating Local and Shuffled Differential Privacy via Histograms},
  author={Victor Balcer and Albert Cheu},
  booktitle={ITC},
  year={2020}
}

@article{kanon,
	title = {Achieving k-anonymity privacy protection using generalization and suppression},
	volume = {10},
	issn = {0218-4885},
	url = {https://doi.org/10.1142/S021848850200165X},
	doi = {10.1142/S021848850200165X},
	number = {5},
	urldate = {2020-04-21},
	journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
	author = {Sweeney, Latanya},
	month = oct,
	year = {2002},
	keywords = {privacy, data privacy, re-identification, data fusion, data anonymity},
	pages = {571--588},
	file = {Sweeney - 2002 - Achieving k-anonymity privacy protection using gen.pdf:/Users/casey/Zotero/storage/4SXPBPXK/Sweeney - 2002 - Achieving k-anonymity privacy protection using gen.pdf:application/pdf},
}

@article{anatomy,
	title = {Anatomy: {Privacy} and {Correlation} {Preserving} {Publication}},
	shorttitle = {Anatomy},
	abstract = {This article presents the anatomy technique for anonymized publication of sensitive data. Anatomy releases all the quasi-identifier and sensitive values directly in two separate tables. Combined with a grouping mechanism, this approach effectively protects privacy, and captures a large amount of correla-tion in the microdata. We propose an efficient algorithm for computing anatomized tables that fulfill the l-diversity anonymity requirement, and minimize the error of reconstructing the microdata, according to any L p norm, the KL-divergence, and the discernability metrics. The algorithm is accompanied by optional heuristics that continuously enhance the data utility of anatomy, until a user-specified time limit has been reached. We also provide detailed explanations about how to leverage anatomized tables to understand the characteristics of the microdata. Extensive experiments confirm that anatomy allows sig-nificantly more accurate data analysis than conventional anonymization methods based on generalization and data swapping. The short version of this article appeared in VLDB 06. The current submission improves our preliminary work by (i) including a thorough discussion of the previous methods, (ii) extending the analysis of anatomy to several other metrics of information loss (i.e., generic L p norm, KL-divergence, and discernability), (iii) elaborating how to deploy the anonymized data for statistical studies, (iv) presenting a new algorithm for computing anatomized tables, and (v) featuring a more comprehensive experimental evaluation.},
	author = {Xiao, Xiaokui and Tao, Yufei},
	month = jan,
	year = {2006},
	file = {Full Text PDF:/Users/casey/Zotero/storage/VINE99X8/Xiao and Tao - 2006 - Anatomy Privacy and Correlation Preserving Public.pdf:application/pdf},
}


@article{ldiv,
	title = {L-diversity: {Privacy} beyond k-anonymity},
	volume = {1},
	issn = {1556-4681},
	shorttitle = {L-diversity},
	url = {https://doi.org/10.1145/1217299.1217302},
	doi = {10.1145/1217299.1217302},
	abstract = {Publishing data about individuals without revealing sensitive information about them is an important problem. In recent years, a new definition of privacy called k-anonymity has gained popularity. In a k-anonymized dataset, each record is indistinguishable from at least k − 1 other records with respect to certain identifying attributes. In this article, we show using two simple attacks that a k-anonymized dataset has some subtle but severe privacy problems. First, an attacker can discover the values of sensitive attributes when there is little diversity in those sensitive attributes. This is a known problem. Second, attackers often have background knowledge, and we show that k-anonymity does not guarantee privacy against attackers using background knowledge. We give a detailed analysis of these two attacks, and we propose a novel and powerful privacy criterion called ℓ-diversity that can defend against such attacks. In addition to building a formal foundation for ℓ-diversity, we show in an experimental evaluation that ℓ-diversity is practical and can be implemented efficiently.},
	number = {1},
	urldate = {2020-05-08},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Machanavajjhala, Ashwin and Kifer, Daniel and Gehrke, Johannes and Venkitasubramaniam, Muthuramakrishnan},
	month = mar,
	year = {2007},
	keywords = {Data privacy, k-anonymity, ℓ-diversity, privacy-preserving data publishing},
	pages = {3--es},
	file = {Full Text PDF:/Users/casey/Zotero/storage/AKJQDBRX/Machanavajjhala et al. - 2007 - L-diversity Privacy beyond k-anonymity.pdf:application/pdf},
}


@inproceedings{definetti,
	address = {Providence, Rhode Island, USA},
	series = {{SIGMOD} '09},
	title = {Attacks on privacy and {deFinetti}'s theorem},
	isbn = {978-1-60558-551-2},
	url = {https://doi.org/10.1145/1559845.1559861},
	doi = {10.1145/1559845.1559861},
	abstract = {In this paper we present a method for reasoning about privacy using the concepts of exchangeability and deFinetti's theorem. We illustrate the usefulness of this technique by using it to attack a popular data sanitization scheme known as Anatomy. We stress that Anatomy is not the only sanitization scheme that is vulnerable to this attack. In fact, any scheme that uses the random worlds model, i.i.d. model, or tuple-independent model needs to be re-evaluated. The difference between the attack presented here and others that have been proposedin the past is that we do not need extensive background knowledge. An attacker only needs to know the nonsensitive attributes of one individual in the data, and can carry out this attack just by building a machine learning model over the sanitized data. The reason this attack is successful is that it exploits a subtle flaw in the way prior work computed the probability of disclosure of a sensitive attribute. We demonstrate this theoretically, empirically, and with intuitive examples. We also discuss how this generalizes to many other privacy schemes.},
	urldate = {2020-05-06},
	booktitle = {Proceedings of the 2009 {ACM} {SIGMOD} {International} {Conference} on {Management} of data},
	publisher = {Association for Computing Machinery},
	author = {Kifer, Daniel},
	month = jun,
	year = {2009},
	keywords = {privacy, random worlds},
	pages = {127--138},
	file = {Full Text PDF:/Users/casey/Zotero/storage/FDWDFMTY/Kifer - 2009 - Attacks on privacy and deFinetti's theorem.pdf:application/pdf},
}

@book{dwork_early,
	title = {Calibrating {Noise} to {Sensitivity} in {Private} {Data} {Analysis}},
	volume = {3876},
	isbn = {978-3-540-32731-8},
	url = {https://www.microsoft.com/en-us/research/publication/calibrating-noise-to-sensitivity-in-private-data-analysis/},
	abstract = {We continue a line of research initiated in [10,11] on privacy-preserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function f mapping databases to reals, the so-called true answer is the result of applying f to the database. To protect privacy, the true answer is perturbed by …},
	language = {en-US},
	urldate = {2020-04-21},
	author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
	month = mar,
	year = {2006},
	annote = {All the content of ``Differential Privacy'' but easier to understand
 },
	file = {Snapshot:/Users/casey/Zotero/storage/8E7ASP8U/calibrating-noise-to-sensitivity-in-private-data-analysis.html:text/html;Full Text PDF:/Users/casey/Zotero/storage/FEQ27EA4/Dwork et al. - 2006 - Calibrating Noise to Sensitivity in Private Data A.pdf:application/pdf},
}

@article{resistance_to_data_collection,
  title={Vernacular resistance to data collection and analysis: A political theory of obfuscation},
  author={Brunton, Finn and Nissenbaum, Helen},
  journal={First Monday},
  year={2011}
}


@article{exponential_mechanism,
	title = {Mechanism {Design} via {Differential} {Privacy}},
	url = {https://www.microsoft.com/en-us/research/publication/mechanism-design-via-differential-privacy/},
	abstract = {We study the role that privacy-preserving algorithms, which prevent the leakage of speciﬁc information about participants, can play in the design of mechanisms for strategic agents, which must encourage players to honestly report information. Speciﬁcally, we show that the recent notion of differential privacy [15, 14], in addition to its own intrinsic virtue, can ensure …},
	language = {en-US},
	urldate = {2020-04-12},
	author = {McSherry, Frank and Talwar, Kunal},
	month = oct,
	year = {2007},
	annote = {Discusses composition and post-processing properties of DP
 },
	file = {Snapshot:/Users/casey/Zotero/storage/UM45NJXT/mechanism-design-via-differential-privacy.html:text/html;Full Text PDF:/Users/casey/Zotero/storage/CAUNX7CZ/McSherry and Talwar - 2007 - Mechanism Design via Differential Privacy.pdf:application/pdf},
}

@inproceedings{older1,
  title={Non-homogeneous generalization in privacy preserving data publishing},
  author={Wong, Wai Kit and Mamoulis, Nikos and Cheung, David Wai Lok},
  booktitle={Proceedings of the 2010 ACM SIGMOD International Conference on Management of data},
  pages={747--758},
  year={2010}
}

@article{older2,
  title={k-Concealment: An Alternative Model of k-Type Anonymity.},
  author={Tassa, Tamir and Mazza, Arnon and Gionis, Aristides},
  journal={Trans. Data Priv.},
  volume={5},
  number={1},
  pages={189--222},
  year={2012}
}

@inproceedings{older3,
  title={Anonymizing set-valued data by nonreciprocal recoding},
  author={Xue, Mingqiang and Karras, Panagiotis and Ra{\"\i}ssi, Chedy and Vaidya, Jaideep and Tan, Kian-Lee},
  booktitle={Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={1050--1058},
  year={2012}
}

@article{older4,
  title={Adaptive Anonymity via $ b $-Matching},
  author={Choromanski, Krzysztof M and Jebara, Tony and Tang, Kui},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  pages={3192--3200},
  year={2013}
}

@inproceedings{older5,
  title={k-Anonymization by freeform generalization},
  author={Doka, Katerina and Xue, Mingqiang and Tsoumakos, Dimitrios and Karras, Panagiotis},
  booktitle={Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security},
  pages={519--530},
  year={2015}
}


@article{RIM,
	title = {The repeated insertion model for rankings: {Missing} link between two subset choice models},
	volume = {69},
	issn = {1860-0980},
	shorttitle = {The repeated insertion model for rankings},
	url = {https://doi.org/10.1007/BF02295838},
	doi = {10.1007/BF02295838},
	abstract = {Several probabilistic models for subset choice have been proposed in the literature, for example, to explain approval voting data. We show that Marley et al.'s latent scale model is subsumed by Falmagne and Regenwetter's size-independent model, in the sense that every choice probability distribution generated by the former can also be explained by the latter. Our proof relies on the construction of a probabilistic ranking model which we label the “repeated insertion model.” This model is a special case of Marden's orthogonal contrast model class and, in turn, includes the classical Mallows φ-model as a special case. We explore its basic properties as well as its relationship to Fligner and Verducci's multistage ranking model.},
	language = {en},
	number = {1},
	urldate = {2020-12-04},
	journal = {Psychometrika},
	author = {Doignon, Jean-Paul and Pekeč, Aleksandar and Regenwetter, Michel},
	month = mar,
	year = {2004},
	pages = {33--54},
	file = {Springer Full Text PDF:/Users/casey/Zotero/storage/CRKSP8W6/Doignon et al. - 2004 - The repeated insertion model for rankings Missing.pdf:application/pdf},
}

@misc{adult ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{GI,
  title={Geo-indistinguishability: Differential privacy for location-based systems},
  author={Andr{\'e}s, Miguel E and Bordenabe, Nicol{\'a}s E and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
  journal={arXiv preprint arXiv:1212.1984},
  year={2012}
}

@inproceedings{roth,
  title={Interactive privacy via the median mechanism},
  author={Roth, Aaron and Roughgarden, Tim},
  booktitle={Proceedings of the forty-second ACM symposium on Theory of computing},
  pages={765--774},
  year={2010},
  organization={ACM}
}

@inproceedings{predictive,
  title={A predictive differentially-private mechanism for mobility traces},
  author={Chatzikokolakis, Konstantinos and Palamidessi, Catuscia and Stronati, Marco},
  booktitle={International Symposium on Privacy Enhancing Technologies Symposium},
  pages={21--41},
  year={2014},
  organization={Springer}
}

@article{pufferfish,
  title={Pufferfish: A framework for mathematical privacy definitions},
  author={Kifer, Daniel and Machanavajjhala, Ashwin},
  journal={ACM Transactions on Database Systems (TODS)},
  volume={39},
  number={1},
  pages={3},
  year={2014},
  publisher={ACM}
}

@inproceedings{renyi,
  title={R{\'e}nyi differential privacy},
  author={Mironov, Ilya},
  booktitle={2017 IEEE 30th Computer Security Foundations Symposium (CSF)},
  pages={263--275},
  year={2017},
  organization={IEEE}
}

@article{nyt, 
title = {Your Apps Know Where You Were Last Night, and They're Not Keeping It Secret}, 
author={Valentino-DeVryes, Jennifer; Singer, Natasha; Keller, Michael; Krolik, Aaron}, 
journal={The New York Times},
year={2018}, 
}

@inproceedings{traffic_monitoring,
  title={Differentially private multi-dimensional time series release for traffic monitoring},
  author={Fan, Liyue and Xiong, Li and Sunderam, Vaidy},
  booktitle={IFIP Annual Conference on Data and Applications Security and Privacy},
  pages={33--48},
  year={2013},
  organization={Springer}
}

@inproceedings{aggregated_encryption,
  title={Differentially private aggregation of distributed time-series with transformation and encryption},
  author={Rastogi, Vibhor and Nath, Suman},
  booktitle={Proceedings of the 2010 ACM SIGMOD International Conference on Management of data},
  pages={735--746},
  year={2010},
  organization={ACM}
}

@inproceedings{matrix_mechanism,
  title={Optimizing linear counting queries under differential privacy},
  author={Li, Chao and Hay, Michael and Rastogi, Vibhor and Miklau, Gerome and McGregor, Andrew},
  booktitle={Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems},
  pages={123--134},
  year={2010},
  organization={ACM}
}

@inproceedings{markov,
  title={Composition properties of inferential privacy for time-series data},
  author={Song, Shuang and Chaudhuri, Kamalika},
  booktitle={2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={814--821},
  year={2017},
  organization={IEEE}
}

@article{universal,
  title={Universally utility-maximizing privacy mechanisms},
  author={Ghosh, Arpita and Roughgarden, Tim and Sundararajan, Mukund},
  journal={SIAM Journal on Computing},
  volume={41},
  number={6},
  pages={1673--1693},
  year={2012},
  publisher={SIAM}
}

@inproceedings{temporal,
  title={Protecting locations with differential privacy under temporal correlations},
  author={Xiao, Yonghui and Xiong, Li},
  booktitle={Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security},
  pages={1298--1309},
  year={2015},
  organization={ACM}
}

@inproceedings{subsampled_renyi,
  author    = {Yu{-}Xiang Wang and
               Borja Balle and
               Shiva Prasad Kasiviswanathan},
  title     = {Subsampled Renyi Differential Privacy and Analytical Moments Accountant},
  booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2019, 16-18 April 2019, Naha, Okinawa, Japan},
  pages     = {1226--1235},
  year      = {2019},
  crossref  = {DBLP:conf/aistats/2019},
  url       = {http://proceedings.mlr.press/v89/wang19b.html},
  timestamp = {Fri, 07 Jun 2019 09:03:47 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/aistats/WangBK19},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{geolife,
  title={GeoLife: A collaborative social networking service among user, location and trajectory.},
  author={Zheng, Yu and Xie, Xing and Ma, Wei-Ying and others},
  journal={IEEE Data Eng. Bull.},
  volume={33},
  number={2},
  pages={32--39},
  year={2010},
  publisher={Citeseer}
}

@article{sml2010,
  title={On-line learning of indoor temperature forecasting models towards energy efficiency},
  author={Zamora-Martinez, Fransisco and Romeu, Pablo and Botella-Rocamora, Pablo and Pardo, Juan},
  journal={Energy and Buildings},
  volume={83},
  pages={162--172},
  year={2014},
  publisher={Elsevier}
}

@article{home_monitoring,
  title={Evaluation of three state-of-the-art classifiers for recognition of activities of daily living from smart home ambient data},
  author={Nef, Tobias and Urwyler, Prabitha and B{\"u}chler, Marcel and Tarnanas, Ioannis and Stucki, Reto and Cazzoli, Dario and M{\"u}ri, Ren{\'e} and Mosimann, Urs},
  journal={Sensors},
  volume={15},
  number={5},
  pages={11725--11740},
  year={2015},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{unique_in_the_crowd,
	title = {Unique in the {Crowd}: {The} privacy bounds of human mobility},
	volume = {3},
	copyright = {2013 The Author(s)},
	issn = {2045-2322},
	shorttitle = {Unique in the {Crowd}},
	url = {https://www.nature.com/articles/srep01376},
	doi = {10.1038/srep01376},
	abstract = {We study fifteen months of human mobility data for one and a half million individuals and find that human mobility traces are highly unique. In fact, in a dataset where the location of an individual is specified hourly and with a spatial resolution equal to that given by the carrier's antennas, four spatio-temporal points are enough to uniquely identify 95\% of the individuals. We coarsen the data spatially and temporally to find a formula for the uniqueness of human mobility traces given their resolution and the available outside information. This formula shows that the uniqueness of mobility traces decays approximately as the 1/10 power of their resolution. Hence, even coarse datasets provide little anonymity. These findings represent fundamental constraints to an individual's privacy and have important implications for the design of frameworks and institutions dedicated to protect the privacy of individuals.},
	language = {en},
	number = {1},
	urldate = {2020-05-06},
	journal = {Scientific Reports},
	author = {de Montjoye, Yves-Alexandre and Hidalgo, César A. and Verleysen, Michel and Blondel, Vincent D.},
	month = mar,
	year = {2013},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {threat example},
	pages = {1--5},
	file = {Full Text PDF:/Users/cmm/Zotero/storage/M9WBP3XF/de Montjoye et al. - 2013 - Unique in the Crowd The privacy bounds of human m.pdf:application/pdf;Snapshot:/Users/cmm/Zotero/storage/MAKKXHIZ/srep01376.html:text/html}
}

@inproceedings{priste,
	title = {{PriSTE}: {From} {Location} {Privacy} to {Spatiotemporal} {Event} {Privacy}},
	shorttitle = {{PriSTE}},
	doi = {10.1109/ICDE.2019.00153},
	abstract = {Location privacy-preserving mechanisms (LPPMs) have been extensively studied for protecting a user's location at each time point or a sequence of locations with different timestamps (i.e., a trajectory). We argue that existing LPPMs are not capable of protecting the sensitive information in user's spatiotemporal activities, such as "visited hospital in the last week" or "regularly commuting between Address 1 and Address 2 every morning and afternoon" (it is easy to infer that Addresses 1 and 2 may be home and office). To address this problem, we define the spatiotemporal event as a new privacy goal, which can be formalized as Boolean expressions between location and time predicates. We show that the spatiotemporal event is a generalization of a single location or a trajectory which is protected by existing LPPMs, while some types of spatiotemporal event may not be protected by the existing LPPMs. Hence, we formally define -spatiotemporal event privacy which is an indistinguishability-based privacy metric. It turns out that, interestingly, such privacy metric is orthogonal to the existing indistinguishability-based location privacy metric such as Geo-indistinguishability. We also discussed the potential solution to achieve both -spatiotemporal event privacy and Geo-indistinguishability.},
	booktitle = {2019 {IEEE} 35th {International} {Conference} on {Data} {Engineering} ({ICDE})},
	author = {Cao, Yang and Xiao, Yonghui and Xiong, Li and Bai, Liquan},
	month = apr,
	year = {2019},
	note = {ISSN: 2375-026X},
	keywords = {data privacy, Data privacy, differential privacy, Google, Hospitals, indistinguishability-based location privacy metric, location privacy, location privacy-preserving mechanisms, LPPM, Measurement, Privacy, privacy goal, single location, spatiotemporal data, spatiotemporal event, spatiotemporal event privacy, Spatiotemporal phenomena, time predicates, Trajectory},
	pages = {1606--1609},
	file = {IEEE Xplore Abstract Record:/Users/cmm/Zotero/storage/X7Z3X3P2/8731480.html:text/html;Submitted Version:/Users/cmm/Zotero/storage/BPNZM78H/Cao et al. - 2019 - PriSTE From Location Privacy to Spatiotemporal Ev.pdf:application/pdf}
}

@inproceedings{bayesian_DP,
	address = {Melbourne, Victoria, Australia},
	series = {{SIGMOD} '15},
	title = {Bayesian {Differential} {Privacy} on {Correlated} {Data}},
	isbn = {978-1-4503-2758-9},
	url = {https://doi.org/10.1145/2723372.2747643},
	doi = {10.1145/2723372.2747643},
	abstract = {Differential privacy provides a rigorous standard for evaluating the privacy of perturbation algorithms. It has widely been regarded that differential privacy is a universal definition that deals with both independent and correlated data and a differentially private algorithm can protect privacy against arbitrary adversaries. However, recent research indicates that differential privacy may not guarantee privacy against arbitrary adversaries if the data are correlated. In this paper, we focus on the private perturbation algorithms on correlated data. We investigate the following three problems: (1) the influence of data correlations on privacy; (2) the influence of adversary prior knowledge on privacy; and (3) a general perturbation algorithm that is private for prior knowledge of any subset of tuples in the data when the data are correlated. We propose a Pufferfish definition of privacy, called Bayesian differential privacy, by which the privacy level of a probabilistic perturbation algorithm can be evaluated even when the data are correlated and when the prior knowledge is incomplete. We present a Gaussian correlation model to accurately describe the structure of data correlations and analyze the Bayesian differential privacy of the perturbation algorithm on the basis of this model. Our results show that privacy is poorest for an adversary who has the least prior knowledge. We further extend this model to a more general one that considers uncertain prior knowledge.},
	urldate = {2020-04-12},
	booktitle = {Proceedings of the 2015 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Yang, Bin and Sato, Issei and Nakagawa, Hiroshi},
	month = may,
	year = {2015},
	keywords = {differential privacy, gaussian markov random field, optimization, output perturbation, private data analysis},
	pages = {747--762},
	annote = {Provides a definition of DP that requires specifying associations.
Uses strong adversary def'n of DP.
Suggests that DP implies independence.},
	file = {Full Text PDF:/Users/cmm/Zotero/storage/V5VSHZRD/Yang et al. - 2015 - Bayesian Differential Privacy on Correlated Data.pdf:application/pdf}
}

@inproceedings{synthesizing_plausible_deniability,
	title = {Synthesizing {Plausible} {Privacy}-{Preserving} {Location} {Traces}},
	doi = {10.1109/SP.2016.39},
	abstract = {Camouflaging user's actual location with fakes is a prevalent obfuscation technique for protecting location privacy. We show that the protection mechanisms based on the existing (ad hoc) techniques for generating fake locations are easily broken by inference attacks. They are also detrimental to many utility functions, as they fail to credibly imitate the mobility of living people. This paper introduces a systematic approach to synthesizing plausible location traces. We propose metrics that capture both geographic and semantic features of real location traces. Based on these statistical metrics, we design a privacy-preserving generative model to synthesize location traces which are plausible to be trajectories of some individuals with consistent lifestyles and meaningful mobilities. Using a state-of-the-art quantitative framework, we show that our synthetic traces can significantly paralyze location inference attacks. We also show that these fake traces have many useful statistical features in common with real traces, thus can be used in many geo-data analysis tasks. We guarantee that the process of generating synthetic traces itself is privacy preserving and ensures plausible deniability. Thus, although the crafted traces statistically resemble human mobility, they do not leak significant information about any particular individual whose data is used in the synthesis process.},
	booktitle = {2016 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Bindschaedler, Vincent and Shokri, Reza},
	month = may,
	year = {2016},
	note = {ISSN: 2375-1207},
	keywords = {Aggregates, data analysis, Data privacy, data protection, Feature extraction, geodata analysis, LBS, location privacy protection, location trace synthesis, location-based service, Measurement, mobile computing, Privacy, privacy-preserving generative model, security of data, Semantics, statistical analysis, statistical metric, Trajectory},
	pages = {546--563},
	file = {IEEE Xplore Full Text PDF:/Users/cmm/Zotero/storage/G76VSLWN/Bindschaedler and Shokri - 2016 - Synthesizing Plausible Privacy-Preserving Location.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/cmm/Zotero/storage/KDDGMX8Y/7546522.html:text/html}
}

@article{plausible_deniability,
	title = {Plausible deniability for privacy-preserving data synthesis},
	volume = {10},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3055540.3055542},
	doi = {10.14778/3055540.3055542},
	abstract = {Releasing full data records is one of the most challenging problems in data privacy. On the one hand, many of the popular techniques such as data de-identification are problematic because of their dependence on the background knowledge of adversaries. On the other hand, rigorous methods such as the exponential mechanism for differential privacy are often computationally impractical to use for releasing high dimensional data or cannot preserve high utility of original data due to their extensive data perturbation. This paper presents a criterion called plausible deniability that provides a formal privacy guarantee, notably for releasing sensitive datasets: an output record can be released only if a certain amount of input records are indistinguishable, up to a privacy parameter. This notion does not depend on the background knowledge of an adversary. Also, it can efficiently be checked by privacy tests. We present mechanisms to generate synthetic datasets with similar statistical properties to the input data and the same format. We study this technique both theoretically and experimentally. A key theoretical result shows that, with proper randomization, the plausible deniability mechanism generates differentially private synthetic data. We demonstrate the efficiency of this generative technique on a large dataset; it is shown to preserve the utility of original data with respect to various statistical analysis and machine learning measures.},
	number = {5},
	urldate = {2020-04-21},
	journal = {Proceedings of the VLDB Endowment},
	author = {Bindschaedler, Vincent and Shokri, Reza and Gunter, Carl A.},
	month = jan,
	year = {2017},
	pages = {481--492},
	file = {Full Text PDF:/Users/cmm/Zotero/storage/SSNWY3YR/Bindschaedler et al. - 2017 - Plausible deniability for privacy-preserving data .pdf:application/pdf}
}

@article{putmode,
	title = {{PutMode}: prediction of uncertain trajectories in moving objects databases},
	volume = {33},
	issn = {1573-7497},
	shorttitle = {{PutMode}},
	url = {https://doi.org/10.1007/s10489-009-0173-z},
	doi = {10.1007/s10489-009-0173-z},
	abstract = {Objective: Prediction of moving objects with uncertain motion patterns is emerging rapidly as a new exciting paradigm and is important for law enforcement applications such as criminal tracking analysis. However, existing algorithms for prediction in spatio-temporal databases focus on discovering frequent trajectory patterns from historical data. Moreover, these methods overlook the effect of some important factors, such as speed and moving direction. This lacks generality as moving objects may follow dynamic motion patterns in real life.},
	language = {en},
	number = {3},
	urldate = {2020-05-18},
	journal = {Applied Intelligence},
	author = {Qiao, Shaojie and Tang, Changjie and Jin, Huidong and Long, Teng and Dai, Shucheng and Ku, Yungchang and Chau, Michael},
	month = dec,
	year = {2010},
	pages = {370--386},
	file = {Springer Full Text PDF:/Users/cmm/Zotero/storage/TQVNENPE/Qiao et al. - 2010 - PutMode prediction of uncertain trajectories in m.pdf:application/pdf}
}

@inproceedings{no_free_lunch,
	address = {Athens, Greece},
	series = {{SIGMOD} '11},
	title = {No free lunch in data privacy},
	isbn = {978-1-4503-0661-4},
	url = {https://doi.org/10.1145/1989323.1989345},
	doi = {10.1145/1989323.1989345},
	abstract = {Differential privacy is a powerful tool for providing privacy-preserving noisy query answers over statistical databases. It guarantees that the distribution of noisy query answers changes very little with the addition or deletion of any tuple. It is frequently accompanied by popularized claims that it provides privacy without any assumptions about the data and that it protects against attackers who know all but one record. In this paper we critically analyze the privacy protections offered by differential privacy. First, we use a no-free-lunch theorem, which defines non-privacy as a game, to argue that it is not possible to provide privacy and utility without making assumptions about how the data are generated. Then we explain where assumptions are needed. We argue that privacy of an individual is preserved when it is possible to limit the inference of an attacker about the participation of the individual in the data generating process. This is different from limiting the inference about the presence of a tuple (for example, Bob's participation in a social network may cause edges to form between pairs of his friends, so that it affects more than just the tuple labeled as "Bob"). The definition of evidence of participation, in turn, depends on how the data are generated -- this is how assumptions enter the picture. We explain these ideas using examples from social network research as well as tabular data for which deterministic statistics have been previously released. In both cases the notion of participation varies, the use of differential privacy can lead to privacy breaches, and differential privacy does not always adequately limit inference about participation.},
	urldate = {2020-04-12},
	booktitle = {Proceedings of the 2011 {ACM} {SIGMOD} {International} {Conference} on {Management} of data},
	publisher = {Association for Computing Machinery},
	author = {Kifer, Daniel and Machanavajjhala, Ashwin},
	month = jun,
	year = {2011},
	keywords = {differential privacy, privacy, inferential privacy},
	pages = {193--204},
	annote = {Discusses how one must limit association between data points to achieve privacy.
 
Considers privacy for social networks. Delete datapoints from dataset vs. hide 'evidence of participation'.
 
Precursor to pufferfish
 
 },
	file = {Full Text PDF:/Users/cmm/Zotero/storage/2EUYZMNS/Kifer and Machanavajjhala - 2011 - No free lunch in data privacy.pdf:application/pdf}
}

@book{DP,
	title = {Differential {Privacy}},
	volume = {4052},
	isbn = {978-3-540-35907-4},
	url = {https://www.microsoft.com/en-us/research/publication/differential-privacy/},
	abstract = {In 1977 Dalenius articulated a desideratum for statistical databases: nothing about an individual should be learnable from the database that cannot be learned without access to the database. We give a general impossibility result showing that a formalization of Dalenius’ goal along the lines of semantic security cannot be achieved. Contrary to intuition, a variant …},
	language = {en-US},
	urldate = {2020-04-12},
	author = {Dwork, Cynthia},
	month = jul,
	year = {2006},
	annote = {Original DP paper.
Way too cryptographic},
	file = {Full Text PDF:/Users/cmm/Zotero/storage/7VQFV7EL/Dwork - 2006 - Differential Privacy.pdf:application/pdf;Snapshot:/Users/cmm/Zotero/storage/VG5FK8TD/differential-privacy.html:text/html}
}

@article{SDPs,
	title = {Semidefinite {Programming}},
	volume = {38},
	issn = {0036-1445, 1095-7200},
	url = {http://epubs.siam.org/doi/10.1137/1038003},
	doi = {10.1137/1038003},
	language = {en},
	number = {1},
	urldate = {2020-06-02},
	journal = {SIAM Review},
	author = {Vandenberghe, Lieven and Boyd, Stephen},
	month = mar,
	year = {1996},
	pages = {49--95},
	file = {Submitted Version:/Users/cmm/Zotero/storage/J5PIHU37/Vandenberghe and Boyd - 1996 - Semidefinite Programming.pdf:application/pdf}
}

@article{cvxopt,
  title={The CVXOPT linear and quadratic cone program solvers},
  author={Vandenberghe, Lieven},
  journal={Online: http://cvxopt. org/documentation/coneprog. pdf},
  year={2010}
}

@misc{zdnet,
	title = {{US} cell carriers are selling access to your real-time phone location data},
	url = {https://www.zdnet.com/article/us-cell-carriers-selling-access-to-real-time-location-data/},
	abstract = {The company embroiled in a privacy row has "direct connections" to all major US wireless carriers, including AT\&T, Verizon, T-Mobile, and Sprint -- and Canadian cell networks, too.},
	language = {en},
	urldate = {2020-06-03},
	journal = {ZDNet},
	author = {Whittaker, Zack},
	note = {Library Catalog: www.zdnet.com},
	file = {Snapshot:/Users/cmm/Zotero/storage/5SV9AQB2/us-cell-carriers-selling-access-to-real-time-location-data.html:text/html}
}

@article{limits_of_predictability,
	title = {Limits of {Predictability} in {Human} {Mobility}},
	volume = {327},
	copyright = {Copyright © 2010, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/327/5968/1018},
	doi = {10.1126/science.1177170},
	abstract = {A range of applications, from predicting the spread of human and electronic viruses to city planning and resource management in mobile communications, depend on our ability to foresee the whereabouts and mobility of individuals, raising a fundamental question: To what degree is human behavior predictable? Here we explore the limits of predictability in human dynamics by studying the mobility patterns of anonymized mobile phone users. By measuring the entropy of each individual’s trajectory, we find a 93\% potential predictability in user mobility across the whole user base. Despite the significant differences in the travel patterns, we find a remarkable lack of variability in predictability, which is largely independent of the distance users cover on a regular basis.
Analysis of the trajectories of people carrying cell phones reveals that human mobility patterns are highly predictable.
Analysis of the trajectories of people carrying cell phones reveals that human mobility patterns are highly predictable.},
	language = {en},
	number = {5968},
	urldate = {2020-06-04},
	journal = {Science},
	author = {Song, Chaoming and Qu, Zehui and Blumm, Nicholas and Barabási, Albert-László},
	month = feb,
	year = {2010},
	pmid = {20167789},
	note = {Publisher: American Association for the Advancement of Science
Section: Report},
	pages = {1018--1021},
	file = {Full Text PDF:/Users/cmm/Zotero/storage/YUS69FBQ/Song et al. - 2010 - Limits of Predictability in Human Mobility.pdf:application/pdf;Snapshot:/Users/cmm/Zotero/storage/9AVIGEGR/1018.html:text/html}
}

@article{ATM_GP,
	title = {Mobility modeling, location tracking, and trajectory prediction in wireless {ATM} networks},
	volume = {16},
	issn = {1558-0008},
	doi = {10.1109/49.709453},
	abstract = {Wireless ATM networks require efficient mobility management to cope with frequent mobile handoff and rerouting of connections. Although much attention has been given in the literature to network architecture design to support wide-area mobility in public ATM networks, little has been done to the important issue of user mobility estimation and prediction to improve the connection reliability and bandwidth efficiency of the underlying system architecture. This paper treats the problem by developing a hierarchical user mobility model that closely represents the movement behavior of a mobile user, and that, when used with appropriate pattern matching and Kalman filtering techniques, yields an accurate location prediction algorithm, HLP, or hierarchical location prediction, which provides necessary information for advance resource reservation and advance optimal route establishment in wireless ATM networks.},
	number = {6},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Tong Liu and Bahl, P. and Chlamtac, I.},
	month = aug,
	year = {1998},
	note = {Conference Name: IEEE Journal on Selected Areas in Communications},
	keywords = {advance optimal route establishment, advance resource reservation, asynchronous transfer mode, Bandwidth, bandwidth efficiency, cellular radio, connection reliability, efficient mobility management, estimation theory, hierarchical location prediction, hierarchical user mobility model, HLP, Information filtering, Information filters, Kalman filtering, Kalman filters, land mobile radio, location prediction algorithm, location tracking, Matched filters, mobile handoff, Mobile radio mobility management, mobility modeling, network architecture design, pattern matching, Pattern matching, Prediction algorithms, prediction theory, Predictive models, public ATM networks, reliability theory, rerouting, system architecture, telecommunication network routing, tracking, Trajectory, trajectory prediction, user mobility estimation, wide-area mobility, wireless ATM networks},
	pages = {922--936},
	file = {IEEE Xplore Full Text PDF:/Users/cmm/Zotero/storage/SRW5D2Q2/Tong Liu et al. - 1998 - Mobility modeling, location tracking, and trajecto.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/cmm/Zotero/storage/6L8K9FMP/709453.html:text/html}
}

@inproceedings{PCS_GP,
	title = {Predictive distance-based mobility management for {PCS} networks},
	volume = {3},
	doi = {10.1109/INFCOM.1999.752157},
	abstract = {This paper presents a mobile tracking scheme that exploits the predictability of user mobility patterns in wireless PCS networks. Instead of the constant velocity fluid-flow or the random-walk mobility model, a more realistic Gauss-Markov model is introduced, where a mobile's velocity is correlated in time to a various degree. Based on the Gauss-Markov model, a mobile's future location is predicted by the network based on the information gathered from the mobile's last report of location and velocity. When a call is made, the network pages the destination mobile at and around the predicted location of the mobile and in the order of descending probability until the mobile is found. A mobile shares the same prediction information with the network and reports its new location whenever it reaches some threshold distance away from the predicted location. We describe an analytical framework to evaluate the cost of mobility management for the proposed predictive distance-based scheme. We then compare this cost against that of the regular, non-predictive distance-based scheme, which is obtained through simulations. Performance advantage of the proposed scheme is demonstrated under various mobility and call patterns, update cost, page cost, and frequencies of mobile location inspections.},
	booktitle = {{IEEE} {INFOCOM} '99. {Conference} on {Computer} {Communications}. {Proceedings}. {Eighteenth} {Annual} {Joint} {Conference} of the {IEEE} {Computer} and {Communications} {Societies}. {The} {Future} is {Now} ({Cat}. {No}.{99CH36320})},
	author = {Liang, B. and Haas, Z.J.},
	month = mar,
	year = {1999},
	note = {ISSN: 0743-166X},
	keywords = {call patterns, cellular radio, Communication standards, correlation, Costs, destination mobile, Frequency, future location prediction, Gauss-Markov model, Gaussian processes, GSM, Inspection, Markov processes, mobile location inspection frequency, Mobile radio mobility management, mobile tracking, mobile velocity, mobility management cost, network paging, nonpredictive distance-based scheme, North America, page cost, performance, personal communication networks, Personal communication networks, prediction theory, predictive distance-based mobility management, probability, radio tracking, simulations, telecommunication network management, Telecommunication traffic, threshold distance, update cost, user mobility patterns, Wireless communication, wireless PCS networks},
	pages = {1377--1384 vol.3},
	file = {IEEE Xplore Full Text PDF:/Users/cmm/Zotero/storage/JU4ARZQR/Liang and Haas - 1999 - Predictive distance-based mobility management for .pdf:application/pdf;IEEE Xplore Abstract Record:/Users/cmm/Zotero/storage/SQ363RC6/752157.html:text/html}
}

@article{Traffic_GP,
	title = {Gaussian {Process} {Decentralized} {Data} {Fusion} and {Active} {Sensing} for {Spatiotemporal} {Traffic} {Modeling} and {Prediction} in {Mobility}-on-{Demand} {Systems}},
	volume = {12},
	issn = {1558-3783},
	doi = {10.1109/TASE.2015.2422852},
	abstract = {Mobility-on-demand (MoD) systems have recently emerged as a promising paradigm of one-way vehicle sharing for sustainable personal urban mobility in densely populated cities. We assume the capability of a MoD system to be enhanced by deploying robotic shared vehicles that can autonomously cruise the streets to be hailed by users. A key challenge of the MoD system is that of real-time, fine-grained mobility demand and traffic flow sensing and prediction. This paper presents novel Gaussian process (GP) decentralized data fusion and active sensing algorithms for real-time, fine-grained traffic modeling and prediction with a fleet of MoD vehicles. The predictive performance of our decentralized data fusion algorithms are theoretically guaranteed to be equivalent to that of sophisticated centralized sparse GP approximations. We derive consensus filtering variants requiring only local communication between neighboring vehicles. We theoretically guarantee the performance of our decentralized active sensing algorithms. When they are used to gather informative data for mobility demand prediction, they can achieve a dual effect of fleet rebalancing to service mobility demands. Empirical evaluation on real-world datasets shows that our algorithms are significantly more time-efficient and scalable in the size of data and fleet while achieving predictive performance comparable to that of state-of-the-art algorithms. Note to Practitioners-Knowing, understanding, and predicting spatiotemporally varying traffic phenomena in real time has become increasingly important to the goal of achieving smooth-flowing, congestion-free traffic in densely populated urban cities, which motivates our work here. This paper addresses the following fundamental problem of data fusion and active sensing: How can a fleet of autonomous robotic vehicles or mobile probes actively cruise a road network to gather and assimilate the most informative data for predicting a spatiotemporally varying traffic phenomenon like a mobility demand pattern or traffic flow? Existing centralized solutions are poorly suited because they suffer from a single point of failure and incur huge communication, space, and time overheads with large data and fleet. This paper proposes novel efficient and scalable decentralized data fusion and active sensing algorithms with theoretical performance guarantees. The practical applicability of our algorithms is not restricted to traffic monitoring [1]-[4]; they can be used in other environmental sensing applications such as mineral prospecting [5], precision agriculture, monitoring of ocean/freshwater phenomena (e.g., plankton bloom) [6]-[9], forest ecosystems, pollution (e.g., oil spill), or contamination. Note that the decentralized data fusion component of our algorithms can also be used for static sensors and passive mobile probes and, interestingly, adapted to parallel implementations to be run on a cluster of machines for achieving efficient and scalable probabilistic prediction (i.e., with predictive uncertainty) with large data. Empirical results show that our algorithms can perform well with two datasets featuring real-world traffic phenomena in the densely-populated urban city of Singapore. A limitation of our algorithms is that the decentralized data fusion components assume independence between multiple traffic phenomena while the decentralized active sensing components only work for a single traffic phenomenon. So, in our future work, we will generalize our algorithms to perform active sensing of multiple traffic phenomena and remove the assumption of independence between them.},
	number = {3},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Chen, Jie and Low, Kian Hsiang and Yao, Yujian and Jaillet, Patrick},
	month = jul,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Automation Science and Engineering},
	keywords = {Active learning, adaptive sampling, Data integration, decentralized active sensing, decentralized active sensing algorithms, decentralized/distributed data fusion, distributed consensus filtering, environmental sensing and monitoring, Gaussian process, Gaussian process decentralized data fusion, Gaussian processes, GP approximation, GP decentralized data fusion, log-Gaussian process, mobile probes, mobile robots, mobility demand prediction, MoD systems, one-way vehicle sharing, Prediction algorithms, Predictive models, relational Gaussian process, road network, road traffic control, Roads, Robot sensing systems, robotic shared vehicles, sensor fusion, spatiotempmobility-on-demand systemsoral traffic prediction, spatiotemporal modeling, spatiotemporal traffic modeling, sustainable personal urban mobility, traffic flow forecasting, Vehicles, vehicular sensor network},
	pages = {901--921},
	file = {IEEE Xplore Full Text PDF:/Users/cmm/Zotero/storage/Y47V2XAI/Chen et al. - 2015 - Gaussian Process Decentralized Data Fusion and Act.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/cmm/Zotero/storage/67LNIM9F/7102794.html:text/html}
}

@inproceedings{temp_GP,
	title = {Adaptive {Home} {Heating} {Control} {Through} {Gaussian} {Process} {Prediction} and {Mathematical} {Programming}},
	url = {https://eprints.soton.ac.uk/272235/},
	abstract = {In this paper, we address the challenge of adaptively controlling a home heating system in order to minimise cost and carbon emissions within a smart grid. Our home energy management agent learns the thermal properties of the home, and uses Gaussian processes to predict the environmental parameters over the next 24 hours, allowing it to provide real time feedback to householders concerning the cost and carbon emissions of their heating preferences. Furthermore, we show how it can then use a mixed-integer quadratic program, or a computationally efficient greedy heuristic, to adapt to real-time cost and carbon intensity signals, adjusting the timing of heater use in order to satisfy preferences for comfort whilst minimising cost and carbon emissions. We evaluate our approach using weather and electricity grid data from January 2010 for the UK, and show our approach can predict the total cost and carbon emissions over a day to within 9\%, and show that over the month it reduces cost and carbon emissions by 15\%, and 9\%, respectively, compared to using a conventional thermostat.},
	language = {en},
	urldate = {2020-06-04},
	author = {Rogers, Alex and Maleki, Sasan and Ghosh, Siddhartha and Jennings, Nicholas R.},
	collaborator = {Rogers, Alex and Maleki, Sasan and Ghosh, Siddhartha and Jennings, Nicholas R.},
	month = may,
	year = {2011},
	note = {Meeting Name: Second International Workshop on Agent Technology for Energy Systems (ATES 2011) (01/05/11)},
	pages = {71--78},
	file = {Full Text PDF:/Users/cmm/Zotero/storage/NI25AKYJ/Rogers et al. - 2011 - Adaptive Home Heating Control Through Gaussian Pro.pdf:application/pdf;Snapshot:/Users/cmm/Zotero/storage/T29J7T2M/272235.html:text/html}
}

@inproceedings{quantifying_dp_cao,
	title = {Quantifying {Differential} {Privacy} under {Temporal} {Correlations}},
	doi = {10.1109/ICDE.2017.132},
	abstract = {Differential Privacy (DP) has received increasing attention as a rigorous privacy framework. Many existing studies employ traditional DP mechanisms (e.g., the Laplace mechanism) as primitives, which assume that the data are independent, or that adversaries do not have knowledge of the data correlations. However, continuous generated data in the real world tend to be temporally correlated, and such correlations can be acquired by adversaries. In this paper, we investigate the potential privacy loss of a traditional DP mechanism under temporal correlations in the context of continuous data release. First, we model the temporal correlations using Markov model and analyze the privacy leakage of a DP mechanism when adversaries have knowledge of such temporal correlations. Our analysis reveals that the privacy loss of a DP mechanism may accumulate and increase over time. We call it temporal privacy leakage. Second, to measure such privacy loss, we design an efficient algorithm for calculating it in polynomial time. Although the temporal privacy leakage may increase over time, we also show that its supremum may exist in some cases. Third, to bound the privacy loss, we propose mechanisms that convert any existing DP mechanism into one against temporal privacy leakage. Experiments with synthetic data confirm that our approach is efficient and effective.},
	booktitle = {2017 {IEEE} 33rd {International} {Conference} on {Data} {Engineering} ({ICDE})},
	author = {Cao, Yang and Yoshikawa, Masatoshi and Xiao, Yonghui and Xiong, Li},
	month = apr,
	year = {2017},
	note = {ISSN: 2375-026X},
	keywords = {differential privacy, Privacy, Correlation, data privacy, Data privacy, Databases, Probabilistic logic, Aggregates, Algorithm design and analysis, computational complexity, data correlations, DP mechanism privacy leakage, DP mechanism privacy loss, Markov model, polynomial time, temporal correlations, temporal privacy leakage},
	pages = {821--832},
	file = {IEEE Xplore Abstract Record:/Users/cmm/Zotero/storage/5DPYLKJU/7930028.html:text/html;Accepted Version:/Users/cmm/Zotero/storage/GMRHQ3J5/Cao et al. - 2017 - Quantifying Differential Privacy under Temporal Co.pdf:application/pdf;cao17icde.pdf:/Users/cmm/Zotero/storage/Z5GBG655/cao17icde.pdf:application/pdf}
}

@inproceedings{dependent_dp,
	address = {San Diego, CA},
	title = {Dependence {Makes} {You} {Vulnerable}: {Differential} {Privacy} {Under} {Dependent} {Tuples}},
	isbn = {978-1-891562-41-9},
	shorttitle = {Dependence {Makes} {You} {Vulnerable}},
%	url = {https://www.ndss-symposium.org/wp-content/uploads/2017/09/dependence-makes-you-vulnerable-differential-privacy-under-dependent-tuples.pdf},
%	doi = {10.14722/ndss.2016.23279},
	abstract = {Differential privacy (DP) is a widely accepted mathematical framework for protecting data privacy. Simply stated, it guarantees that the distribution of query results changes only slightly due to the modiﬁcation of any one tuple in the database. This allows protection, even against powerful adversaries, who know the entire database except one tuple. For providing this guarantee, differential privacy mechanisms assume independence of tuples in the database – a vulnerable assumption that can lead to degradation in expected privacy levels especially when applied to real-world datasets that manifest natural dependence owing to various social, behavioral, and genetic relationships between users. In this paper, we make several contributions that not only demonstrate the feasibility of exploiting the above vulnerability but also provide steps towards mitigating it. First, we present an inference attack, using real datasets, where an adversary leverages the probabilistic dependence between tuples to extract users’ sensitive information from differentially private query results (violating the DP guarantees). Second, we introduce the notion of dependent differential privacy (DDP) that accounts for the dependence that exists between tuples and propose a dependent perturbation mechanism (DPM) to achieve the privacy guarantees in DDP. Finally, using a combination of theoretical analysis and extensive experiments involving different classes of queries (e.g., machine learning queries, graph queries) issued over multiple large-scale real-world datasets, we show that our DPM consistently outperforms state-of-the-art approaches in managing the privacy-utility tradeoffs for dependent data.},
	language = {en},
	urldate = {2020-04-12},
	booktitle = {Proceedings 2016 {Network} and {Distributed} {System} {Security} {Symposium}},
	publisher = {Internet Society},
	author = {Liu, Changchang and Chakraborty, Supriyo and Mittal, Prateek},
	year = {2016},
	keywords = {inferential privacy},
	annote = {Puts forth the notion that DP makes independence assumptions.},
	file = {Liu et al. - 2016 - Dependence Makes You Vulnerable Differential Priv.pdf:/Users/cmm/Zotero/storage/K6E3IVE3/Liu et al. - 2016 - Dependence Makes You Vulnerable Differential Priv.pdf:application/pdf}
}

@inproceedings{song_pufferfish_2017,
	address = {Chicago, Illinois, USA},
	series = {{SIGMOD} '17},
	title = {Pufferfish {Privacy} {Mechanisms} for {Correlated} {Data}},
	isbn = {978-1-4503-4197-4},
	url = {https://doi.org/10.1145/3035918.3064025},
	doi = {10.1145/3035918.3064025},
	abstract = {Many modern databases include personal and sensitive correlated data, such as private information on users connected together in a social network, and measurements of physical activity of single subjects across time. However, differential privacy, the current gold standard in data privacy, does not adequately address privacy issues in this kind of data. This work looks at a recent generalization of differential privacy, called Pufferfish, that can be used to address privacy in correlated data. The main challenge in applying Pufferfish is a lack of suitable mechanisms. We provide the first mechanism -- the Wasserstein Mechanism -- which applies to any general Pufferfish framework. Since this mechanism may be computationally inefficient, we provide an additional mechanism that applies to some practical cases such as physical activity measurements across time, and is computationally efficient. Our experimental evaluations indicate that this mechanism provides privacy and utility for synthetic as well as real data in two separate domains.},
	urldate = {2020-05-14},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Song, Shuang and Wang, Yizhen and Chaudhuri, Kamalika},
	month = may,
	year = {2017},
	keywords = {differential privacy, privacy, pufferfish privacy},
	pages = {1291--1306},
	file = {Full Text PDF:/Users/cmm/Zotero/storage/HR64N3MM/Song et al. - 2017 - Pufferfish Privacy Mechanisms for Correlated Data.pdf:application/pdf}
}

@article{wash_post,
	title = {Perspective {\textbar} {Smartphone} data reveal which {Americans} are social distancing (and not)},
	issn = {0190-8286},
	url = {https://www.washingtonpost.com/technology/2020/03/24/social-distancing-maps-cellphone-location/},
	abstract = {D.C. gets an 'A' while Wyoming earns an 'F' for following coronavirus stay-at-home advice, based on the locations of tens of millions of phones},
	language = {en-US},
	urldate = {2020-09-17},
	month = march,
	year = {2020},
	journal = {Washington Post},
	author = {Fowler, Geoffrey A.},
	file = {Snapshot:/Users/cmm/Zotero/storage/2F29VQ6L/social-distancing-maps-cellphone-location.html:text/html}
}

@inproceedings{surveillance_GP,
	title = {Gaussian process regression flow for analysis of motion trajectories},
	doi = {10.1109/ICCV.2011.6126365},
	abstract = {Recognition of motions and activities of objects in videos requires effective representations for analysis and matching of motion trajectories. In this paper, we introduce a new representation specifically aimed at matching motion trajectories. We model a trajectory as a continuous dense flow field from a sparse set of vector sequences using Gaussian Process Regression. Furthermore, we introduce a random sampling strategy for learning stable classes of motions from limited data. Our representation allows for incrementally predicting possible paths and detecting anomalous events from online trajectories. This representation also supports matching of complex motions with acceleration changes and pauses or stops within a trajectory. We use the proposed approach for classifying and predicting motion trajectories in traffic monitoring domains and test on several data sets. We show that our approach works well on various types of complete and incomplete trajectories from a variety of video data sets with different frame rates.},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	author = {Kihwan Kim and Dongryeol Lee and Essa, Irfan},
	month = nov,
	year = {2011},
	note = {ISSN: 2380-7504},
	keywords = {Trajectory, Training, Gaussian processes, anomalous event detection, continuous dense flow field, Gaussian process regression flow, image matching, motion estimation, motion recognition, motion trajectory matching, online trajectory, random sampling strategy, Testing, Tracking, traffic monitoring domains, vector sequences, Vectors, video data sets, Videos},
	pages = {1164--1171},
	file = {IEEE Xplore Full Text PDF:/Users/cmm/Zotero/storage/SC2D8FTY/Kihwan Kim et al. - 2011 - Gaussian process regression flow for analysis of m.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/cmm/Zotero/storage/N6V9LUN3/6126365.html:text/html}
}

@article{Deep_NN_GP,
	title = {Deep {Neural} {Networks} as {Gaussian} {Processes}},
	url = {http://arxiv.org/abs/1711.00165},
	abstract = {It has long been known that a single-layer fully-connected neural network with an i.i.d. prior over its parameters is equivalent to a Gaussian process (GP), in the limit of infinite network width. This correspondence enables exact Bayesian inference for infinite width neural networks on regression tasks by means of evaluating the corresponding GP. Recently, kernel functions which mimic multi-layer random neural networks have been developed, but only outside of a Bayesian framework. As such, previous work has not identified that these kernels can be used as covariance functions for GPs and allow fully Bayesian prediction with a deep neural network. In this work, we derive the exact equivalence between infinitely wide deep networks and GPs. We further develop a computationally efficient pipeline to compute the covariance function for these GPs. We then use the resulting GPs to perform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10. We observe that trained neural network accuracy approaches that of the corresponding GP with increasing layer width, and that the GP uncertainty is strongly correlated with trained network prediction error. We further find that test performance increases as finite-width trained networks are made wider and more similar to a GP, and thus that GP predictions typically outperform those of finite-width networks. Finally we connect the performance of these GPs to the recent theory of signal propagation in random neural networks.},
	urldate = {2020-06-21},
	journal = {arXiv:1711.00165 [cs, stat]},
	author = {Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S. and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
	month = mar,
	year = {2018},
	note = {arXiv: 1711.00165},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published version in ICLR 2018. 10 pages + appendix},
	file = {arXiv Fulltext PDF:/Users/cmm/Zotero/storage/M4YV6ID6/Lee et al. - 2018 - Deep Neural Networks as Gaussian Processes.pdf:application/pdf;arXiv.org Snapshot:/Users/cmm/Zotero/storage/CNBWBTGN/1711.html:text/html}
}














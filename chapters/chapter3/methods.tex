\section{\technique}
\label{sec:deepcandidate}
While useful and general, the document embedding $\overline{g}(x)$ does not satisfy \SDP. We now turn to describing our privacy-preserving technique, \technique, which generates general, $\epsilon$-\SDP~document embeddings that preserve relevant information in $\overline{g}(x)$, and are useful for downstream tasks. To understand the nontrivial nature of this problem, we first analyze why the simplest, straightfoward approaches are insufficient. 

%Outline
%First reiterate our goal (preserve relevant information in bar g) 
%Describe how this is difficult with simply adding noise 
%new subsection -- tukey approach using exponentiala mechanism -- use depth as utility  
%with infinite points to choose from this would work fine, but we can't do that 
%new subsection -- cluster preserving embeddings 
%talk about how we take advantage of the structure in this document's domain. In other words, we inject bias into the mechanism based off of publicly accessible non-private information. Use of public information is also used in clifton's approach  
%train new embedding to preserve the cluster -- contains more information than the cluster alone. Add'ly transmitting the cluster through e.g. randomized response is not possible 1) with utility (too many clusters) and 2) with sentDP 

%Then for algorithm section -- we talk about appx to depth 

%since DP defers to randomized algorithms we can't just publish the exact mean embedding 

\paragraph{Motivation.}
  Preserving privacy for high dimensional objects is known to be challenging \cite{kamath_high_dim, mdp_low_dim, DP_compression} . For instance, adding Laplace noise directly to $\overline{g}(x)$, as done to satisfy some privacy definitions \cite{metricdp, orig_metricdp}, does not guarantee \SDP~for any $\epsilon$. Recall that the embedding space is all of $\R^d$. A change in one sentence can lead to an unbounded change in $\overline{g}(x)$, since we do not put any restrictions on the general encoder $G$. Thus, no matter how much noise we add to $\overline{g}(x)$ we cannot satisfy \SDP. 

A straightforward workaround might be to simply truncate embeddings such that they all lie in a limited set such as a sphere or hypercube as done in prior work \cite{clifton, abadi}. In doing so, we bound how far apart embeddings can be for any two sentences, $\|G(s_i) - G(s_i')\|_1$, thus allowing us to satisfy \SDP~by adding finite variance noise. However, such schemes offer poor utility due to the high dimensional nature of useful document embeddings (we confirm this in our experiments). We must add noise with standard deviation proportional to the dimension of the embedding, thus requiring an untenable degree of noise for complex encoders like BERT which embed into $\R^{768}$. 

Our method has three pillars: \textbf{(1)} sampling from a candidate set of public, non-private document embeddings to represent the private document, \textbf{(2)} using the Tukey median to approximate the document embedding, and \textbf{(3)} pre-training the sentence encoder, $G$, to produce relevant candidates with high Tukey depth for private document $x$. 

\subsection{Taking advantage of public data: sampling from candidates}
Instead of having our mechanism select a private embedding $z$ from the entire space of $\R^d$, we focus the mechanism to select from a set of $m$ candidate  embeddings, $F$, generated by $m$ public, non-private documents. We assume the document $x$ is drawn from some distribution $\mu$ over documents $\calX$. For example, if we know $x$ is a restaurant review, $\mu$ may be the distribution over all restaurant reviews. $F$ is then a collection of document embeddings over $m$ publicly accessible documents $x_i \sim \mu$, 
\begin{align*}
	F = \{f_i = \overline{g}(x_i) : x_1, \dots, x_m \overset{\text{iid}}{\sim} \mu\} \ , 
\end{align*}
and denote the corresponding distribution over $f_i$ as $\overline{g}(\mu)$. By selecting candidate documents that are similar in nature to the private document $x$, we inject an advantageous inductive bias into our mechanism, which is critical to satisfy strong privacy while preserving information relevant to $x$. 

%Such inductive bias is critical to satisfy the strong privacy offered by \SDP~while preserving meaningful information unique to $x$. 

\subsection{Approximating the document embedding:\\ \quad \quad \  The Tukey Median}
\label{sec:tukey}
We now propose a novel mechanism $\mname$, which approximates $\overline{g}(x)$ by sampling a candidate embedding from $F$. $\mname$ works by concentrating probability on candidates with high Tukey Depth w.r.t. the set of sentence embeddings $S_x = \{G(s_i) : s_i \in x\}$. We model sentences $s_i$ from document $x$ as i.i.d. draws from distribution $\nu_x$. Then, $S_x$ is $k$ draws from $g(\nu_x)$, the distribution of sentences from $\nu_x$ passing through $G$. Deep points are a good approximation of the mean under light assumptions. If $g(\nu_x)$ belongs to the set of halfspace-symmetric distributions (including all elliptic distributions e.g. Gaussians), we know that its mean lies in the Tukey Median \cite{tukey_props}. 

Formally, $\mname$ is an instance of the exponential mechanism (Definition \ref{def: exp mech}), and is defined by its utility function. We set the utility of a candidate document embedding $f_i \in F$ to be an approximation of its depth w.r.t. sentence embeddings $S_x$, 
\begin{align}
	u(x, f_i) = \tdappx_{S_x}(f_i) \quad. 
	\label{eqn:utility}
\end{align}
The approximation $\tdappx_{S_x}$, which we detail in the Appendix, is necessary for computational efficiency. If the utility of $f_i$ is high, we call it a `deep candidate' for sentence embeddings $S_x$.

The more candidates sampled (higher $m$), the higher the probability that at least one has high depth. Without privacy, we could report the deepest candidate, $z = \argmax{f_i \in F} \tdappx_{S_x}(f_i)$. However, when preserving privacy with $\mname$, increasing $m$ has diminishing returns. To see this, fix a set of sentence embeddings $S_x$ for document $x$ and the i.i.d. distribution over candidate embeddings $f_i \sim \overline{g}(\mu)$. This induces a multinomial distribution over depth,  
\vspace{-0.6cm}
\begin{align*}
	u_j(x) = \Pr[u(x, f_i) = j], \ \ \sum_{j = 0}^{\lfloor \frac{k}{2} \rfloor} u_j(x) = 1 \ ,
\end{align*}
\vspace{-0.5cm}

\noindent where randomness is taken over draws of $f_i$. 

For candidate set $F$ and sentence embeddings $S_x$, the probability of $\mname$'s selected candidate, $z$, having (approximated) depth $j^*$ is given by 
\begin{align}
	\Pr[u(x, z) = j^*] = \frac{a_{j^*}(x)e^{\epsilon j^* / 2}}{\sum_{j=0}^{\lfloor \frac{k}{2} \rfloor} a_j(x) e^{\epsilon j / 2}}
	\label{eqn:prob deep}
\end{align}
where $a_j(x)$ is the fraction of candidates in $F$ with depth $j$ w.r.t. the sentence embeddings of document $x$, $S_x$. For $m$ sufficiently large, $a_j(x)$ concentrates around $u_j(x)$, so further increasing $m$ 
% Thus, while increasing $m$ may increase the number of deep candidates w.r.t. $S_x$, 
does not increase the probability of $\mname$ \emph{sampling} a deep candidate. 

\begin{table}[h!]
  \begin{center}
  \vspace{-0.25cm}
    \caption{Conditions for deep candidates}
    \label{tab:mech example}
    \begin{tabular}{l|c|r} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      $\epsilon$ & $b$ & $j^*$ \\
      \hline
      3 & 55 & 5\\
      6 & 25 & 3\\
      10 & 5 & 2\\
      23 & 1 & 1\\
    \end{tabular}
  \end{center}
  \vspace{-0.5cm}
\end{table}

For numerical intuition, suppose $m = 5000$ (as in our experiments), $\geq b$ candidates have depth $\geq j^*$, and all other candidates have depth 0, $\mname$ will sample one of these deep candidates w.p. $\geq 0.95$ under the settings in Table \ref{tab:mech example}. 

\begin{figure}
	\centering
	\includegraphics[width = \columnwidth]{figures/training_diagram.png} 
	\vspace{-0.65cm}
	\caption[$G'$ is trained to encourage similar documents to embed close together and different documents to embed far apart. ]{$G'$ is trained to encourage similar documents to embed close together and different documents to embed far apart. We first compute embeddings of all (public, non-private) training set documents $T$ with pretrained encoder $G$, $T_G = \{t_i = \overline{g}(x_i) : x_i \in T\}$ (blue dots). We run $k$-means to define $n_c$ clusters, and label each training document embedding $t_i \in T_G$ with its cluster $c$. We then train $H$ to recode sentences to $S_x'$ such that their mean $\overline{g}'(x)$ can be used by a linear model $L$ to predict cluster $c$. Our training objective is the cross-entropy loss of the linear model $L$ in predicting $c$.}
%	\caption{$G'$ is trained to recode document embeddings such that clusters can be predicted by linear model $L$. This encourages similar documents to embed close together and different documents to embed far apart.}
	\label{fig:training diagram}
	\vspace{-0.4cm}
\end{figure}

For low $\epsilon < 10$ (high privacy), about 1\% of candidates need to have high depth $(\geq 3)$ in order to be reliably sampled. Note that this is only possible for documents with $\geq 6$ sentences. For higher $\epsilon \geq 10$, $\mname$ will reliably sample low depth candidates even if there are only a few. 
 
From these remarks we draw two insights on how \technique\ can achieve high utility.\\
\textbf{(1)} \emph{More sentences} A higher $k$ enables greater depth, and thus a higher probability of sampling deep candidates with privacy. We explore this effect in our experiments. \\
\textbf{(2)} \emph{ Tuned encoder} By tuning the sentence encoder $G$ for a given domain, we can modify the distribution over document embeddings $\overline{g}(\mu)$ and sentence embeddings $g(\nu_x)$ to encourage deep candidates (high probability $u_j$ for deep $j$) that are relevant to document $x$.

\input{chapters/chapter3/experiment_figs}

\subsection{Taking advantage of structure: cluster-preserving embeddings}

So far, we have identified that deep candidates from $F$ can approximate $\overline{g}(x)$. To produce a good approximation, we need to ensure that 1) there reliably exist deep candidates for any given set of sentence embeddings $S_x$, and 2) that these deep candidates are good representatives of document $x$. The general sentence encoder $G$ used may not satisfy this `out of the box'. If the distribution on document embeddings $\overline{g}(\mu)$ is very scattered around the instance space $\R^{768}$, it can be exceedingly unlikely to have a deep candidate $f_i$ among sentence embeddings $S_x$. On the other hand, if distribution $\overline{g}(\mu)$ is tightly concentrated in one region (e.g. `before training' in Figure \ref{fig:training diagram}), then we may reliably have many deep candidates, but several will be poor representatives of the document embedding $\overline{g}(x)$. 

To prevent this, we propose an unsupervised, efficient, and intuitive modification to the (pretrained) sentence encoder $G$. We freeze the weights of $G$ and add additional perceptron layers mapping into the same embeddings space $H:\R^d \rightarrow \R^d$, producing the extended encoder $G' = H \circ G$. Broadly, we train $H$ to place similar document embeddings close together, and different embeddings far part.  To do so, we leverage the assumption that a given domain's distribution over document embeddings $\overline{g}(\mu)$ can be parameterized by $n_c$ clusters, visualized as the black circles in Figure \ref{fig:training diagram}. $H$'s aim is to recode sentence embeddings such that document embedding clusters are preserved, but spaced apart from each other. By preserving clusters, we are more likely to have deep candidates (increased probability $u_j$ for high depth $j$). By spacing clusters apart, these deep candidates are more likely to come from the same or a nearby cluster as document $x$, and thus be good representatives. Note that $H$ is domain-specific: we train separate $H$ encoders for each dataset. 

%Consider a document $x$ with sentence embeddings $S_x$ and document embedding $\overline{g}(x)$ (mean of $S_x$) belonging to cluster $c \in [n_c]$. $H$'s task is to recode sentence embeddings $S_x$ to $S_x'$ such that the new document embedding $\overline{g}'(x)$ is close to those from cluster $c$ and far from those of other clusters $b \in [n_c] \backslash c$.   


%\paragraph{Training $G'$:} To achieve this end, we first compute embeddings of all (public, non-private) training set documents $T$ with pretrained encoder $G$, $T_G = \{t_i = \overline{g}(x_i) : x_i \in T\}$ (blue dots in Figure \ref{fig:training diagram}). We run $k$-means to define $n_c$ clusters, and label each training document embedding $t_i \in T_G$ with its cluster $c$. We then train $H$ to recode sentences to $S_x'$ such that their mean $\overline{g}'(x)$ can be used by a linear model $L$ to predict cluster $c$. Our training objective is the cross-entropy loss of the linear model $L$ in predicting the cluster. Note that this is subtly different from simply taking the activations of a final layer since we average the $k$ sentence embeddings into a single document embedding before passing it to $L$. 
%
%Intuitively, $L$ chooses $n_c$ directions in $\R^d$, and $G'$ is encouraged to generate sentence embeddings such that the resulting average document embedding $\overline{g}'(x)$ lies along one of those directions. So, if cluster 1 includes emails discussing global affairs and cluster 5 includes emails discussing celebrity gossip, $G'$ should easily distinguish the two and place their corresponding sentence embeddings along very different directions of $L$.  
%By embedding similar documents to close together and different documents far apart, $G'$ helps $\mname$'s utility by increasing the likelihood of deep candidates that good representatives of private document $x$. 

\subsection{Sampling Algorithm}
The final component of \technique\ is computing the approximate depth of a candidate for use as utility in the exponential mechanism as in Eq. \eqref{eqn:utility}. We use a version of the approximation algorithm proposed in \cite{median_hyp}. Intuitively, our algorithm computes the one-dimensional depth of each $f_i$ among $x$'s sentence embeddings $S_x$ on each of $p$ random projections. The approximate depth of $f_i$ is then its lowest depth across the $p$ projections. We are guaranteed that $\tdappx_{S_x}(f_i) \geq \text{TD}_{S_x}(f_i)$. Due to space constraints, we leave the detailed description of the algorithm for the Appendix.
\begin{theorem}
\label{thm:mainthm}
	$\mname$ satisfies $\epsilon$-Sentence Privacy
\end{theorem}
Proof follows from the fact that $\tdappx_{S_x}(f_i)$ has bounded sensitivity (changing one sentence can only change depth of $f_i$ by one). We expand on this, too, in the Appendix. 








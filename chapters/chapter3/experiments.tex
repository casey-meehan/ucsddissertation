\section{Experiments}
\label{sec:experiments}
\subsection{Datasets}
\label{sec: datasets} 
We produce private, general embeddings of documents from three English-language datasets: 

\textbf{\goodreads} \cite{goodreads} 60k book reviews from four categories: fantasy, history, romance, and childrens literature.  Train-48k | Val-8k | Test-4k 

\textbf{\tnews} \cite{20newsgroup} 11239 correspondences from 20 different affinity groups. Due to similarity between several groups (e.g. \texttt{comp.os.ms-windows.misc} and \texttt{comp.sys.ibm.pc.hardware}), the dataset is partitioned into nine categories. Train-6743k | Val-2247k | Test-2249k

\textbf{\imdb} \cite{imdb} 29k movie reviews from the IMDB database, each labeled as a positive or negative review. Train-23k | Val-2k | Test-4k 

To evaluate utility of these unsupervised, private embeddings, we check if they are predictive of document properties. For the \goodreads\ and \tnews\ datasets, we evaluate how useful the embeddings are for topic classification. For \imdb\ we evaluate how useful the embeddings are for sentiment analysis (positive or negative review). Our metric for performance is test-set macro $F_1$ score. 

\subsection{Training Details \& Setup}
For the general encoder, $G:\calS \rightarrow \R^{768}$, we use SBERT \cite{sbert}, a version of BERT fine-tuned for sentence encoding. Sentence embeddings are generated by mean-pooling output tokens. In all tasks, we freeze the weights of SBERT. The cluster-preserving recoder, $H$, as well as every classifier is implemented as an instance of a 4-layer MLP taking $768$-dimension inputs and only differing on output dimension. We denote an instance of this MLP with output dimension $o$ as \MLP{o}. We run 5 trials of each experiment with randomness taken over the privacy mechanisms, and plot the mean along with a $\pm$ 1 standard deviation envelope. 

\paragraph{\technique:} The candidate set $F$ consists of 5k document embeddings from the training set, each containing at least 8 sentences. To train $G'$, we find $n_c = 50$ clusters with $k$-means. We train a classifier $C_{\text{dc}} = $ \MLP{r} on document embeddings $g'(x)$ to predict class, where $r$ is the number of classes (topics or sentiments). 

\subsection{Baselines}
We compare the performance of \technique\ with 4 baselines: \textbf{Non-private}, \textbf{Truncation}, \textbf{Word-level Metric-DP}, and \textbf{Random Guesser}. 

\textbf{Non-private:} This demonstrates the usefulness of non-private sentence-mean document embeddings $\overline{g}(x)$. We generate $\overline{g}(x)$ for every document using SBERT, and then train a classifier $C_{\text{nonpriv}} = $ \MLP{r} to predict $x$'s label from $\overline{g}(x)$. 

\textbf{Truncation:} We adopt the method from \citealt{clifton} to truncate (clip) sentence embeddings within a box in $\R^{768}$, thereby bounding sensitivity as described at the beginning of Section \ref{sec:deepcandidate}. Laplace noise is then added to each dimension. Documents with more sentences have proportionally less noise added due to the averaging operation reducing sensitivity. 

%\paragraph{Truncation:} The truncation baseline \needcite\ requires first constraining the embedding instance space. We do so by computing the 75\% median interval on each of the 768 dimensions of training document embeddings $T_G$. Sentence embeddings are truncated at each dimension to lie in this box. In order to account for this distribution shift, a new classifier $C_{\text{trunc}} = $ \MLP{r} is trained on truncated mean embeddings to predict class. The number of epochs is determined with the validation set. At test time, a document's sentence embeddings $S_x$ are truncated and averaged. We then add Laplace noise to each dimension with scale factor $\frac{768 w}{k \epsilon}$, where $w$ is the width of the box on that dimension (\emph{sensitivity} in DP terms). Note that the standard deviation of noise added is inversely proportional to the number of sentences in the document, due to the averaging operation reducing sensitivity. 

\textbf{Word Metric-DP (MDP):} The method from \citealt{metricdp} satisfies $\epsilon$-word-level metric DP by randomizing words. We implement MDP to produce a randomized document $x'$, compute $\overline{g}(x')$ with SBERT, and predict class using $C_{\text{nonpriv}}$. 

\textbf{Random Guess:} To set a bottom-line, we show the theoretical performance of a random guesser only knowing the distribution of labels. 

\subsection{Results \& Discussion} 
\textbf{How does performance change with privacy parameter $\epsilon$?}\\ 
This is addressed in Figures \ref{fig:eps:tnews} to \ref{fig:eps:imdb}. Here, we observe how the test set macro $F_1$ score changes with privacy parameter $\epsilon$ (a lower $\epsilon$ offers stronger privacy). Generally speaking, for local differential privacy, $\epsilon < 10$ is taken to be a strong privacy regime, $10 \leq \epsilon < 20$ is moderate privacy, and $\epsilon \geq 25$ is weak privacy. The \textbf{truncation} baseline mechanism does increase accuracy with increasing $\epsilon$, but never performs much better than the random guesser. This is to be expected with high dimension embeddings, since the standard deviation of noise added increases linearly with dimension. 

The word-level \textbf{MDP} mechanism performs significantly better than \textbf{truncation}, achieving relatively good performance for $\epsilon \geq 30$. There are two significant caveats, however. First, is the privacy definition: as discussed in the Introduction, for the same $\epsilon$, word-level MDP is strictly weaker than \SDP. 
%The MDP definition only guarantees that changing a single word with a similar word is $\epsilon$-indistinguishable to an adversary trying to recover the original document. Sentence-DP guarantees that adding, removing, or modifying \emph{any number of words in any way} in a given sentence is $\epsilon$-indistinguishable -- a significantly stronger guarantee. 
The second caveat is the level of $\epsilon$ at which privacy is achieved. Despite a weaker privacy definition, the MDP mechanism does not achieve competitive performance until the weak-privacy regime of $\epsilon$. We suspect this is due to two reasons. First, is the fact that the MDP mechanism does not take advantage of contextual information in each sentence as our technique does; randomizing each word independently does not use higher level linguistic information. Second, is the fact that the MDP mechanism does not use domain-specific knowledge as our mechanism does with use of relevant candidates and domain specific sentence encodings. 

In comparison, \technique\ offers strong utility across tasks and datasets for relatively low values of $\epsilon$, even into the strong privacy regime. Beyond $\epsilon = 25$, the performance of \technique\ tends to max out, approximately 10-15\% below the non-private approach. This is due to the fact that \technique\ offers a noisy version of an \emph{approximation} of the document embedding $\overline{g}(x)$ -- it cannot perform any better than deterministically selecting the deepest candidate, and even this candidate may be a poor representative of $x$. We consider this room for improvement, since there are potentially many other ways to tune $G'$ and select the candidate pool $F$ such that deep candidates are nearly always good representatives of a given document $x$. 

\noindent\textbf{How does performance change with the number of sentences $k$?}\\
This is addressed in Figures \ref{fig:k:tnews} to \ref{fig:k:imdb}. We limit the test set to those documents with $k$ in the listed range on the x-axis. We set $\epsilon = 10$, the limit of the strong privacy regime. Neither baseline offers performance above that of the random guesser at this value of $\epsilon$.  \technique\ produces precisely the performance we expect to see: documents with more sentences result in sampling higher quality candidates, confirming the insights of Section \ref{sec:tukey}. Across datasets and tasks, documents with more than 10-15 sentences tend to have high quality embeddings. 

\section{Conclusions and Future Work}
\vspace{-0.5em}
We introduce a strong and interpretable local privacy guarantee for documents, \SDP, along with \technique, a technique that combines principles from NLP and robust statistics to generate general $\epsilon$-\SDP\ embeddings. Our experiments confirm that such methods can outperform existing approaches even with with more relaxed privacy guarantees. Previous methods have argued that it is ``virtually impossible'' to satisfy pure local DP \cite{metricdp, mdp_low_dim} at the word level while capturing linguistic semantics. Our work appears to refute this notion at least at the document level. 

To follow up, we plan to explore other approaches (apart from $k$-means) of capturing the structure of the embedding distribution $\overline{g}(\mu)$ to encourage better candidate selection. We also plan to experiment with decoding private embeddings back to documents by using novel candidates produced by a generative model trained on $F$. 

% \clearpage

\section*{Acknowledgements} 
KC and CM would like to thank ONR under N00014-20-1-2334. KM gratefully acknowledges funding from an Amazon Research Award and Adobe Unrestricted Research Gifts. We would would also like to thank our reviewers for their insightful feedback.
%Questions are 
%\begin{enumerate}
%	\item How does performance compare w/ baselines as we change privacy parameter $\epsilon$.  
%	\item How does performance compare w/ baselines as we change number of sentences $k$ in the private document. 
%\end{enumerate}
%
%\cm{First subsection is datasets, maybe a table. Tran/val/test splits and explain what the dataset is (sentiment / classification). } \\
%\cm{Second subsection: training details \& setup. Talk about SBERT and MLP layer shit and dimension and train with this kind of loss for this many epochs with this particular optimizer. Don't mention SBERT earlier just here. Number of parameters in MLP.} \\
%\cm{In second subsection: setup: e.g. ``for all experiments we get the frozen embeddings'' we select the best MLP classifier based on da da da. We use Macro F1 for metric. } \\
%\cm{Results \& Discussion: show questions here. talk about how the figures answer the questions. } \\


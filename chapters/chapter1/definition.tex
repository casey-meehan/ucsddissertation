\section{Defining \emph{Déjà Vu} Memorization}
\label{sec:definition}

\paragraph{What is \dejavu memorization?} At a high level, the objective of SSL is to learn general representations of objects that occur in nature. This is often accomplished by associating different parts of an image with one another in the learned embedding. Returning to our example in Figure \ref{fig:black_swan}, given an image whose background contains a patch of water, the model may learn that the foreground object is a water animal such as duck, pelican, otter, \emph{etc.}, by observing different images that contain water from the training set. We refer to this type of learning as \emph{correlation}: the association of objects that tend to co-occur in images from the training data distribution.

A natural question to ask is \emph{``Can the reconstruction of the black swan in Figure \ref{fig:black_swan} be reasoned as correlation?''} The intuitive answer may be no, since the reconstructed image is qualitatively very similar to the original image. However, this reasoning implicitly assumes that for a random image from the training data distribution containing a patch of water, the foreground object is unlikely to be a black swan. Mathematically, if we denote by $\mathcal{P}$ the training data distribution and $A$ the image, then
\begin{equation*}
\label{eq:p_corr}
p_\text{corr} := \mathbb{P}_{A \sim \mathcal{P}}(\mathrm{object}(A) = \texttt{black swan} ~|~ \mathrm{crop}(A) = \texttt{water})
\end{equation*}
is the probability of inferring that the foreground object is a black swan through \emph{correlation}. This probability may be naturally high due to biases in the distribution $\mathcal{P}$, \emph{e.g.}, if $\mathcal{P}$ contains no other water animal except for black swans. In fact, such correlations are often exploited to learn a model for image inpainting with great success~\citep{yu2018generative, ulyanov2018deep}.

Despite this, we argue that reconstruction of the black swan in Figure \ref{fig:black_swan} is \emph{not} due to correlation, but rather due to \emph{unintended memorization}: the association of objects unique to a single training image. As we will show in the following sections, the example in Figure \ref{fig:black_swan} is not a rare success case and can be replicated across many training samples. More importantly, failure to reconstruct the foreground object in Figure \ref{fig:black_swan} (\textbf{right}) on test images hints at inferring through correlation is unlikely to succeed---a fact that we verify quantitatively in Section \ref{sec:label inference accuracy}. Motivated by this discussion, we give a verbal definition of \dejavu memorization below, and design a testing methodology to quantify \dejavu memorization in Section \ref{sec:notation and setup}.
\mybox{\textbf{Definition:} A model exhibits \emph{déjà vu memorization} when it retains information so specific to an individual training image, that it enables recovery of aspects particular to that image given a part that does not contain them.
The recovered aspect must be beyond what can be inferred using only correlations in the data distribution.} 

% \textbf{Definition:} A model exhibits \emph{déjà vu memorization} when it retains information so specific to an individual training image, that it enables recovery of aspects particular to that image given a part that does not contain them.
% The recovered aspect must be beyond what can be inferred using only correlations in the data distribution.


 We intentionally kept the above definition broad enough to encompass different types of information that can be inferred about the training image, including but not restricted to object category, shape, color and position. For example, if one can infer that the foreground object is red given the background patch with accuracy significantly beyond correlation, we consider this an instance of \dejavu memorization as well. We mainly focus on object category to quantify \dejavu memorization in Section \ref{sec:quant} since the ground truth label can be easily obtained. We consider other types of information more qualitatively in the visual reconstruction experiments in Section \ref{sec:visualizing}.

\paragraph{Privacy implications of \dejavu memorization.} \Dejavu memorization can be a cause for concern when the training data contains privacy-sensitive information. As a motivating example, consider an SSL model trained on photos of individuals. If the model exhibits \dejavu memorization then, given the face of an individual, it may be possible to infer where the individual was or even visually reconstruct their location in the training image. Such information leakage raises privacy concerns, especially if there was no prior agreement that the trained model may reveal such information to third parties. This hypothetical scenario serves as a motivation that \dejavu memorization should be carefully examined to avoid unintended disclosure of private information in practical applications.

\input{chapters/chapter1/KNN_adv_cartoon.tex}

\textbf{Distinguishing memorization from correlation.} When measuring \dejavu memorization, it is crucial to differentiate what the model associates through \emph{memorization} and what it associates through \emph{correlation}. Our testing methodology is based on the following intuitive definition.
\mybox{\textbf{Definition:} If an SSL model associates two parts in a training image, we say that it is due to \emph{correlation} if other SSL models trained on a similar dataset from $\mathcal{P}$ without this image would likely make the same association. Otherwise, we say that it is due to \emph{memorization}.}

Notably, such intuition forms the basis for differential privacy (DP; \cite{dwork2006calibrating, dwork2013algorithmic})---the most widely accepted notion of privacy in ML.

\subsection{Testing Methodology for Measuring \emph{Déjà Vu} Memorization}
\label{sec:notation and setup}

In this section, we use the above intuition to measure the extent of \dejavu memorization in SSL. Figure \ref{fig:split_and_pipeline_cartoon} gives an overview of our testing methodology.
\vspace{-0.75em}
\paragraph{Dataset splitting.} We focus on testing \dejavu memorization for SSL models trained on the ImageNet-1K dataset~\citep{imagenet}. Our test first splits the ImageNet training set into three independent and disjoint subsets $\calA$, $\calB$ and $\calX$. The dataset $\calA$ is called the \emph{target set} and $\calB$ is called the \emph{reference set}. The two datasets are used to train two separate SSL models, $\SSL_A$ and $\SSL_B$, called the \emph{target model} and the \emph{reference model}. Finally, the dataset set $\calX$ is used as an auxiliary public dataset to extract information from $\SSL_A$ and $\SSL_B$.
%\footnote{See Appendix \ref{sec:appx splits} for details on how the dataset splits are generated.}.
Our dataset splitting serves the purpose of distinguishing memorization from correlation in the following manner. Given a sample $A_i \in \calA$, if our test returns the same result on $\SSL_A$ and $\SSL_B$ then it is likely due to correlation because $A_i$ is not a training sample for $\SSL_B$. Otherwise, because $\calA$ and $\calB$ are drawn from the same underlying distribution, our test must have inferred some information unique to $A_i$ due to memorization. Thus, by comparing the difference in the test results for $\SSL_A$ and $\SSL_B$, we can measure the degree of \dejavu memorization\footnote{See Appendix \ref{sec:appx splits} for details on how the dataset splits are generated.}.
\vspace{-0.75em}
\paragraph{Extracting foreground and background crops.} Our testing methodology aims at measuring what can be inferred about the foreground object in an ImageNet sample given a background crop. This is made possible because ImageNet provides bounding box annotations for a subset of its training images---around 150K out of 1.3M samples. We split these annotated images equally between $\calA$ and $\calB$. Given an annotated image $A_i$, we treat everything inside the bounding box as the foreground object associated with the image label, denoted $\object{A_i}$. We take the largest possible crop that does not intersect with any bounding box as the background crop (or \emph{periphery crop}), denoted $\crop{A_i}$\footnote{We also present another heuristic in \cref{sec:appx corner crop} which takes a corner crop as the background crop, allowing our test to be run without bounding box annotations.}
%Since the labeled object tends to be at the image's center, the corner crop usually excludes it. }
%Because most images in ImageNet are object centric, an image's corner would not include the foreground object.}.
\vspace{-0.75em}
\paragraph{KNN-based test design.} Joint-embedding SSL approaches encourage the embeddings of random crops of a training image $A_i \in \calA$ to be similar. Intuitively, if the model exhibits \dejavu memorization, it is reasonable to expect that the embedding of $\crop{A_i}$ is similar to that of $\object{A_i}$ since both crops are from the same training image. In other words, $\SSL_A(\crop{A_i})$ encodes information about $\object{A_i}$ that cannot be inferred through correlation. However, decoding such information is challenging as these approaches do not learn a decoder associated with the encoder $\SSL_A$.

Here, we leverage the public set $\calX$ to decode the information contained in $\crop{A_i}$ about $\object{A_i}$. More specifically, we map images in $\calX$ to their embeddings using $\SSL_A$ and extract the $k$-nearest-neighbor (KNN) subset of $\SSL_A(\crop{A_i})$ in $\calX$. We can then decode the information contained in $\crop{A_i}$ in one of two ways:
\begin{itemize}
\item \emph{Label inference:} Since $\calX$ is a subset of ImageNet, each embedding in the KNN subset is associated with a class label. If $\crop{A_i}$ encodes information about the foreground object, its embedding will be close to samples in $\calX$ that have the same class label (\emph{i.e.}, foreground object category). We can then use a KNN classifier to infer the foreground object in $A_i$ given $\crop{A_i}$.
\item \emph{Visual reconstruction:} Following \citet{RCDM}, we train an RCDM---a conditional generative model---on $\calX$ to decode $\SSL_A$ embeddings into images. The RCDM reconstruction can recover qualitative aspects of an image remarkably well, such as recovering object color or spatial orientation using its SSL embedding. Given the KNN subset, we average their SSL embeddings and use the trained RCDM model to visually reconstruct $A_i$.
\end{itemize}
In Section \ref{sec:quant}, we focus on quantitatively measuring \dejavu memorization with label inference, and then use the RCDM reconstruction to visualize \dejavu memorization in Section \ref{sec:visualizing}.
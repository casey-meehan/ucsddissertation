\graphicspath{{./chapters/chapter1/}}
\chapter{ }
\subsection{Limitations and societal impact}
\paragraph{Limitations. }
Our work sets out to define, quantify, and visualize data memorization in SSL. Our tests guide us towards potential mitigation strategies. However, note that these strategies are distinct from provable privacy (e.g. DP), and do not guarantee that data is not memorized. It is possible that --- even if our tests detect no memorization --- data is being memorized in some other fashion, and could be detected with a different test. Furthermore, we focus on detecting image memorization with a curated, de-duplicated dataset (ImageNet-1k), which may over- or underestimate data memorization in practice. We chose this in order to claim the learning algorithm as the cause for memorization as opposed to the dataset itself. It is possible that models exhibit different memorization behavior on larger, less curated datasets. With orders of magnitude more data it is possible that memorization is reduced, but with more data duplication it also may be exacerbated. 

\paragraph{Societal Impact. }
Our work's findings have a critical societal impact from a privacy perspective. We show that it is possible for SSL---an increasingly popular learning paradigm---to memorize training images, which could have significant privacy implications. This direction of research is important if we want to understand how we can train such models without exposing user data. Additionally, our proposed mitigation strategies point to the possibility of having strong privacy without significant loss in utility. Ultimately, we open a promising direction towards making SSL vision models more secure.  

\subsection{Experimental details}

\subsubsection{Details on dataset splits}
\label{sec:appx splits}
Imagenet1k provides bounding box annotations of foreground objects to a subset of examples in each class. 
Private sets $\calA$ and $\calB$ contain shared examples, $\calA \cap \calB$, without bounding box annotations, and unique examples with bounding box annotations. Denote the unique examples in each set as $\Abox = \calA \backslash (\calA \cap \calB)$ and $\Bbox = \calB \backslash (\calA \cap \calB)$. To identify memorization, our tests only attempt to infer the labels of the unique examples $\Abox$ and $\Bbox$ that differentiate the two private sets. The periphery crop, $\crop{A_i}$, is computed as the largest possible crop that does not intersect with the foreground object bounding box. In some instances the largest periphery crop is small, and not high enough resolution to get a meaningful embedding. To circumvent this, we only run the test on bounding box examples where the periphery crop is at least $100 \times 100$ pixels.

Each size of training set, 100k to 500k, includes an equal number of examples per class in both sets $\calA$ and $\calB$. The total bounding box annotated examples of each class are evenly divided between $\Abox$ and $\Bbox$. The remaining examples in each class are the shared examples $\calA \cap \calB$. Shared examples are necessary due to a limit number of bounding box examples and a limited number of total images. However, we reiterate that the bounding box examples in set $\calA$ are \emph{unique} to set $\calA$, and thus can only be memorized by $\SSL_A$. 

The disjoint public set, $X$, contains ground truth labels but no bounding-box annotations. The size and content of $X$ remains fixed for all tests. 

\subsubsection{Details on the training setup}
\paragraph{Model Training:} We use PyTorch~\citep{pytorch} with FFCV-SSL~\citep{demo}. All models are trained for 1000 epochs with model checkpoints taken at 50, 100, 250, 500, 750, and 1000 epochs. We note that 1000 epochs is used in the original papers of both VICReg and SimCLR. All sweeps of epochs use the 300k dataset. All sweeps of datasets use the final, 1000 epoch checkpoint. We use a batch size of 1024, and LARS optimizer \citep{LARS} for all SSL models. All models use Resnet101 for the backbone. As seen in Appendix \ref{sec:appx rn50}, a Resnet50 backbone results in \dejavu consistent with that of Resnet101. 

\paragraph{VICReg Training:} VICReg is trained with the 3-layer fully connected projector used in the original paper with layer dimensions 8192-8192-8192. The invariance, variance, and covariance parameters are set to $\lambda = 25, \mu = 25, \nu = 1$, respectively, which are used in the original paper \citep{vicreg}. The LARS base learning rate is set to 0.2, and weight decay is set to 1e-6. 

\paragraph{SimCLR Training:} SimCLR is trained with the 2-layer fully connected projector used in the original paper with layer dimensions 2048-256. The temperature parameter is set to $\tau=0.15$. The LARS base learning rate is set to 0.3, and weight decay is set to 1e-6. 

\paragraph{Supervised Training:} Unlike the SSL models, the supervised model is trained with label access using cross-entropy loss. To keep architectures as similar as possible, the supervised model also uses a Resnet101 backbone and the same projector as VICReg. A final batchnorm, ReLU, and linear layer is added to bring the 8192 dimension projector output to 1000-way classification activations. We use these activations as the supervised model's projector embedding. The supervised model uses the LARS optimizer with learning rate 0.2. 

\subsubsection{Details on the evaluation setup}
\paragraph{KNN:} For each test, we build two KNN's: one using the target model, $\SSL_A$ (or $\CLF_A$), and one using the reference model $\SSL_B$ (or $\CLF_B$). As depicted in Figure \ref{fig:split_and_pipeline_cartoon}, each KNN is built  using the projector embeddings of all images in the public set $\calX$ as the neighbor set. When testing for memorization on an image $A_i \in \calA$, we first embed $\crop{A_i}$ using $\SSL_A$, and find its $K = 100$ $L_2$ nearest neighbors within the $\SSL_A$ embeddings of $\calX$. See section \ref{sec:appx KNN} for a discussion on selection of $K$. We then take the majority vote of the neighbors' labels to determine the class of $A_i$. This entire pipleline is repeated using reference model $\SSL_B$ and its KNN to compute reference model accuracy. 

In practice, all of our quantitative tests are repeated once with $\SSL_A$ as the target model (recovering labels of images in set $\calA$) and again with $\SSL_B$ as the target model (recovering labels of images in set $\calB$). All results shown are the average of these two tests. Throughout the paper, we describe $\SSL_A$ as the target model and $\SSL_B$ as the reference model for ease of exposition. 

\paragraph{RCDM:} The RCDM is trained on a face-blurred version of ImageNet~\citep{imagenet} and is used to decode the SSL backbone embedding of an image back into an approximation of the original image. All RCDMs are trained on the public set of images $\calX$ used for the KNN. A separate RCDM must be trained for each SSL model, since each model has a unique mapping from image space to embedding space. 

At inference time, the RCDM is used to reconstruct the foreground object given only the periphery cropping. To produce this reconstruciton, the RCDM needs an approximation of the backbone embedding of the original image. The backbone of image $A_i$ is approximated by \textbf{1)} computing crop embedding $\SSLpj_A(\crop{A_i})$, \textbf{2)} finding the five public set nearest neighbors of the crop embedding, and \textbf{3)} averaging the five nearest neighbors' backbone embeddings. In practice, these public set nearest neighbors are often a very good approximation of the original image, capturing aspects like object class, position, subspecies, etc..  

\clearpage

\subsection{Additional quantitative experiments}
\label{sec:appx quantitative}

\subsubsection{Sample-level memorization}
\input{chapters/chapter1/partition_attk_figure}
\input{chapters/chapter1/sweep_parameters_figure} 
Many SSL algorithms contain hyperparameters that control how similar the embeddings of different views should be in the training objective. 
We show that these hyperparameters directly affect \dejavu memorization. Figure \ref{fig:sweep params} shows the size of the memorized set for SimCLR (left) and VICReg (right) as a function of their respective hyperparameters, $\tau$ and $\lambda$. We observe that the memorized set is largest within a relatively narrow band of hyperparameter values, indicating strong \dejavu memorization. By selecting hyperparameters outside this band, \dejavu memorization sharply decreases while the linear probe validation accuracy on ImageNet remains roughly the same.

%\clearpage

\subsubsection{Selection of $K$ for KNN}
\label{sec:appx KNN} 
In this section, we describe the impact of $K$ on the KNN label inference accuracy. 

\begin{figure}[ht]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/attk_knn_acc_top1_legend.pdf}
         \caption{Vicreg, Accuracy}
         \label{fig:vicreg v. epoch}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/attk_knn_partition_top1_legend.pdf}
         \caption{Vicreg, Share of memorized examples }
         \label{fig:vicreg lp v. epoch}
     \end{subfigure}
     \hfill
\caption[Impact of $K$ on label inference accuracy for target and reference models.]{
Impact of $K$ on label inference accuracy for target and reference models. \textbf{Left:} the population-level label inference accuracy experiment of Section \ref{sec:label inference accuracy} on VICReg vs. $K$. \textbf{Right:} the individualized memorization test of Section \ref{sec:dissection} on VICReg vs. $K$. In both cases, we see that our tests are relatively robust to choice of $K$ beyond $K=50$.  
}
\label{fig:attack v K}
\end{figure}

Figure \ref{fig:attack v K} above shows how the tests of Section \ref{sec:quant} change with number of public set nearest neighbors $K$ used to make label inferences. Both tests are relatively robust to any choice of $K$. Results are shown on VICReg trained for 1k epochs on the 300k dataset. We see that any choice of $K$ greater than 50 and less than the number of examples per class (300, in this case) appears to have good performance. Since our smallest dataset has 100 images per class, we chose to set $K = 100$ for all experiments. 

\clearpage

% \subsection{Additional Quantitative Test Results}
\subsubsection{Effect of SSL criteria}
\label{sec:appx simclr results} 
We repeat the quantitative memorization tests of Section \ref{sec:quant} on different models: VICReg\citep{vicreg}, Barlow-Twins\citep{zbontar2021barlow}, Dino\citep{Dino}, Byol\citep{grill2020byol}, SimCLR\citep{simclr} and a supervised model in \cref{fig:all_models_quantitative}. We observe differences between SSL training criteria with respect to Dejavu memorization. The easy ones to attack are VICReg and Barlow Twins whereas SimCLR and Byol are more robust to these attacks. While the degree of memorization appears to be reduced for SimCLR compared with VICReg, it is still stronger than the supervised baseline.

\begin{figure}[ht]
\captionsetup[subfigure]{font=scriptsize,labelfont=scriptsize}
     \centering
     \includegraphics[width=\textwidth]{figures/dejavu_ssl_criterions.pdf}
\caption[Comparison of \dejavu memorization for VICReg, Barlow Twins, Dino, Byol, SimCLR, and a supervised model.]{
Comparison of \dejavu memorization for VICReg, Barlow Twins, Dino, Byol, SimCLR, and a supervised model. All tests are described in Section \ref{sec:quant}. We are showing \dejavu vs. number of training epochs. We see that SimCLR (center row) shows less \dejavu than VICReg, yet marginally more than the supervised model. Even with this reduced degree of memorization, we are able to produce detailed reconstructions of training set images, as shown in Figures \ref{fig:mem v corr dam} and \ref{fig:mem v corr spider}. 
}
\label{fig:all_models_quantitative}
\end{figure}

\clearpage 

\subsubsection{Effect of Model Architecture and Complexity}
\label{sec:appx rn50}
Results shown in the main paper use Resnet101 for the model backbone. To understand the relationship between \dejavu and overparameterization, we compare with the smaller Resnet50 and Resnet18 in Figure \ref{fig:rn101 v. rn50}. Overall, we find that increasing the number of parameters of the model leads to higher degree of \dejavu memorization. The same trend holds when using Vision Transformers (VIT-Tiny, -Small, -Base, and -Large with patch size of 16) of various sizes as the SSL backbone, instead of a Resnet. This highlights that \dejavu memorization is not unique to convolution architectures. 

\begin{figure}[ht]
\captionsetup[subfigure]{font=scriptsize,labelfont=scriptsize}
     \centering
     \includegraphics[width=\textwidth]{figures/plot_arch_comp.pdf}
     \caption[Comparison of VICReg \dejavu memorization for different architectures and model sizes.]{Comparison of VICReg \dejavu memorization for different architectures and model sizes. On the left, we present deja vu memorization using VIT architectures (from vit-tiny in the first row to vit-base in the last row). On the right, we use Resnet based architectures (from resnet18 in the first row to resnet101 in the last row). All tests are described in Section \ref{sec:quant}, with the plots showing \dejavu vs. number of training epochs. Reducing model complexity from Resnet101 to Resnet18 or from Vit-Large to Vit-tiny has a significant impact on the degree of memorization.}
\label{fig:rn101 v. rn50}
\end{figure}

\clearpage

\subsubsection{The impact of Guillotine Regularization on Deja Vu}
\label{sec:guillotine}
In our experiments, we show \dejavu using the projector representation. The SSL loss directly incentivizes the projector representation to be invariant to random crops of a particular image. As such, we expect the projector to be the \emph{most} overfit and produce the strongest \dejavu. Here, we study whether earlier representations between the projector and backbone exhibit less \dejavu memorization. This phenomenon -- `guillotine regularization' -- has recently been studied from the perspective of generalization in \citet{Guillotine}. Here, we study it from the perspective of \emph{memorization}. 

To show how guillotine regularization impacts \dejavu, we repeat the tests of Section \ref{sec:quant} on each layer of the VICReg projector: the 2048-dimension backbone (layer 0) up to the projector output (layer 3). We evaluate whether memorization is indeed reduced for the more \emph{regularized} layers between the projector output and the backbone. 

\begin{figure*}[h]
\captionsetup[subfigure]{font=scriptsize,labelfont=scriptsize}
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/attk_layer_acc_top1_legend.pdf}
         \caption{population level accuracy}
     \end{subfigure}
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/attk_layer_partition_top1_legend.pdf}
         \caption{share of memorized examples}
     \end{subfigure}
     \hfill
\caption[\dejavu memorization versus layer from backbone (0) to projector output (3).]{
\dejavu memorization versus layer from backbone (0) to projector output (3). The memorization tests of Section \ref{sec:quant} are evaluated at each level of the VICReg projector. We see that \dejavu is significantly stronger closer to the projector output and nearly zero near the backbone. Interestingly, most memorization appears to occur in the final two layers of VICReg.
}
\label{fig:guillotine}
\end{figure*}

Figure \ref{fig:guillotine} shows how guillotine regularization significantly reduces the degree of memorization in VICReg. The vast majority of VICReg's \dejavu appears to occur in the final two layers of the projector (2,3): in earlier layers (0,1), the label inference accuracy of the target model and reference model are comparable. This suggests that -- like the hyperparameter selection of Section \ref{sec:conclusion} -- guillotine regularization can also significantly mitigate \dejavu memorization. In the following, we extend this result to SimCLR and supervised models by measuring the degree of \dejavu in the backbone (layer 0) versus training epochs and dataset size. 

\newpage

\paragraph{Comparison of \dejavu in projector and backbone vs. epochs and dataset size}
Since the backbone is mostly used at inference time, we now evaluate how much \dejavu exists in the backbone representation for VICReg and SimCLR. We repeat the tests of Section \ref{sec:quant} versus training epochs and train set size. 

\begin{figure}[h]
     \centering
     \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/plot_vicreg_projback.pdf}
         \caption{VICReg}
         \label{fig:vicreg v. epoch}
     \end{subfigure}
     \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/plot_simclr_projback.pdf}
         \caption{SimCLR}
         \label{fig:vicreg lp v. epoch}
     \end{subfigure}
     \hfill
\caption[Accuracy of label inference on VICReg and SimCLR using projector and backbone representations.]{
Accuracy of label inference on VICReg and SimCLR using projector and backbone representations. \textbf{First two columns:} Effect of training epochs on memorization for each representation. \textbf{Last two columns:} Effect of training set size on memorization for each representation. In contrast with VICReg, the \dejavu memorization detected in SimCLR's projector and backbone representations is quite similar. While SimCLR's projector memorization appears weaker than that of VICReg, its backbone memorization is markedly stronger. This kind be easily explained as a byproduct of Guillotine Regularization~\citep{Guillotine}, i.e. removing layers close to the objective reduce the bias of the network with respect to the training task. Since SimCLR's projector has fewer layers than VICReg's, the impact of Guillotine Regularization is less salient.
}
\label{fig:proj v backbone}
\end{figure}

Figure \ref{fig:proj v backbone} shows that, indeed, \dejavu is significantly reduced in the backbone representation. For SimCLR, however, we see that backbone memorization is comparable with projector memorization. In light of the Guillotine regularization results above, this makes some sense since SimCLR uses fewer layers in its projector. Given that we were able to generate accurate reconstructions with the SimCLR projector (see Figures \ref{fig:mem v corr spider} and \ref{fig:mem v corr dam}), we now evaluate whether we can produce accurate reconstructions of training examples using the SimCLR backbone alone. 

\clearpage

\subsection{Additional reconstruction examples}
\label{sec:appx visualization}
The two reconstruction experiments of Section \ref{sec:visualizing} are each exemplified within one class. However, we see strong reconstructions using $\SSL_A$ in several classes, and similar experimental results. To demonstrate this, we repeat the experiments \ref{sec:mem v corr} using the \emph{yellow garden spider} class and the and the \emph{aircraft carrier} class. 
\input{chapters/chapter1/mem_v_corr_spider.tex}
\paragraph{Selection of Memorized and Correlated Images:} The images of Figure \ref{fig:mem v corr dam} and \ref{fig:mem v corr spider} were chosen methodically as follows. 

\paragraph{Image selection:} The 20 images of Figures \ref{fig:mem v corr dam} and \ref{fig:mem v corr spider} are  selected deterministically using label inference accuracy and KNN confidence score. The 10 most correlated images are those images in the correlated set (both models infer label correctly) of $\calA$ with the highest confidence agreement between models $\SSL_A$ and $\SSL_B$. To measure confidence agreement we take the minimum confidence of the two models. The 10 most memorized images are those images in the memorized set (only target model infers the label correctly) of $\calA$ with the highest confidence difference between models $\SSL_A$ and $\SSL_B$.

\paragraph{Class selection:} To find classes with a high degree of \dejavu, classes were sorted by the label inference accuracy gap between the target and reference model. We selected the class based on a handful of criteria. First, we prioritized classes without images of human faces, thereby removing classes like `basketball', `bobsled', `train station', and even `tench' which is a fish often depicted in the hands of a fisherman. Second, we prioritized classes that include at least ten images with a high confidence difference between the target and reference models (`most memorized' images described above) and at least ten images with high confidence agreement (`most correlated' images described above). This led us to the \emph{dam} and \emph{yellow garden spider} classes. 
\clearpage

\input{chapters/chapter1/ship_examples.tex}

\paragraph{Selection of Beyond-Label-Inference Images:} The images of Figure \ref{fig:in class badger} and \ref{fig:in class ship} were chosen methodically as follows. 

\paragraph{Image selection:} The four images of Figures \ref{fig:in class badger} 
 and \ref{fig:in class ship} 
are selected using KNN confidence score, and, necessarily, hand picked selection for unlabeled features. Within a given class, we look at the top 40 images with highest target model KNN confidence scores. We then filter through these images to identify a distinguishable feature like different species within the same class or different object positions within the same class. This step is necessary because we are looking for features that are not labeled by ImageNet. We then choose two of these top 40 with one feature (e.g. American badger) and two with the alternative feature (e.g. European badger). 

\paragraph{Class selection:} To find classes with a high degree of \dejavu, classes were sorted by the target model's top-40 KNN confidence values within each class. As in the memorization vs. correlation experiment, we prioritized classes without images of human faces.

\subsubsection{Reconstructions using SimCLR Backbone} 
\label{sec:appx backbone results} 
The label inference results in Appendix \ref{sec:guillotine} show that the SimCLR backbone exhibits a similar degree of \dejavu memorization as the projector does. To evaluate the risk of such memorization, we repeat the reconstruction experiment of Section \ref{sec:visualizing} on the \emph{dam} class using the SimCLR backbone instead of its projector.\\

\begin{figure}[h]
     \centering
     \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/dam_simclr_backbone_1.png}
         \caption{First {\color{part_orange}memorized} dam example}
     \end{subfigure}
     \begin{subfigure}[b]{\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/dam_simclr_backbone_2.png}
         \caption{Second {\color{part_orange}memorized} dam example}
     \end{subfigure}
     \hfill
     \caption[Instances of \dejavu memorization by the SimCLR backbone representation.]{Instances of \dejavu memorization by the SimCLR backbone representation. Here, the backbone embedding of the crop is used instead of the projector embedding on the same training images used in Figure \ref{fig:mem v corr dam}. Interestingly, we see that \dejavu memorization is still present in the SimCLR backbone representation. Here, the nearest neighbor set recovers dam given an uninformative crop of still or running water. Even without projector access, we are able to reconstruct images in set $\calA$ using $\SSL_A$, and are unable using $\SSL_B$. }
     \label{fig:simclr backbone dejavu}
\end{figure}


Figure \ref{fig:simclr backbone dejavu} demonstrates that we are able to reconstruct training set images using the SimCLR backbone alone. This indicates that \dejavu memorization can be leveraged to make detailed inferences about training set images without \emph{any} access to the projector. As such, withholding the projector for model release may not be a strong enough mitigation against \dejavu memorization.  

\clearpage

\subsection{Detecting \Dejavu without Bounding Box Annotations}
\label{sec:appx corner crop} 
The memorization tests presented critically depend on bounding box annotations in order to separate the foreground object from the periphery crop. Since such annotations are often not available, we propose a heuristic test that simply uses the lower left corner of an image as a surrogate for the periphery crop. Since foreground objects tend to be near the center of the image, the corner crop usually excludes the foreground object and does not require a bounding box annotation. 

\cref{corner crop} demonstrates that this heuristic test can successfully capture the trends of the original tests (seen in Figure \ref{fig:all_models_quantitative}) \emph{without} access to bounding box annotations. However, as compared to Figure \ref{fig:all_models_quantitative}, the heuristic tends to slightly underestimate the degree of memorization. This is likely due to the fact that some corner crops partially include the foreground object, thus enabling the $\KNN$ to successfully recover the label with the reference model where it would have failed with a proper periphery crop that excludes the foreground object. 

\begin{figure}[ht]
\captionsetup[subfigure]{font=scriptsize,labelfont=scriptsize}
     \centering
     \includegraphics[width=\textwidth]{figures/plot_models_corner_crop.pdf}
\caption[Deja Vu Memorization using a simple corner crop instead of the periphery crop extracted using bounding box annotations.]{
Deja Vu Memorization using a simple corner crop instead of the periphery crop extracted using bounding box annotations. While the heuristic overall underestimates the degree of \dejavu, it roughly follows the same trends versus dataset size and training epochs. This is crucial, since it allows us to estimate \dejavu without access to bounding box annotations. 
}
\label{corner crop}
\end{figure}
 
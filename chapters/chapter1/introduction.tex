\section{Introduction}
\label{sec:intro}
Self-supervised learning (SSL)~\citep{chen2020simclr, chen2020simsiam, zbontar2021barlow, vicreg, caron2020swav, MAE} aims to learn general representations of content-rich data without explicit labels by solving a \textit{pretext task}. In many recent works, such pretext tasks rely on joint-embedding architectures whereby randomized image augmentations are applied to create multiple views of a training sample, and the model is trained to produce similar representations for those views. When using cropping as random image augmentation, the model learns to associate objects or parts (including the background scenery) that co-occur in an image.
However, doing so also arguably exposes the training data to higher privacy risk as objects in training images can be explicitly memorized by the SSL model. For example, if the training data contains the photos of individuals, the SSL model may learn to associate the face of a person with their activity or physical location in the photo. This may allow an adversary to extract such information from the trained model for targeted individuals.

\input{./chapters/chapter1/swan_cartoon.tex}

In this work, we aim to evaluate to what extent SSL models memorize the association of specific objects in training images or the association of objects and their specific backgrounds, and whether this memorization signal can be used to reconstruct the model's training samples. Our results demonstrate that SSL models memorize such associations beyond simple correlation. For instance, in Figure \ref{fig:black_swan} (\textbf{left}), we use the SSL representation of a \emph{training image crop containing only water} and this enables us to reconstruct the object in the foreground with remarkable specificity---in this case a black swan.
By contrast, in Figure \ref{fig:black_swan} (\textbf{right}), when using the \emph{crop from the background of a test set image} that the SSL model \emph{has not seen before}, its representation only contains enough information to infer, through correlation, that the foreground object was likely some kind of waterbird --- but not the specific one in the image.

Figure \ref{fig:black_swan} shows that SSL models suffer from the unintended memorization of images in their training data---a phenomenon we refer to as \emph{déjà vu memorization}
%\footnote{The French loanword \emph{déjà vu} means already-seen, which reflects the type of unintended memorization of objects that the SSL model saw during training.}.
\footnote{The French loanword \emph{déjà vu} means `already-seen', just as an image is seen and memorized in training.}
Beyond visualizing \emph{déjà vu} memorization through data reconstruction, we also design a series of experiments to quantify the degree of memorization for different SSL algorithms, model architectures, training set size, \emph{etc.} We observe that \emph{déjà vu} memorization is exacerbated by the atypically large number of training epochs often recommended in SSL training, as well as certain hyperparameters in the SSL training objective. Perhaps surprisingly, we show that \emph{déjà vu} memorization occurs even when the training set is large---as large as half of ImageNet~\citep{imagenet}---and can continually worsen even when standard techniques for evaluating learned representation quality (such as linear probing) do not suggest increased overfitting. Our work serves as the first systematic study of unintended memorization in SSL models and motivates future work on understanding and preventing this behavior. Specifically, we: 
\begin{itemize}
    \vspace{-0.5em}
    \item Elucidate how SSL representations memorize aspects of individual training images, what we call \emph{déjà vu} memorization;
    \item Design a novel training data reconstruction pipeline for non-generative vision models. This is in contrast to many prominent reconstruction algorithms like \citep{carlini2021extracting, google_diffusion}, which rely on the model itself to generate its own memorized samples and is not possible for SSL models or classifiers;
    \item Propose metrics to quantify the degree of \dejavu memorization committed by an SSL model. This allows us to observe how \dejavu changes with training epochs, dataset size, training criteria, model architecture and more. 
\end{itemize}

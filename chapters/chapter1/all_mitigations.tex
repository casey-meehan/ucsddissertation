\begin{figure}[ht]
\label{fig:mitigations}
\begin{minipage}[t]{0.5\textwidth}
\centering
     \begin{subfigure}[b]{0.47\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/dejavu_vicreg_param.png}
         \vspace{-1.5em}
         \caption{Loss hyper-parameter}
         \label{fig:dejavu v. invariance}
     \end{subfigure}
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/deja_vu_vs_layer.png}
         \vspace{-1.5em}
         \caption{Guillotine regularization}
         \label{fig:dejavu v. guillotine}
     \end{subfigure}~
     \vspace{-0.5em}
    \caption[Effect of two kinds of hyper-parameters on VICReg memorization. ]{
    Effect of two kinds of hyper-parameters on VICReg memorization. \textbf{Left:} \dejavu score (red) versus the \emph{invariance} loss parameter, $\lambda$, used in the VICReg criterion (100k dataset). Larger $\lambda$ significantly reduces \dejavu, with minimal effect on linear probe validation performance (green). $\lambda = 25$ (near maximum \dejavu) is recommended in the original paper \textbf{Right:} \dejavu score versus projector layer---guillotine regularization \cite{Guillotine}---from projector to backbone. Removing the projector can significantly reduce \dejavu. Appendix \ref{sec:guillotine} shows that the backbone still can memorize, however; we demonstrate reconstructions using the SimCLR backbone.
    }
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\centering
     \begin{subfigure}[b]{0.46\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/deja_vu_vs_parameters.png}
         \vspace{-1.3em}
         \caption{\dejavu vs. capacity}
         \label{fig:dejavu v. capacity}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.52\textwidth}
          \tiny
          \centering
          \setlength{\tabcolsep}{3pt}
          \begin{tabular}{|c|c|c|}
            \hline
            Criteria & DV & Acc P/B \\
            \hline
            Supervised & 8.9 & 55.3/61.1\\
            \hline
            Byol\citep{grill2020byol} & 8.0& 54.3/59.4\\
            \hline
            SimCLR\citep{chen2020simclr} & 10.0 & 44.2/54.1\\
            \hline
            Dino\citep{Dino} & 14.5 & 26.3/55.7 \\
            \hline
            Barlow T.\citep{zbontar2021barlow} & 30.5 & 33.7/54.4\\
            \hline
            VICReg\citep{vicreg} & \textbf{33.2} & 40.3/55.2\\
            \hline
          \end{tabular}
          \vspace{1.3em}
          % \caption{\dejavu (DV) vs. SSL Criterion}
          \caption{\dejavu (DV) vs. Criterion}
          \label{tab:dejavu vs. criterion}
    \end{subfigure}
    \vspace{-1.4em}
    \caption[Effect of model architecture and criterion on \dejavu memorization.]{
    %Comparison of \dejavu score for different architectures and training criteria. 
    Effect of model architecture and criterion on \dejavu memorization. 
    \textbf{Left:} \dejavu score with VICReg for resnet (purple) and vision transformer (green) architectures versus number of model parameters. As expected, memorization grows with larger model capacity. This trend is more pronounced for convolutional (resnet) than transformer (ViT) architectures. \textbf{Right:} Comparison of \dejavu score 20\% conf. and ImageNet linear probe validation accuracy (P: using projector embeddings, B: using backbone embeddings) for various SSL criteria. %\textbf{Nearly all SSL models have more memorization than the supervised baseline.} 
    % Effect of training epochs and train set size on \dejavu score.
    % \textbf{Left:} \dejavu score increases with higher number of training epochs, indicating worsening memorization.
    % \textbf{Right:} \dejavu score stays roughly constant with training set size. Both trends are not captured according to the linear probe train-test gap---a common method to evaluate generalization of SSL representations.
    }
    \end{minipage}
\end{figure}
\section{Background}\label{sec:background} 
\textbf{Notations.} \textbf{Boldface} (such as $\bx=\langle x_1, 
 \cdots, x_n\rangle$) denotes a data sequence (ordered list); normal font (such as $x_1$) denotes individual values and $\{\cdot\}$ represents a multiset or bag of values.\vspace{-0.3cm}
\subsection{Local Differential Privacy}\label{sec:ldp}
 \vspace{-0.2cm}The local model consists of a set of data owners and an untrusted data aggregator (analyst); each individual perturbs their data using a \ldp algorithm (randomizers) and sends it to the analyst. % which uses these noisy responses to glean information about the entire dataset.
The \ldp guarantee is formally defined as
\begin{defn}\vspace{-0.1cm}[Local Differential Privacy, \ldp \cite{Warner,Evfimievski:2003:LPB:773153.773174,Kasivi}]
 A randomized algorithm $\mathcal{M} : \mathcal{X} \rightarrow \mathcal{Y}$ is $\epsilon$-locally differentially private (or $\epsilon$-\ldp), if for any pair of private values $x, x' \in \mathcal{X}$ and any subset of output, %$\mathcal{W} \subseteq \mathcal{Y}$ we have $\mathrm{Pr}\big[\mathcal{M}(x) \in \mathcal{W}\big] \leq e^{\epsilon} \cdot \mathrm{Pr}\big[\mathcal{M}(x') \in \mathcal{W}  \big]$.
 %\end{defn}
 \begin{gather}
 \mathrm{Pr}\big[\mathcal{M}(x) \in \mathcal{W}\big] \leq e^{\epsilon} \cdot \mathrm{Pr}\big[\mathcal{M}(x') \in \mathcal{W}  \big]
  \end{gather}
  \end{defn}
The shuffle model is an extension of the local model where the data owners first randomize their inputs. Additionally, an intermediate trusted shuffler applies a \textit{uniformly random permutation} to all the noisy responses before the analyst can view them. The anonymity provided by the shuffler requires less noise than the local model for achieving the same
privacy.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%INFERENTIAL PRIVACY BACKGROUND 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Local Inferential Privacy}  \vspace{-0.2cm}
% %introduce pufferfish inferntial log loss 
% %In this section, we introduce some context for inferential privacy in the \ldp setting. 
% %Inferential privacy captures the privacy loss in the face of an informed adversary in a Bayesian framework. 
% Local inferential privacy captures what information a Bayesian adversary \cite{Pufferfish}, with some prior, can learn in the \ldp setting. 
% Specifically, it measures the largest possible ratio between the adversary's posterior and prior beliefs about an individual’s data after observing a mechanism's output .%\footnote{This quantity is identical to the \ldp parameter of the mechanism when\textit{individuals’ data are independent}\cite{sok,}.}.
% \begin{defn}(Local Inferential Privacy Loss \cite{Pufferfish}) Let $\bx=\langle x_1, \cdots, x_n\rangle$ and let $\by=\langle y_1, \cdots, y_n \rangle$ denote the input (private) and output sequences (observable to the adversary) in the \ldp setting. Additionally, the adversary's auxiliary knowledge is modeled by a prior distribution $\mathcal{P}$ on $\mathbf{x}$. The inferential privacy loss for the input sequence $\mathbf{x}$ is given by
% % \vspace{0cm} 
% \begin{equation}
% % \vspace{-0.1cm}
% \small \mathbb{L}_{\calP}(\mathbf{x})=\max_{\substack{i\in [n]\\ a,b \in \calX}}\Bigg(\log\frac{\mathrm{Pr}_{\calP}[\mathbf{y}|x_i=a]}{\mathrm{Pr}_{\calP}[\mathbf{y}|x_i=b]}\Bigg)
% =\max_{\substack{i\in [n]\\ a,b \in \calX}}\Bigg (	\bigg| \log \frac{\mathrm{Pr}_{\calP}[x_i = a | \bf{y} ]}{\mathrm{Pr}_{\calP}[x_i = b | \bf{y}]}
% 	- \log \frac{\mathrm{Pr}_{\calP}[x_i = a]}{\mathrm{Pr}_{\calP}[x_i = b]} \bigg|\Bigg)
% \end{equation}
% \label{def:ip}
% \vspace{-1em}
% \end{defn}
% % Using Bayes' theorem, we have\vspace{-0.2cm}
% % \begin{gather*}\small\vspace{-0.4cm} \mathbb{L}_{\calP}(\mathbf{x})=\max_{\substack{i\in [n]\\ a,b \in \calX}}\Bigg (	\bigg| \log \frac{\mathrm{Pr}_{\calP}[x_i = a | \bf{y} ]}{\mathrm{Pr}_{\calP}[x_i = b | \bf{y}]}
% % 	- \log \frac{\mathrm{Pr}_{\calP}[x_i = a]}{\mathrm{Pr}_{\calP}[x_i = b]} \bigg|\Bigg)\vspace{-0.7cm}\end{gather*}
% Bounding  $\mathbb{L}_{\calP}(\mathbf{x})$  would imply
%  that the adversary's belief about the value of any $x_i$ does not change by much even after observing the output sequence $\bf{y}$. This means that an informed adversary does not learn much about the individual $i$'s private input upon observation of the entire private dataset $\by$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%END INFERENTIAL PRIVACY BACKGROUND 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Mallows Model} \label{sec:background:MM}
A permutation of a set $S$ is a bijection $S\mapsto S$. The set of permutations of $[n], n \in \mathbb{N}$ forms a symmetric group $\mathrm{S}_n$. As a shorthand, we use $\sigma(\bx)$ to denote applying permutation $\sigma \in \mathrm{S}_n$ to a data sequence $\bx$ of length $n$. Additionally, $\sigma(i), i\in [n], \sigma \in \mathrm{S}_n$ denotes the value at index $i$ in $\sigma$ and $\sigma^{-1}$ denotes its inverse. For example, if $\sigma=( 1 \: 3 \: 5\: 4\: 2)$ and $\bx=\langle 21, 33, 45, 65 , 67\rangle$, then $\sigma(\bx)=\langle 21, 45, 67, 65, 33\rangle$, $\sigma(2)=3, \sigma(3)=5$ and $\sigma^{-1}=(1 \: 5 \: 2 \: 4 \: 3)$.
\\Mallows model is a popular probabilistic model for permutations \citep{MM}.  %It is an exponential location model and is usually referred to as the Gaussian distribution for permutations. 
The mode of the distribution is given
by the reference permutation $\sigma_0$ -- the probability of a permutation increases as we move `closer' to $\sigma_0$ as measured by rank distance metrics, such as the Kendall's tau distance (Def. \ref{def:kendall}). The dispersion parameter $\theta$ controls how fast this increase happens.  %The formal definition of the Mallows model is as follows.
\begin{defn}
\label{def: mallows}
For a dispersion parameter $\theta$, a reference permutation $\sigma_o \in \mathrm{S}_n$, and a rank distance measure $\textswab{d}: \mathrm{S}_n \times \mathrm{S}_n \mapsto \R $,   
$
\mathbb{P}_{\Theta,\textswab{d}}(\sigma:\sigma_0)=\frac{1}{\psi(\theta,\textswab{d})} e^{-\theta  \textswab{d}(\sigma, \sigma_0)}$
is the Mallows model where $\psi(\theta,\textswab{d})=\sum_{\sigma \in \mathrm{S}_n} e^{-\theta \textswab{d}(\sigma,\sigma_0)}$ is a normalization term and  $\sigma \in \mathrm{S}_n$.
\end{defn}





